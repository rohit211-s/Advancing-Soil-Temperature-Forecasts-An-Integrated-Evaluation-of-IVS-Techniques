{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GitytHHMwD1m",
        "cHgT0WGLK6MU",
        "6ZdU6EmcJgb6",
        "0gx51ALOLGNE",
        "2jFWpddYmqzg",
        "AjLheUnMm0Ka",
        "epBSX96am50G",
        "8dG2hQZHm907",
        "ZgnG9XtAm93G",
        "LL7EKtJ3m95h",
        "aU0eGuitm97Z",
        "n_agQ-VRm99d",
        "FV--iSpVm9_q",
        "D3LQn1Vim-CI",
        "ICCzX0rOm-D5",
        "Pa-mJeMnm-HS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa6PZgl_gLaK",
        "outputId": "7b4a5880-426c-455c-bdb0-1fbe9f8b2ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TST04MfiQCqk",
        "outputId": "955507ce-51bb-448a-a3fd-719ca35416cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/612.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install umap-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZFG4QamR_bQ",
        "outputId": "2835ca89-85fa-4a7c-e359-ead82b919c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.10.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.56.4)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.65.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (67.7.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82816 sha256=5e97d4052b49ee0b7fa1a2b8aba0f3e08898ee2c0e243cb9ebca86f34b9790ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=f87398346e1ef36e135da035ea7ccecf8e721565259b025dfb993b2ef56816ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.10 umap-learn-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U scikit-learn"
      ],
      "metadata": {
        "id": "wg3s6lvzEvrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5846459c-30e5-4ea1-a709-f6737972ba79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openpyxl import Workbook\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.init import xavier_uniform_\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import umap\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression, Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "sq8fAgwxRY0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AdaBelief Optimizer"
      ],
      "metadata": {
        "id": "0FWN4o8tDPSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDbtZT-TDyqi",
        "outputId": "93891f36-8123-4e80-d37c-cc67e33a219a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from tabulate import tabulate\n",
        "from colorama import Fore, Back, Style\n",
        "\n",
        "version_higher = ( torch.__version__ >= \"1.5.0\" )\n",
        "\n",
        "class AdaBelief(Optimizer):\n",
        "    r\"\"\"Implements AdaBelief algorithm. Modified from Adam in PyTorch\n",
        "    Arguments:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float, optional): learning rate (default: 1e-3)\n",
        "        betas (Tuple[float, float], optional): coefficients used for computing\n",
        "            running averages of gradient and its square (default: (0.9, 0.999))\n",
        "        eps (float, optional): term added to the denominator to improve\n",
        "            numerical stability (default: 1e-16)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n",
        "            algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
        "            (default: False)\n",
        "        weight_decouple (boolean, optional): ( default: True) If set as True, then\n",
        "            the optimizer uses decoupled weight decay as in AdamW\n",
        "        fixed_decay (boolean, optional): (default: False) This is used when weight_decouple\n",
        "            is set as True.\n",
        "            When fixed_decay == True, the weight decay is performed as\n",
        "            $W_{new} = W_{old} - W_{old} \\times decay$.\n",
        "            When fixed_decay == False, the weight decay is performed as\n",
        "            $W_{new} = W_{old} - W_{old} \\times decay \\times lr$. Note that in this case, the\n",
        "            weight decay ratio decreases with learning rate (lr).\n",
        "        rectify (boolean, optional): (default: True) If set as True, then perform the rectified\n",
        "            update similar to RAdam\n",
        "        degenerated_to_sgd (boolean, optional) (default:True) If set as True, then perform SGD update\n",
        "            when variance of gradient is high\n",
        "        print_change_log (boolean, optional) (default: True) If set as True, print the modifcation to\n",
        "            default hyper-parameters\n",
        "    reference: AdaBelief Optimizer, adapting stepsizes by the belief in observed gradients, NeurIPS 2020\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-16,\n",
        "                 weight_decay=0, amsgrad=False, weight_decouple=True, fixed_decay=False, rectify=True,\n",
        "                 degenerated_to_sgd=True, print_change_log = True):\n",
        "\n",
        "        # ------------------------------------------------------------------------------\n",
        "        # Print modifications to default arguments\n",
        "        if print_change_log:\n",
        "            print(Fore.RED + 'Please check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.')\n",
        "            print(Fore.RED + 'Modifications to default arguments:')\n",
        "            default_table = tabulate([\n",
        "                ['adabelief-pytorch=0.0.5','1e-8','False','False'],\n",
        "                ['>=0.1.0 (Current 0.2.0)','1e-16','True','True']],\n",
        "                headers=['eps','weight_decouple','rectify'])\n",
        "            print(Fore.RED + default_table)\n",
        "\n",
        "            recommend_table = tabulate([\n",
        "                ['Recommended eps = 1e-8', 'Recommended eps = 1e-16'],\n",
        "                ],\n",
        "                headers=['SGD better than Adam (e.g. CNN for Image Classification)','Adam better than SGD (e.g. Transformer, GAN)'])\n",
        "            print(Fore.BLUE + recommend_table)\n",
        "\n",
        "            print(Fore.BLUE +'For a complete table of recommended hyperparameters, see')\n",
        "            print(Fore.BLUE + 'https://github.com/juntang-zhuang/Adabelief-Optimizer')\n",
        "\n",
        "            print(Fore.GREEN + 'You can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.')\n",
        "\n",
        "            print(Style.RESET_ALL)\n",
        "        # ------------------------------------------------------------------------------\n",
        "\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "\n",
        "        self.degenerated_to_sgd = degenerated_to_sgd\n",
        "        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n",
        "            for param in params:\n",
        "                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n",
        "                    param['buffer'] = [[None, None, None] for _ in range(10)]\n",
        "\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, amsgrad=amsgrad, buffer=[[None, None, None] for _ in range(10)])\n",
        "        super(AdaBelief, self).__init__(params, defaults)\n",
        "\n",
        "        self.degenerated_to_sgd = degenerated_to_sgd\n",
        "        self.weight_decouple = weight_decouple\n",
        "        self.rectify = rectify\n",
        "        self.fixed_decay = fixed_decay\n",
        "        if self.weight_decouple:\n",
        "            print('Weight decoupling enabled in AdaBelief')\n",
        "            if self.fixed_decay:\n",
        "                print('Weight decay fixed')\n",
        "        if self.rectify:\n",
        "            print('Rectification enabled in AdaBelief')\n",
        "        if amsgrad:\n",
        "            print('AMSGrad enabled in AdaBelief')\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(AdaBelief, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('amsgrad', False)\n",
        "\n",
        "    def reset(self):\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                state = self.state[p]\n",
        "                amsgrad = group['amsgrad']\n",
        "\n",
        "                # State initialization\n",
        "                state['step'] = 0\n",
        "                # Exponential moving average of gradient values\n",
        "                state['exp_avg'] = torch.zeros_like(p.data,memory_format=torch.preserve_format) \\\n",
        "                    if version_higher else torch.zeros_like(p.data)\n",
        "\n",
        "                # Exponential moving average of squared gradient values\n",
        "                state['exp_avg_var'] = torch.zeros_like(p.data,memory_format=torch.preserve_format) \\\n",
        "                    if version_higher else torch.zeros_like(p.data)\n",
        "\n",
        "                if amsgrad:\n",
        "                    # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                    state['max_exp_avg_var'] = torch.zeros_like(p.data,memory_format=torch.preserve_format) \\\n",
        "                        if version_higher else torch.zeros_like(p.data)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                # cast data type\n",
        "                half_precision = False\n",
        "                if p.data.dtype == torch.float16:\n",
        "                    half_precision = True\n",
        "                    p.data = p.data.float()\n",
        "                    p.grad = p.grad.float()\n",
        "\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError(\n",
        "                        'AdaBelief does not support sparse gradients, please consider SparseAdam instead')\n",
        "                amsgrad = group['amsgrad']\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data,memory_format=torch.preserve_format) \\\n",
        "                        if version_higher else torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_var'] = torch.zeros_like(p.data,memory_format=torch.preserve_format) \\\n",
        "                        if version_higher else torch.zeros_like(p.data)\n",
        "                    if amsgrad:\n",
        "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                        state['max_exp_avg_var'] = torch.zeros_like(p.data,memory_format=torch.preserve_format) \\\n",
        "                            if version_higher else torch.zeros_like(p.data)\n",
        "\n",
        "                # perform weight decay, check if decoupled weight decay\n",
        "                if self.weight_decouple:\n",
        "                    if not self.fixed_decay:\n",
        "                        p.data.mul_(1.0 - group['lr'] * group['weight_decay'])\n",
        "                    else:\n",
        "                        p.data.mul_(1.0 - group['weight_decay'])\n",
        "                else:\n",
        "                    if group['weight_decay'] != 0:\n",
        "                        grad.add_(p.data, alpha=group['weight_decay'])\n",
        "\n",
        "                # get current state variable\n",
        "                exp_avg, exp_avg_var = state['exp_avg'], state['exp_avg_var']\n",
        "\n",
        "                state['step'] += 1\n",
        "                bias_correction1 = 1 - beta1 ** state['step']\n",
        "                bias_correction2 = 1 - beta2 ** state['step']\n",
        "\n",
        "                # Update first and second moment running average\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "                grad_residual = grad - exp_avg\n",
        "                exp_avg_var.mul_(beta2).addcmul_( grad_residual, grad_residual, value=1 - beta2)\n",
        "\n",
        "                if amsgrad:\n",
        "                    max_exp_avg_var = state['max_exp_avg_var']\n",
        "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
        "                    torch.max(max_exp_avg_var, exp_avg_var.add_(group['eps']), out=max_exp_avg_var)\n",
        "\n",
        "                    # Use the max. for normalizing running avg. of gradient\n",
        "                    denom = (max_exp_avg_var.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
        "                else:\n",
        "                    denom = (exp_avg_var.add_(group['eps']).sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
        "\n",
        "                # update\n",
        "                if not self.rectify:\n",
        "                    # Default update\n",
        "                    step_size = group['lr'] / bias_correction1\n",
        "                    p.data.addcdiv_( exp_avg, denom, value=-step_size)\n",
        "\n",
        "                else:  # Rectified update, forked from RAdam\n",
        "                    buffered = group['buffer'][int(state['step'] % 10)]\n",
        "                    if state['step'] == buffered[0]:\n",
        "                        N_sma, step_size = buffered[1], buffered[2]\n",
        "                    else:\n",
        "                        buffered[0] = state['step']\n",
        "                        beta2_t = beta2 ** state['step']\n",
        "                        N_sma_max = 2 / (1 - beta2) - 1\n",
        "                        N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                        buffered[1] = N_sma\n",
        "\n",
        "                        # more conservative since it's an approximated value\n",
        "                        if N_sma >= 5:\n",
        "                            step_size = math.sqrt(\n",
        "                                (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n",
        "                                        N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                        elif self.degenerated_to_sgd:\n",
        "                            step_size = 1.0 / (1 - beta1 ** state['step'])\n",
        "                        else:\n",
        "                            step_size = -1\n",
        "                        buffered[2] = step_size\n",
        "\n",
        "                    if N_sma >= 5:\n",
        "                        denom = exp_avg_var.sqrt().add_(group['eps'])\n",
        "                        p.data.addcdiv_(exp_avg, denom, value=-step_size * group['lr'])\n",
        "                    elif step_size > 0:\n",
        "                        p.data.add_( exp_avg, alpha=-step_size * group['lr'])\n",
        "\n",
        "                if half_precision:\n",
        "                    p.data = p.data.half()\n",
        "                    p.grad = p.grad.half()\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "KFyEtZ-CDR5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RangerAdaBelief Optimizer"
      ],
      "metadata": {
        "id": "Egkh3hehDdcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ranger deep learning optimizer - AdaBelief + RAdam + Lookahead + Gradient Centralization, combined into one optimizer.\n",
        "\n",
        "# https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n",
        "# and/or\n",
        "# https://github.com/lessw2020/Best-Deep-Learning-Optimizers\n",
        "\n",
        "# Credits:\n",
        "# Gradient Centralization --> https://arxiv.org/abs/2004.01461v2 (a new optimization technique for DNNs), github:  https://github.com/Yonghongwei/Gradient-Centralization\n",
        "# RAdam -->  https://github.com/LiyuanLucasLiu/RAdam\n",
        "# Lookahead --> rewritten by lessw2020, but big thanks to Github @LonePatient and @RWightman for ideas from their code.\n",
        "# Lookahead paper --> MZhang,G Hinton  https://arxiv.org/abs/1907.08610\n",
        "# AdaBelief --> J. Zhuang et al. https://arxiv.org/abs/2010.07468\n",
        "\n",
        "# summary of changes\n",
        "# 9/4/20 - updated addcmul_ signature to avoid warning.  Integrates latest changes from GC developer (he did the work for this), and verified on performance on private dataset.\n",
        "# 4/11/20 - add gradient centralization option.  Set new testing benchmark for accuracy with it, toggle with use_gc flag at init.\n",
        "# full code integration with all updates at param level instead of group, moves slow weights into state dict (from generic weights),\n",
        "# supports group learning rates (thanks @SHolderbach), fixes sporadic load from saved model issues.\n",
        "# changes 8/31/19 - fix references to *self*.N_sma_threshold;\n",
        "# changed eps to 1e-5 as better default than 1e-8.\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "\n",
        "def centralized_gradient(x, use_gc=True, gc_conv_only=False):\n",
        "    '''credit - https://github.com/Yonghongwei/Gradient-Centralization '''\n",
        "    if use_gc:\n",
        "        if gc_conv_only:\n",
        "            if len(list(x.size())) > 3:\n",
        "                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n",
        "        else:\n",
        "            if len(list(x.size())) > 1:\n",
        "                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n",
        "    return x\n",
        "\n",
        "\n",
        "class RangerAdaBelief(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3,                       # lr\n",
        "                 alpha=0.5, k=6, N_sma_threshhold=5,           # Ranger options\n",
        "                 betas=(.95, 0.999), eps=1e-5, weight_decay=0,  # Adam options\n",
        "                 # Gradient centralization on or off, applied to conv layers only or conv + fc layers\n",
        "                 use_gc=True, gc_conv_only=False, gc_loc=True, adabelief = True, weight_decouple = True,\n",
        "                 ):\n",
        "\n",
        "        # parameter checks\n",
        "        if not 0.0 <= alpha <= 1.0:\n",
        "            raise ValueError(f'Invalid slow update rate: {alpha}')\n",
        "        if not 1 <= k:\n",
        "            raise ValueError(f'Invalid lookahead steps: {k}')\n",
        "        if not lr > 0:\n",
        "            raise ValueError(f'Invalid Learning Rate: {lr}')\n",
        "        if not eps > 0:\n",
        "            raise ValueError(f'Invalid eps: {eps}')\n",
        "\n",
        "        # parameter comments:\n",
        "        # beta1 (momentum) of .95 seems to work better than .90...\n",
        "        # N_sma_threshold of 5 seems better in testing than 4.\n",
        "        # In both cases, worth testing on your dataset (.90 vs .95, 4 vs 5) to make sure which works best for you.\n",
        "\n",
        "        # prep defaults and init torch.optim base\n",
        "        defaults = dict(lr=lr, alpha=alpha, k=k, step_counter=0, betas=betas,\n",
        "                        N_sma_threshhold=N_sma_threshhold, eps=eps, weight_decay=weight_decay)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "        # adjustable threshold\n",
        "        self.N_sma_threshhold = N_sma_threshhold\n",
        "\n",
        "        # look ahead params\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.k = k\n",
        "\n",
        "        # radam buffer for state\n",
        "        self.radam_buffer = [[None, None, None] for ind in range(10)]\n",
        "\n",
        "        # gc on or off\n",
        "        self.gc_loc = gc_loc\n",
        "        self.use_gc = use_gc\n",
        "        self.gc_conv_only = gc_conv_only\n",
        "        # level of gradient centralization\n",
        "        #self.gc_gradient_threshold = 3 if gc_conv_only else 1\n",
        "\n",
        "        # Turn on AdaBelief or Not\n",
        "        self.adabelief = adabelief\n",
        "\n",
        "        # Turn on decoupled weight decay or not\n",
        "        self.weight_decouple = weight_decouple\n",
        "\n",
        "        print(\n",
        "            f\"Ranger optimizer loaded. \\nGradient Centralization usage = {self.use_gc}\")\n",
        "        if (self.use_gc and self.gc_conv_only == False):\n",
        "            print(f\"GC applied to both conv and fc layers\")\n",
        "        elif (self.use_gc and self.gc_conv_only == True):\n",
        "            print(f\"GC applied to conv layers only\")\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        print(\"set state called\")\n",
        "        super(RangerAdaBelief, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        # note - below is commented out b/c I have other work that passes back the loss as a float, and thus not a callable closure.\n",
        "        # Uncomment if you need to use the actual closure...\n",
        "\n",
        "        # if closure is not None:\n",
        "        #loss = closure()\n",
        "\n",
        "        # Evaluate averages and grad, update param tensors\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                grad = p.grad.data.float()\n",
        "\n",
        "                if not self.weight_decouple: # if not decoupled weight decay, add weight decay to grad\n",
        "                    grad.add_(p.data * group['weight_decay'])\n",
        "\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError(\n",
        "                        'Ranger optimizer does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]  # get state dict for this param\n",
        "\n",
        "                if len(state) == 0:  # if first time to run...init dictionary with our desired entries\n",
        "                    # if self.first_run_check==0:\n",
        "                    # self.first_run_check=1\n",
        "                    #print(\"Initializing slow buffer...should not see this at load from saved model!\")\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "\n",
        "                    # look ahead weight storage now in state dict\n",
        "                    state['slow_buffer'] = torch.empty_like(p.data)\n",
        "                    state['slow_buffer'].copy_(p.data)\n",
        "\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(\n",
        "                        p_data_fp32)\n",
        "\n",
        "                # begin computations\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                # GC operation for Conv layers and FC layers\n",
        "                # if grad.dim() > self.gc_gradient_threshold:\n",
        "                #    grad.add_(-grad.mean(dim=tuple(range(1, grad.dim())), keepdim=True))\n",
        "                if self.gc_loc:\n",
        "                    grad = centralized_gradient(grad, use_gc=self.use_gc, gc_conv_only=self.gc_conv_only)\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                # compute mean moving avg\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "\n",
        "                # compute variance mov avg\n",
        "                if self.adabelief:\n",
        "                    exp_avg_sq.mul_(beta2).addcmul_(grad - exp_avg, grad - exp_avg, value=1 - beta2)\n",
        "                else:\n",
        "                    exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
        "\n",
        "                buffered = self.radam_buffer[int(state['step'] % 10)]\n",
        "\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * \\\n",
        "                        state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "                    if N_sma > self.N_sma_threshhold:\n",
        "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (\n",
        "                            N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = step_size\n",
        "\n",
        "                # if group['weight_decay'] != 0:\n",
        "                #    p_data_fp32.add_(-group['weight_decay']\n",
        "                #                     * group['lr'], p_data_fp32)\n",
        "\n",
        "                # apply lr\n",
        "                if N_sma > self.N_sma_threshhold:\n",
        "                    if self.adabelief:\n",
        "                        denom = exp_avg_sq.add_(group['eps']).sqrt().add_(group['eps'])\n",
        "                    else:\n",
        "                        denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "                    G_grad = exp_avg / denom\n",
        "                else:\n",
        "                    G_grad = exp_avg\n",
        "\n",
        "                if self.weight_decouple and (group['weight_decay'] != 0): # decoupled weight decay\n",
        "                    G_grad.add_(p_data_fp32, alpha=group['weight_decay'])\n",
        "\n",
        "                # GC operation\n",
        "                if self.gc_loc == False:\n",
        "                    G_grad = centralized_gradient(G_grad, use_gc=self.use_gc, gc_conv_only=self.gc_conv_only)\n",
        "\n",
        "                p_data_fp32.add_(G_grad, alpha=-step_size * group['lr'])\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "                # integrated look ahead...\n",
        "                # we do it at the param level instead of group level\n",
        "                if state['step'] % group['k'] == 0:\n",
        "                    # get access to slow param tensor\n",
        "                    slow_p = state['slow_buffer']\n",
        "                    # (fast weights - slow weights) * alpha\n",
        "                    slow_p.add_(p.data - slow_p, alpha=self.alpha)\n",
        "                    # copy interpolated weights to RAdam param tensor\n",
        "                    p.data.copy_(slow_p)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "7JdY3DzoDglC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Base Code"
      ],
      "metadata": {
        "id": "chpwMSBTDlfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "        in_features = input_size\n",
        "        for hidden_size in hidden_sizes:\n",
        "            self.hidden_layers.append(nn.Linear(in_features, hidden_size))\n",
        "            self.hidden_layers.append(nn.ReLU())\n",
        "            in_features = hidden_size\n",
        "        self.output_layer = nn.Linear(in_features, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = layer(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fUYQiqIoDou0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-Beats Base Code"
      ],
      "metadata": {
        "id": "Mh6eGxsZEZVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE=1\n",
        "HORIZON=1\n",
        "\n",
        "import os\n",
        "\n",
        "# Create a function to implement a ModelCheckpoint callback with a specific filename\n",
        "def create_model_checkpoint(model_name, save_path=\"model_experiments\"):\n",
        "  return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, model_name), # create filepath to save model\n",
        "                                            verbose=0, # only output a limited amount of text\n",
        "                                            save_best_only=True) # save only the best model to file"
      ],
      "metadata": {
        "id": "djUkfzplH1Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create NBeatsBlock custom layer\n",
        "class NBeatsBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, # the constructor takes all the hyperparameters for the layer\n",
        "               input_size: int,\n",
        "               theta_size: int,\n",
        "               horizon: int,\n",
        "               n_neurons: int,\n",
        "               n_layers: int,\n",
        "               **kwargs): # the **kwargs argument takes care of all of the arguments for the parent class (input_shape, trainable, name)\n",
        "    super().__init__(**kwargs)\n",
        "    self.input_size = input_size\n",
        "    self.theta_size = theta_size\n",
        "    self.horizon = horizon\n",
        "    self.n_neurons = n_neurons\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    # Block contains stack of 4 fully connected layers each has ReLU activation\n",
        "    self.hidden = [tf.keras.layers.Dense(n_neurons, activation=\"relu\") for _ in range(n_layers)]\n",
        "    # Output of block is a theta layer with linear activation\n",
        "    self.theta_layer = tf.keras.layers.Dense(theta_size, activation=\"linear\", name=\"theta\")\n",
        "\n",
        "  def call(self, inputs): # the call method is what runs when the layer is called\n",
        "    x = inputs\n",
        "    for layer in self.hidden: # pass inputs through each hidden layer\n",
        "      x = layer(x)\n",
        "    theta = self.theta_layer(x)\n",
        "    # Output the backcast and forecast from theta\n",
        "    backcast, forecast = theta[:, :self.input_size], theta[:, -self.horizon:]\n",
        "    return backcast, forecast\n",
        "\n",
        "# Set up dummy NBeatsBlock layer to represent inputs and outputs\n",
        "dummy_nbeats_block_layer = NBeatsBlock(input_size=WINDOW_SIZE,\n",
        "                                       theta_size=WINDOW_SIZE+HORIZON, # backcast + forecast\n",
        "                                       horizon=HORIZON,\n",
        "                                       n_neurons=128,\n",
        "                                       n_layers=4)\n",
        "\n",
        "\n",
        "# Create dummy inputs (have to be same size as input_size)\n",
        "dummy_inputs = tf.expand_dims(tf.range(WINDOW_SIZE) + 1, axis=0) # input shape to the model has to reflect Dense layer input requirements (ndim=2)\n",
        "print(dummy_inputs)\n",
        "\n",
        "# Pass dummy inputs to dummy NBeatsBlock layer\n",
        "backcast, forecast = dummy_nbeats_block_layer(dummy_inputs)\n",
        "# These are the activation outputs of the theta layer (they'll be random due to no training of the model)\n",
        "print(f\"Backcast: {tf.squeeze(backcast.numpy())}\")\n",
        "print(f\"Forecast: {tf.squeeze(forecast.numpy())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAzqaeQvEb2I",
        "outputId": "69c4ae14-1e80-43c1-d961-1c4a9f851550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "Backcast: -0.01372959278523922\n",
            "Forecast: -0.020774032920598984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithms without Preprocessing"
      ],
      "metadata": {
        "id": "GitytHHMwD1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.head())\n",
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "split_size = int(len(X) * 0.8)\n",
        "X_train, y_train = X_scaled[:split_size], y_scaled[:split_size]\n",
        "X_test, y_test = X_scaled[split_size:], y_scaled[split_size:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6i03jJPwQah",
        "outputId": "f7e9e80e-1660-4d1e-80aa-0616755ea73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
            "Period                                                                   \n",
            "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
            "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
            "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
            "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
            "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
            "\n",
            "            RelHum avg 2m  (pct)  2m Rain tot (in)  SolRad avg2m  (w/m^2)  \\\n",
            "Period                                                                      \n",
            "2013-10-23                  81.0              0.02             177.630005   \n",
            "2013-10-24                  75.0              0.00             146.940002   \n",
            "2013-10-25                  78.0              0.00             181.080002   \n",
            "2013-10-26                  76.0              0.00             181.639999   \n",
            "2013-10-27                  78.0              0.00             181.229996   \n",
            "\n",
            "            10m Wind avg (mph)  10m Wind min (mph)  10m Wind max (mph)  \\\n",
            "Period                                                                   \n",
            "2013-10-23                4.90                0.06           16.940001   \n",
            "2013-10-24                2.32                0.02           10.660000   \n",
            "2013-10-25                2.83                0.00           12.820000   \n",
            "2013-10-26                2.57                0.06           10.360000   \n",
            "2013-10-27                1.93                0.02           11.320000   \n",
            "\n",
            "            BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
            "Period                                            \n",
            "2013-10-23       1009.0     0.08       59.970001  \n",
            "2013-10-24       1016.0     0.10       50.910000  \n",
            "2013-10-25       1019.0     0.08       53.060001  \n",
            "2013-10-26       1018.0     0.07       50.770000  \n",
            "2013-10-27       1016.0     0.07       51.209999  \n",
            "[[-0.4032232  -0.7458762  -0.53653353 ... -0.6738904  -0.62721187\n",
            "  -0.4421828 ]\n",
            " [-1.2142386  -0.9646546  -0.9517654  ...  0.8194011  -0.18470922\n",
            "  -1.2763008 ]\n",
            " [-1.045161   -1.1638292  -0.64796025 ...  1.4593831  -0.62721187\n",
            "  -1.0783588 ]\n",
            " ...\n",
            " [ 0.8657881   1.2097985   0.6939246  ... -0.88721776 -0.18470922\n",
            "   1.0990016 ]\n",
            " [ 0.84627926  1.1651019   0.8205888  ... -0.6738904   0.2577933\n",
            "   1.0502068 ]\n",
            " [ 0.99027425  1.1690223   1.0320144  ... -0.6738904   1.3640499\n",
            "   1.093478  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with Adam"
      ],
      "metadata": {
        "id": "loKioTKCD8RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create and train the MLP model\n",
        "# Modify the hyperparameters to adjust the model architecture and training process\n",
        "for roh in range(1,21):\n",
        "  mlp = MLPRegressor(hidden_layer_sizes=(roh), activation='relu', solver='adam', max_iter=100, random_state=0)\n",
        "  mlp.fit(X_train, y_train)\n",
        "  train_predictions = mlp.predict(X_train)\n",
        "  test_predictions = mlp.predict(X_test)\n",
        "  train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
        "  test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
        "  print(roh)\n",
        "  print(\"Training RMSE:\", train_rmse)\n",
        "  print(\"Testing RMSE:\", test_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCP7bjbrwW62",
        "outputId": "c46e7b20-e964-490e-ce1f-2cd35227db7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Training RMSE: 0.9848808\n",
            "Testing RMSE: 0.79375076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Training RMSE: 0.36596215\n",
            "Testing RMSE: 0.41044065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Training RMSE: 0.32292977\n",
            "Testing RMSE: 0.37016293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "Training RMSE: 0.33134982\n",
            "Testing RMSE: 0.3716964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "Training RMSE: 0.3241821\n",
            "Testing RMSE: 0.39789635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "Training RMSE: 0.3177581\n",
            "Testing RMSE: 0.37184703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "Training RMSE: 0.32392028\n",
            "Testing RMSE: 0.402155\n",
            "8\n",
            "Training RMSE: 0.31153947\n",
            "Testing RMSE: 0.39736417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "Training RMSE: 0.31081238\n",
            "Testing RMSE: 0.37443262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Training RMSE: 0.3167272\n",
            "Testing RMSE: 0.3910427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "Training RMSE: 0.30940247\n",
            "Testing RMSE: 0.39841247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "Training RMSE: 0.31711793\n",
            "Testing RMSE: 0.41229904\n",
            "13\n",
            "Training RMSE: 0.30327082\n",
            "Testing RMSE: 0.40141007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "Training RMSE: 0.30332398\n",
            "Testing RMSE: 0.37017518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "Training RMSE: 0.3020628\n",
            "Testing RMSE: 0.37959164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "Training RMSE: 0.29524326\n",
            "Testing RMSE: 0.36904827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "Training RMSE: 0.30721182\n",
            "Testing RMSE: 0.42961964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "Training RMSE: 0.30965766\n",
            "Testing RMSE: 0.39662173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "Training RMSE: 0.30477932\n",
            "Testing RMSE: 0.3886721\n",
            "20\n",
            "Training RMSE: 0.29358694\n",
            "Testing RMSE: 0.4098198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with AdaBelief"
      ],
      "metadata": {
        "id": "BOxrjd1rEARC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your data to tensors\n",
        "inputs_train = torch.tensor(X_train, dtype=torch.float)\n",
        "labels_train = torch.tensor(y_train, dtype=torch.float)\n",
        "inputs_test = torch.tensor(X_test, dtype=torch.float)\n",
        "labels_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "test_dataset = TensorDataset(inputs_test, labels_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "for roh in range(1,21):\n",
        "  # Create ELM model\n",
        "  input_dim = inputs_train.shape[1]\n",
        "  hidden_dim = [roh]\n",
        "  output_dim = 1  # Set output_size to 1 for a single regression target\n",
        "\n",
        "  # Create an instance of the MLP model\n",
        "  model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "  # Define your loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print(\"hello\")\n",
        "  print(model.parameters())\n",
        "  # Create an instance of the AdaBelief optimizer\n",
        "  optimizer = AdaBelief(model.parameters(),lr=0.01, betas = (0.9,0.999), eps=1e-8, weight_decouple = True, rectify = False)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 100\n",
        "  best_loss = float('inf')  # Initialize with a very high loss\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      #print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
        "      # Check if current loss is the lowest so far\n",
        "      if avg_loss < best_loss:\n",
        "          best_loss = avg_loss\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "  # Load the state of the best model\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          predictions.extend(output.numpy())\n",
        "\n",
        "  predictions = np.array(predictions)\n",
        "  if roh==1:\n",
        "    labels_test = labels_test.numpy()\n",
        "  else:\n",
        "    labels_test = labels_test\n",
        "  rmse = np.sqrt(mean_squared_error(labels_test, predictions))\n",
        "  print(roh)\n",
        "  print(f\"Test RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDdh4Pz2wW9A",
        "outputId": "fd3e7a77-2963-4e66-a3e2-c242c54b6967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "<generator object Module.parameters at 0x7876929ed620>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "1\n",
            "Test RMSE: 0.42321813106536865\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929ed8c0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "2\n",
            "Test RMSE: 0.38328033685684204\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "3\n",
            "Test RMSE: 0.36680668592453003\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "4\n",
            "Test RMSE: 0.46817269921302795\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "5\n",
            "Test RMSE: 0.3685937821865082\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "6\n",
            "Test RMSE: 0.3588719367980957\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "7\n",
            "Test RMSE: 0.357048362493515\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "8\n",
            "Test RMSE: 0.3799217939376831\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "9\n",
            "Test RMSE: 0.3819767236709595\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "10\n",
            "Test RMSE: 0.3634163439273834\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "11\n",
            "Test RMSE: 0.4115660488605499\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "12\n",
            "Test RMSE: 0.3497655987739563\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "13\n",
            "Test RMSE: 0.35515841841697693\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "14\n",
            "Test RMSE: 0.481987327337265\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "15\n",
            "Test RMSE: 0.4217095375061035\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "16\n",
            "Test RMSE: 0.3965783715248108\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "17\n",
            "Test RMSE: 0.4480355978012085\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929ed8c0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "18\n",
            "Test RMSE: 0.3924518823623657\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929ed8c0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "19\n",
            "Test RMSE: 0.3967134654521942\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929ed8c0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "20\n",
            "Test RMSE: 0.4321887493133545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with RangerAdaBelief"
      ],
      "metadata": {
        "id": "oNNj9NVpEFQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your data to tensors\n",
        "inputs_train = torch.tensor(X_train, dtype=torch.float)\n",
        "labels_train = torch.tensor(y_train, dtype=torch.float)\n",
        "inputs_test = torch.tensor(X_test, dtype=torch.float)\n",
        "labels_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "test_dataset = TensorDataset(inputs_test, labels_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "for roh in range(1,21):\n",
        "  # Create ELM model\n",
        "  input_dim = inputs_train.shape[1]\n",
        "  hidden_dim = [roh]\n",
        "  output_dim = 1  # Set output_size to 1 for a single regression target\n",
        "\n",
        "  # Create an instance of the MLP model\n",
        "  model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "  # Define your loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print(\"hello\")\n",
        "  print(model.parameters())\n",
        "  # Create an instance of the AdaBelief optimizer\n",
        "  optimizer = RangerAdaBelief(model.parameters(), lr=1e-2, eps=1e-12, betas=(0.9,0.999),weight_decouple = True)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 100\n",
        "  best_loss = float('inf')  # Initialize with a very high loss\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      #print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
        "      # Check if current loss is the lowest so far\n",
        "      if avg_loss < best_loss:\n",
        "          best_loss = avg_loss\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "  # Load the state of the best model\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          predictions.extend(output.numpy())\n",
        "\n",
        "  predictions = np.array(predictions)\n",
        "  if roh==1:\n",
        "    labels_test = labels_test.numpy()\n",
        "  else:\n",
        "    labels_test = labels_test\n",
        "  rmse = np.sqrt(mean_squared_error(labels_test, predictions))\n",
        "  print(roh)\n",
        "  print(f\"Test RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrvD-F7xwXAZ",
        "outputId": "49ab20de-ad2e-4a71-99e1-41fa9052c56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "1\n",
            "Test RMSE: 0.3965911865234375\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "2\n",
            "Test RMSE: 0.44384339451789856\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "3\n",
            "Test RMSE: 0.3936100900173187\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "4\n",
            "Test RMSE: 0.41137444972991943\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "5\n",
            "Test RMSE: 0.4547647535800934\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "6\n",
            "Test RMSE: 0.4285668730735779\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "7\n",
            "Test RMSE: 0.4787379503250122\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "8\n",
            "Test RMSE: 0.41523033380508423\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "9\n",
            "Test RMSE: 0.45765310525894165\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "10\n",
            "Test RMSE: 0.45470377802848816\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "11\n",
            "Test RMSE: 0.3822126090526581\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "12\n",
            "Test RMSE: 0.4169258773326874\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "13\n",
            "Test RMSE: 0.4210951328277588\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "14\n",
            "Test RMSE: 0.4389651119709015\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "15\n",
            "Test RMSE: 0.48252302408218384\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "16\n",
            "Test RMSE: 0.357139527797699\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "17\n",
            "Test RMSE: 0.37457263469696045\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "18\n",
            "Test RMSE: 0.4336089491844177\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "19\n",
            "Test RMSE: 0.44067656993865967\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876929eda10>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "20\n",
            "Test RMSE: 0.4232686758041382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "y88aPFNdEQC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we pass our data to the Conv1D layer, we have to reshape it in order to make sure it works\n",
        "x = tf.constant(X_train)\n",
        "expand_dims_layer = layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) # add an extra dimension for timesteps\n",
        "print(f\"Original shape: {x.shape}\") # (WINDOW_SIZE)\n",
        "print(f\"Expanded shape: {expand_dims_layer(x).shape}\") # (WINDOW_SIZE, input_dim)\n",
        "print(f\"Original values with expanded shape:\\n {expand_dims_layer(x)}\")\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  # Create Lambda layer to reshape inputs, without this layer, the model will error\n",
        "  layers.Lambda(lambda x: tf.expand_dims(x, axis=1)), # resize the inputs to adjust for window size / Conv1D 3D input requirements\n",
        "  layers.Conv1D(filters=12, kernel_size=5, padding=\"causal\", activation=\"relu\"),\n",
        "  layers.Dense(HORIZON)\n",
        "], name=\"model_1_conv1D\")\n",
        "\n",
        "# Compile model\n",
        "model_1.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "# Fit model\n",
        "model_1.fit(X_train,\n",
        "            y_train,\n",
        "            batch_size=128,\n",
        "            epochs=100,\n",
        "            verbose=0,\n",
        "            validation_data=(X_test, y_test),\n",
        "            callbacks=[create_model_checkpoint(model_name=model_1.name)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_AaeGIpwXHX",
        "outputId": "a2a984d7-6b3b-4176-890e-5ca511fcc894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (2833, 13)\n",
            "Expanded shape: (2833, 1, 13)\n",
            "Original values with expanded shape:\n",
            " [[[-0.4032232  -0.7458762  -0.53653353 ... -0.6738904  -0.62721187\n",
            "   -0.4421828 ]]\n",
            "\n",
            " [[-1.2142386  -0.9646546  -0.9517654  ...  0.8194011  -0.18470922\n",
            "   -1.2763008 ]]\n",
            "\n",
            " [[-1.045161   -1.1638292  -0.64796025 ...  1.4593831  -0.62721187\n",
            "   -1.0783588 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.8657881   1.2097985   0.6939246  ... -0.88721776 -0.18470922\n",
            "    1.0990016 ]]\n",
            "\n",
            " [[ 0.84627926  1.1651019   0.8205888  ... -0.6738904   0.2577933\n",
            "    1.0502068 ]]\n",
            "\n",
            " [[ 0.99027425  1.1690223   1.0320144  ... -0.6738904   1.3640499\n",
            "    1.093478  ]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x787652d32cb0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXUDX9eHwXJd",
        "outputId": "70dca7b2-545b-4de2-8903-a94c3f36cb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1484 - root_mean_squared_error: 0.3852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1484123021364212, 0.38524317741394043]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for roh in range(1,21):\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # Let's build an LSTM model with the Functional API\n",
        "  inputs = layers.Input(shape=(13))\n",
        "  x = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(inputs) # expand input dimension to be compatible with LSTM\n",
        "  # print(x.shape)\n",
        "  # x = layers.LSTM(12, activation=\"relu\", return_sequences=True)(x) # this layer will error if the inputs are not the right shape\n",
        "  x = layers.LSTM(roh, activation=\"relu\")(x) # using the tanh loss function results in a massive error\n",
        "  # print(x.shape)\n",
        "\n",
        "\n",
        "  output = layers.Dense(HORIZON)(x)\n",
        "  model_2 = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_2_lstm\")\n",
        "\n",
        "  # Compile model\n",
        "  model_2.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  # Seems when saving the model several warnings are appearing: https://github.com/tensorflow/tensorflow/issues/47554\n",
        "  model_2.fit(X_train,\n",
        "              y_train,\n",
        "              epochs=100,\n",
        "              verbose=0,\n",
        "              batch_size=128,\n",
        "              validation_data=(X_test, y_test),\n",
        "              callbacks=[create_model_checkpoint(model_name=model_2.name)])\n",
        "  print(roh)\n",
        "  print(model_2.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCFARDTmwYBz",
        "outputId": "d509800f-2f39-4f69-b082-5f26b6c7cf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1555 - root_mean_squared_error: 0.3944\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15554165840148926, 0.39438769221305847]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N-Beats"
      ],
      "metadata": {
        "id": "cvCFo15eETCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "train_labels_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
        "\n",
        "test_features_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "test_labels_dataset = tf.data.Dataset.from_tensor_slices(y_test)\n",
        "\n",
        "# 2. Combine features & labels\n",
        "train_dataset = tf.data.Dataset.zip((train_features_dataset, train_labels_dataset))\n",
        "test_dataset = tf.data.Dataset.zip((test_features_dataset, test_labels_dataset))\n",
        "\n",
        "# 3. Batch and prefetch for optimal performance\n",
        "BATCH_SIZE = 1024 # taken from Appendix D in N-BEATS paper\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNzhU_A_wYGK",
        "outputId": "fe72888a-dca6-41a8-f0a8-52517df73c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 13), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
              " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 13), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for roh in range(1,21):\n",
        "  # Values from N-BEATS paper Figure 1 and Table 18/Appendix D\n",
        "  N_EPOCHS = 100 # called \"Iterations\" in Table 18\n",
        "  N_NEURONS = roh # called \"Width\" in Table 18\n",
        "  N_LAYERS = 2\n",
        "  N_STACKS = 1\n",
        "  INPUT_SIZE = WINDOW_SIZE * HORIZON # called \"Lookback\" in Table 18\n",
        "  THETA_SIZE = INPUT_SIZE + HORIZON\n",
        "\n",
        "  INPUT_SIZE, THETA_SIZE\n",
        "\n",
        "\n",
        "  # %%time\n",
        "\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # 1. Setup N-BEATS Block layer\n",
        "  nbeats_block_layer = NBeatsBlock(input_size=INPUT_SIZE,\n",
        "                                  theta_size=THETA_SIZE,\n",
        "                                  horizon=HORIZON,\n",
        "                                  n_neurons=N_NEURONS,\n",
        "                                  n_layers=N_LAYERS,\n",
        "                                  name=\"InitialBlock\")\n",
        "\n",
        "  # 2. Create input to stacks\n",
        "  stack_input = layers.Input(shape=(13), name=\"stack_input\")\n",
        "\n",
        "  # 3. Create initial backcast and forecast input (backwards predictions are referred to as residuals in the paper)\n",
        "  backcast, forecast = nbeats_block_layer(stack_input)\n",
        "  # Add in subtraction residual link, thank you to: https://github.com/mrdbourke/tensorflow-deep-learning/discussions/174\n",
        "  residuals = layers.subtract([stack_input, backcast], name=f\"subtract_00\")\n",
        "\n",
        "  # 4. Create stacks of blocks\n",
        "  for i, _ in enumerate(range(N_STACKS-1)): # first stack is already creted in (3)\n",
        "\n",
        "    # 5. Use the NBeatsBlock to calculate the backcast as well as block forecast\n",
        "    backcast, block_forecast = NBeatsBlock(\n",
        "        input_size=INPUT_SIZE,\n",
        "        theta_size=THETA_SIZE,\n",
        "        horizon=HORIZON,\n",
        "        n_neurons=N_NEURONS,\n",
        "        n_layers=N_LAYERS,\n",
        "        name=f\"NBeatsBlock_{i}\"\n",
        "    )(residuals) # pass it in residuals (the backcast)\n",
        "\n",
        "    # 6. Create the double residual stacking\n",
        "    residuals = layers.subtract([residuals, backcast], name=f\"subtract_{i}\")\n",
        "    forecast = layers.add([forecast, block_forecast], name=f\"add_{i}\")\n",
        "\n",
        "  # 7. Put the stack model together\n",
        "  model_3 = tf.keras.Model(inputs=stack_input,\n",
        "                          outputs=forecast,\n",
        "                          name=\"model_3_N-BEATS\")\n",
        "\n",
        "  # 8. Compile with MAE loss and Adam optimizer\n",
        "  model_3.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  # 9. Fit the model with EarlyStopping and ReduceLROnPlateau callbacks\n",
        "  model_3.fit(train_dataset,\n",
        "              epochs=N_EPOCHS,\n",
        "              validation_data=test_dataset,\n",
        "              verbose=0, # prevent large amounts of training outputs\n",
        "              # callbacks=[create_model_checkpoint(model_name=stack_model.name)] # saving model every epoch consumes far too much time\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100, verbose=1)])\n",
        "  print(roh)\n",
        "  # Evaluate N-BEATS model on the test dataset\n",
        "  model_3.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ3SQjvswYH-",
        "outputId": "7088a61a-75e6-47b5-948e-1092fe5d7377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6875 - root_mean_squared_error: 0.8291\n",
            "2\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4647 - root_mean_squared_error: 0.6817\n",
            "3\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2786 - root_mean_squared_error: 0.5279\n",
            "4\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2422 - root_mean_squared_error: 0.4921\n",
            "5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2041 - root_mean_squared_error: 0.4518\n",
            "6\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1767 - root_mean_squared_error: 0.4204\n",
            "7\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1836 - root_mean_squared_error: 0.4284\n",
            "8\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1680 - root_mean_squared_error: 0.4098\n",
            "9\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1737 - root_mean_squared_error: 0.4167\n",
            "10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1491 - root_mean_squared_error: 0.3861\n",
            "11\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1647 - root_mean_squared_error: 0.4058\n",
            "12\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1457 - root_mean_squared_error: 0.3817\n",
            "13\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1526 - root_mean_squared_error: 0.3906\n",
            "14\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1447 - root_mean_squared_error: 0.3804\n",
            "15\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1393 - root_mean_squared_error: 0.3732\n",
            "16\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1554 - root_mean_squared_error: 0.3943\n",
            "17\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1375 - root_mean_squared_error: 0.3709\n",
            "18\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1493 - root_mean_squared_error: 0.3864\n",
            "19\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1340 - root_mean_squared_error: 0.3661\n",
            "20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1313 - root_mean_squared_error: 0.3623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stability Selection with Randomized Lasso Regression"
      ],
      "metadata": {
        "id": "FihSk2DSSy2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "bFwKKv8fRY2Q",
        "outputId": "6e531fdf-fffa-4bc9-cc1d-a98bf8bcddaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  Tsoil avg-10cm  (F)  \\\n",
              "Period                                                                      \n",
              "2013-10-23         64.54         49.50         74.88                75.06   \n",
              "2013-10-24         55.81         46.71         70.52                70.90   \n",
              "2013-10-25         57.63         44.17         73.71                69.71   \n",
              "2013-10-26         55.54         43.03         72.10                69.17   \n",
              "2013-10-27         56.08         41.13         74.44                68.75   \n",
              "...                  ...           ...           ...                  ...   \n",
              "2023-07-04         82.29         72.63         96.03                82.89   \n",
              "2023-07-05         83.59         73.24         93.70                82.56   \n",
              "2023-07-06         82.61         75.49         93.33                82.51   \n",
              "2023-07-07         80.43         73.02         93.65                81.79   \n",
              "2023-07-08         81.38         73.06         92.86                79.88   \n",
              "\n",
              "            Tsoil min(avg)-10cm  (F)  Tsoil max(avg)-10cm  (F)  \\\n",
              "Period                                                           \n",
              "2013-10-23                     72.81                     76.64   \n",
              "2013-10-24                     69.15                     72.68   \n",
              "2013-10-25                     67.19                     72.41   \n",
              "2013-10-26                     66.58                     71.98   \n",
              "2013-10-27                     65.97                     71.64   \n",
              "...                              ...                       ...   \n",
              "2023-07-04                     79.41                     86.88   \n",
              "2023-07-05                     79.27                     85.78   \n",
              "2023-07-06                     79.95                     85.91   \n",
              "2023-07-07                     78.75                     85.01   \n",
              "2023-07-08                     76.62                     83.93   \n",
              "\n",
              "            2m DewPt avg (F)  RelHum avg 2m  (pct)  2m Rain tot (in)  \\\n",
              "Period                                                                 \n",
              "2013-10-23             57.11                  81.0              0.02   \n",
              "2013-10-24             46.72                  75.0              0.00   \n",
              "2013-10-25             49.45                  78.0              0.00   \n",
              "2013-10-26             46.68                  76.0              0.00   \n",
              "2013-10-27             47.10                  78.0              0.00   \n",
              "...                      ...                   ...               ...   \n",
              "2023-07-04             74.57                  80.0              0.04   \n",
              "2023-07-05             75.47                  78.0              0.00   \n",
              "2023-07-06             76.08                  82.0              0.00   \n",
              "2023-07-07             74.57                  83.0              3.55   \n",
              "2023-07-08             75.19                  83.0              0.01   \n",
              "\n",
              "            SolRad avg2m  (w/m^2)  10m Wind avg (mph)  10m Wind min (mph)  \\\n",
              "Period                                                                      \n",
              "2013-10-23                 177.63                4.90                0.06   \n",
              "2013-10-24                 146.94                2.32                0.02   \n",
              "2013-10-25                 181.08                2.83                0.00   \n",
              "2013-10-26                 181.64                2.57                0.06   \n",
              "2013-10-27                 181.23                1.93                0.02   \n",
              "...                           ...                 ...                 ...   \n",
              "2023-07-04                 279.92                3.02                0.05   \n",
              "2023-07-05                 250.34                3.21                0.00   \n",
              "2023-07-06                 223.97                3.62                0.02   \n",
              "2023-07-07                 213.76                4.53                0.00   \n",
              "2023-07-08                 277.76                4.61                0.02   \n",
              "\n",
              "            10m Wind max (mph)  BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
              "Period                                                                \n",
              "2013-10-23               16.94         1009     0.08           59.97  \n",
              "2013-10-24               10.66         1016     0.10           50.91  \n",
              "2013-10-25               12.82         1019     0.08           53.06  \n",
              "2013-10-26               10.36         1018     0.07           50.77  \n",
              "2013-10-27               11.32         1016     0.07           51.21  \n",
              "...                        ...          ...      ...             ...  \n",
              "2023-07-04               25.05         1015     0.21           76.66  \n",
              "2023-07-05               13.58         1015     0.19           77.62  \n",
              "2023-07-06               15.75         1013     0.18           77.80  \n",
              "2023-07-07               40.15         1011     0.17           76.16  \n",
              "2023-07-08               23.71         1011     0.20           76.85  \n",
              "\n",
              "[3542 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-4b182777-11b4-4f8b-abc9-2c8ccc68e51d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>Tsoil avg-10cm  (F)</th>\n",
              "      <th>Tsoil min(avg)-10cm  (F)</th>\n",
              "      <th>Tsoil max(avg)-10cm  (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>RelHum avg 2m  (pct)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>SolRad avg2m  (w/m^2)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>10m Wind min (mph)</th>\n",
              "      <th>10m Wind max (mph)</th>\n",
              "      <th>BP avg (mb)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.54</td>\n",
              "      <td>49.50</td>\n",
              "      <td>74.88</td>\n",
              "      <td>75.06</td>\n",
              "      <td>72.81</td>\n",
              "      <td>76.64</td>\n",
              "      <td>57.11</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>177.63</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.94</td>\n",
              "      <td>1009</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.81</td>\n",
              "      <td>46.71</td>\n",
              "      <td>70.52</td>\n",
              "      <td>70.90</td>\n",
              "      <td>69.15</td>\n",
              "      <td>72.68</td>\n",
              "      <td>46.72</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>146.94</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.66</td>\n",
              "      <td>1016</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.63</td>\n",
              "      <td>44.17</td>\n",
              "      <td>73.71</td>\n",
              "      <td>69.71</td>\n",
              "      <td>67.19</td>\n",
              "      <td>72.41</td>\n",
              "      <td>49.45</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.08</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.82</td>\n",
              "      <td>1019</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.54</td>\n",
              "      <td>43.03</td>\n",
              "      <td>72.10</td>\n",
              "      <td>69.17</td>\n",
              "      <td>66.58</td>\n",
              "      <td>71.98</td>\n",
              "      <td>46.68</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.64</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10.36</td>\n",
              "      <td>1018</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.08</td>\n",
              "      <td>41.13</td>\n",
              "      <td>74.44</td>\n",
              "      <td>68.75</td>\n",
              "      <td>65.97</td>\n",
              "      <td>71.64</td>\n",
              "      <td>47.10</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.23</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.32</td>\n",
              "      <td>1016</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-04</th>\n",
              "      <td>82.29</td>\n",
              "      <td>72.63</td>\n",
              "      <td>96.03</td>\n",
              "      <td>82.89</td>\n",
              "      <td>79.41</td>\n",
              "      <td>86.88</td>\n",
              "      <td>74.57</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.04</td>\n",
              "      <td>279.92</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>25.05</td>\n",
              "      <td>1015</td>\n",
              "      <td>0.21</td>\n",
              "      <td>76.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>83.59</td>\n",
              "      <td>73.24</td>\n",
              "      <td>93.70</td>\n",
              "      <td>82.56</td>\n",
              "      <td>79.27</td>\n",
              "      <td>85.78</td>\n",
              "      <td>75.47</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>250.34</td>\n",
              "      <td>3.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.58</td>\n",
              "      <td>1015</td>\n",
              "      <td>0.19</td>\n",
              "      <td>77.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>82.61</td>\n",
              "      <td>75.49</td>\n",
              "      <td>93.33</td>\n",
              "      <td>82.51</td>\n",
              "      <td>79.95</td>\n",
              "      <td>85.91</td>\n",
              "      <td>76.08</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>223.97</td>\n",
              "      <td>3.62</td>\n",
              "      <td>0.02</td>\n",
              "      <td>15.75</td>\n",
              "      <td>1013</td>\n",
              "      <td>0.18</td>\n",
              "      <td>77.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>80.43</td>\n",
              "      <td>73.02</td>\n",
              "      <td>93.65</td>\n",
              "      <td>81.79</td>\n",
              "      <td>78.75</td>\n",
              "      <td>85.01</td>\n",
              "      <td>74.57</td>\n",
              "      <td>83.0</td>\n",
              "      <td>3.55</td>\n",
              "      <td>213.76</td>\n",
              "      <td>4.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>40.15</td>\n",
              "      <td>1011</td>\n",
              "      <td>0.17</td>\n",
              "      <td>76.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-08</th>\n",
              "      <td>81.38</td>\n",
              "      <td>73.06</td>\n",
              "      <td>92.86</td>\n",
              "      <td>79.88</td>\n",
              "      <td>76.62</td>\n",
              "      <td>83.93</td>\n",
              "      <td>75.19</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>277.76</td>\n",
              "      <td>4.61</td>\n",
              "      <td>0.02</td>\n",
              "      <td>23.71</td>\n",
              "      <td>1011</td>\n",
              "      <td>0.20</td>\n",
              "      <td>76.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3542 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b182777-11b4-4f8b-abc9-2c8ccc68e51d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-ff1ae63c-0874-4646-a902-30461c158364\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff1ae63c-0874-4646-a902-30461c158364')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-ff1ae63c-0874-4646-a902-30461c158364 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b182777-11b4-4f8b-abc9-2c8ccc68e51d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b182777-11b4-4f8b-abc9-2c8ccc68e51d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "jVDJvfBARY4T",
        "outputId": "01f1c94a-43e7-47c0-aee7-71b80f095a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
              "Period                                                                   \n",
              "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
              "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
              "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
              "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
              "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
              "\n",
              "            RelHum avg 2m  (pct)  2m Rain tot (in)  SolRad avg2m  (w/m^2)  \\\n",
              "Period                                                                      \n",
              "2013-10-23                  81.0              0.02             177.630005   \n",
              "2013-10-24                  75.0              0.00             146.940002   \n",
              "2013-10-25                  78.0              0.00             181.080002   \n",
              "2013-10-26                  76.0              0.00             181.639999   \n",
              "2013-10-27                  78.0              0.00             181.229996   \n",
              "\n",
              "            10m Wind avg (mph)  10m Wind min (mph)  10m Wind max (mph)  \\\n",
              "Period                                                                   \n",
              "2013-10-23                4.90                0.06           16.940001   \n",
              "2013-10-24                2.32                0.02           10.660000   \n",
              "2013-10-25                2.83                0.00           12.820000   \n",
              "2013-10-26                2.57                0.06           10.360000   \n",
              "2013-10-27                1.93                0.02           11.320000   \n",
              "\n",
              "            BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
              "Period                                            \n",
              "2013-10-23       1009.0     0.08       59.970001  \n",
              "2013-10-24       1016.0     0.10       50.910000  \n",
              "2013-10-25       1019.0     0.08       53.060001  \n",
              "2013-10-26       1018.0     0.07       50.770000  \n",
              "2013-10-27       1016.0     0.07       51.209999  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-e4afe9c4-4cdc-45f2-b22a-7de5c0b35f03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>RelHum avg 2m  (pct)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>SolRad avg2m  (w/m^2)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>10m Wind min (mph)</th>\n",
              "      <th>10m Wind max (mph)</th>\n",
              "      <th>BP avg (mb)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.540001</td>\n",
              "      <td>49.500000</td>\n",
              "      <td>74.879997</td>\n",
              "      <td>57.110001</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>177.630005</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.940001</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.810001</td>\n",
              "      <td>46.709999</td>\n",
              "      <td>70.519997</td>\n",
              "      <td>46.720001</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>146.940002</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.660000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.630001</td>\n",
              "      <td>44.169998</td>\n",
              "      <td>73.709999</td>\n",
              "      <td>49.450001</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.080002</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.820000</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.060001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.540001</td>\n",
              "      <td>43.029999</td>\n",
              "      <td>72.099998</td>\n",
              "      <td>46.680000</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.639999</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10.360000</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.080002</td>\n",
              "      <td>41.130001</td>\n",
              "      <td>74.440002</td>\n",
              "      <td>47.099998</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.229996</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.320000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.209999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4afe9c4-4cdc-45f2-b22a-7de5c0b35f03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-de04ebc8-3be1-44d3-a3d5-26e5e5f60b0f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de04ebc8-3be1-44d3-a3d5-26e5e5f60b0f')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-de04ebc8-3be1-44d3-a3d5-26e5e5f60b0f button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4afe9c4-4cdc-45f2-b22a-7de5c0b35f03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4afe9c4-4cdc-45f2-b22a-7de5c0b35f03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxpNwLxdRY6Z",
        "outputId": "d3f6c9a5-9c00-47ff-e410-462fb4fad722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Period\n",
              "2013-10-23    75.059998\n",
              "2013-10-24    70.900002\n",
              "2013-10-25    69.709999\n",
              "2013-10-26    69.169998\n",
              "2013-10-27    68.750000\n",
              "Name: Tsoil avg-10cm  (F), dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "beuOexPlR6oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.utils.random import sample_without_replacement\n",
        "from sklearn.utils.multiclass import type_of_target\n",
        "\n",
        "\n",
        "__all__ = [\n",
        "    'bootstrap_without_replacement',\n",
        "    'complementary_pairs_bootstrap',\n",
        "    'stratified_bootstrap'\n",
        "]\n",
        "\n",
        "\n",
        "def bootstrap_without_replacement(y, n_subsamples, random_state=None):\n",
        "\n",
        "    n_samples = y.shape[0]\n",
        "    return sample_without_replacement(n_samples, n_subsamples,\n",
        "                                      random_state=random_state)\n",
        "\n",
        "\n",
        "def complementary_pairs_bootstrap(y, n_subsamples, random_state=None):\n",
        "\n",
        "    n_samples = y.shape[0]\n",
        "    subsample = bootstrap_without_replacement(y, n_subsamples, random_state)\n",
        "    complementary_subsample = np.setdiff1d(np.arange(n_samples), subsample)\n",
        "\n",
        "    return subsample, complementary_subsample\n",
        "\n",
        "\n",
        "def stratified_bootstrap(y, n_subsamples, random_state=None):\n",
        "\n",
        "    type_of_target_y = type_of_target(y)\n",
        "    allowed_target_types = ('binary', 'multiclass')\n",
        "    if type_of_target_y not in allowed_target_types:\n",
        "        raise ValueError(\n",
        "            'Supported target types are: {}. Got {!r} instead.'.format(\n",
        "                allowed_target_types, type_of_target_y))\n",
        "\n",
        "    unique_y, y_counts = np.unique(y, return_counts=True)\n",
        "    y_counts_relative = y_counts / y_counts.sum()\n",
        "    y_n_samples = np.int32(np.round(y_counts_relative * n_subsamples))\n",
        "\n",
        "    # the above should return grouped subsamples which approximately sum up\n",
        "    # to n_subsamples but may not work out exactly due to rounding errors.\n",
        "    # If this is the case, adjust the count of the largest class\n",
        "    if y_n_samples.sum() != n_subsamples:\n",
        "        delta = n_subsamples - y_n_samples.sum()\n",
        "        majority_class = np.argmax(y_counts)\n",
        "        y_n_samples[majority_class] += delta\n",
        "\n",
        "    all_selected = np.array([], dtype=np.int32)\n",
        "    for i, u in enumerate(unique_y):\n",
        "        indices = np.where(y == u)[0]\n",
        "        selected_indices = indices[bootstrap_without_replacement(indices,\n",
        "                                                                 y_n_samples[i],\n",
        "                                                                 random_state)]\n",
        "        all_selected = np.concatenate((all_selected, selected_indices))\n",
        "\n",
        "    return all_selected"
      ],
      "metadata": {
        "id": "saylDMt_Hqpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy import sparse\n",
        "from scipy.sparse import issparse\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Lasso\n",
        "#from sklearn.linear_model.base import _preprocess_data\n",
        "from sklearn.utils import check_X_y, check_random_state\n",
        "\n",
        "__all__ = ['RandomizedLogisticRegression', 'RandomizedLasso']\n",
        "\n",
        "\n",
        "def _rescale_data(X, weights):\n",
        "    if issparse(X):\n",
        "        size = weights.shape[0]\n",
        "        weight_dia = sparse.dia_matrix((1 - weights, 0), (size, size))\n",
        "        X_rescaled = X * weight_dia\n",
        "    else:\n",
        "        X_rescaled = X * (1 - weights)\n",
        "\n",
        "    return X_rescaled\n",
        "\n",
        "\n",
        "class RandomizedLogisticRegression(LogisticRegression):\n",
        "\n",
        "    def __init__(self, weakness=0.5, tol=1e-4, C=1.0,\n",
        "                 fit_intercept=True, intercept_scaling=1, class_weight=None,\n",
        "                 random_state=None, solver='liblinear', max_iter=100,\n",
        "                 multi_class='ovr', verbose=0, warm_start=False, n_jobs=1):\n",
        "        self.weakness = weakness\n",
        "        super(RandomizedLogisticRegression, self).__init__(\n",
        "            penalty='l1', dual=False, tol=tol, C=C, fit_intercept=fit_intercept,\n",
        "            intercept_scaling=intercept_scaling, class_weight=class_weight,\n",
        "            random_state=random_state, solver=solver, max_iter=max_iter,\n",
        "            multi_class=multi_class, verbose=verbose, warm_start=warm_start,\n",
        "            n_jobs=n_jobs)\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "\n",
        "        if not isinstance(self.weakness, float) or not (0.0 < self.weakness <= 1.0):\n",
        "            raise ValueError('weakness should be a float in (0, 1], got %s' % self.weakness)\n",
        "\n",
        "        X, y = check_X_y(X, y, accept_sparse='csr', dtype=[np.float64, np.float32],\n",
        "                         order=\"C\")\n",
        "\n",
        "        n_features = X.shape[1]\n",
        "        weakness = 1. - self.weakness\n",
        "        random_state = check_random_state(self.random_state)\n",
        "\n",
        "        weights = weakness * random_state.randint(0, 1 + 1, size=(n_features,))\n",
        "        X_rescaled = _rescale_data(X, weights)\n",
        "        return super(RandomizedLogisticRegression, self).fit(X_rescaled, y, sample_weight)\n",
        "\n",
        "\n",
        "class RandomizedLasso(Lasso):\n",
        "\n",
        "    def __init__(self, weakness=0.5, alpha=1.0, fit_intercept=True,\n",
        "                 precompute=False, copy_X=True, max_iter=1000,\n",
        "                 tol=1e-4, warm_start=False, positive=False,\n",
        "                 random_state=None, selection='cyclic'):\n",
        "        self.weakness = weakness\n",
        "        super(RandomizedLasso, self).__init__(\n",
        "            alpha=alpha, fit_intercept=fit_intercept,\n",
        "            precompute=precompute, copy_X=copy_X,\n",
        "            max_iter=max_iter, tol=tol, warm_start=warm_start,\n",
        "            positive=positive, random_state=random_state,\n",
        "            selection=selection)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        if not isinstance(self.weakness, float) or not (0.0 < self.weakness <= 1.0):\n",
        "            raise ValueError('weakness should be a float in (0, 1], got %s' % self.weakness)\n",
        "\n",
        "        X, y = check_X_y(X, y, accept_sparse=True)\n",
        "\n",
        "        n_features = X.shape[1]\n",
        "        weakness = 1. - self.weakness\n",
        "        random_state = check_random_state(self.random_state)\n",
        "\n",
        "        weights = weakness * random_state.randint(0, 1 + 1, size=(n_features,))\n",
        "\n",
        "        # TODO: I am afraid this will do double normalization if set to true\n",
        "        #X, y, _, _ = _preprocess_data(X, y, self.fit_intercept, normalize=self.normalize, copy=False,\n",
        "        #             sample_weight=None, return_mean=False)\n",
        "\n",
        "        # TODO: Check if this is a problem if it happens before standardization\n",
        "        X_rescaled = _rescale_data(X, weights)\n",
        "        return super(RandomizedLasso, self).fit(X_rescaled, y)"
      ],
      "metadata": {
        "id": "HqDLc1mdMeuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from warnings import warn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
        "#from sklearn.externals.joblib import Parallel, delayed\n",
        "from sklearn.utils.parallel import Parallel\n",
        "from sklearn.utils.parallel import delayed\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import check_array, check_random_state, check_X_y, safe_mask\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "\n",
        "__all__ = ['StabilitySelection', 'plot_stability_path']\n",
        "\n",
        "BOOTSTRAP_FUNC_MAPPING = {\n",
        "    'subsample': bootstrap_without_replacement,\n",
        "    'complementary_pairs': complementary_pairs_bootstrap,\n",
        "    'stratified': stratified_bootstrap\n",
        "}\n",
        "\n",
        "\n",
        "def _return_estimator_from_pipeline(pipeline):\n",
        "    \"\"\"Returns the final estimator in a Pipeline, or the estimator\n",
        "    if it is not\"\"\"\n",
        "    if isinstance(pipeline, Pipeline):\n",
        "        return pipeline._final_estimator\n",
        "    else:\n",
        "        return pipeline\n",
        "\n",
        "\n",
        "def _bootstrap_generator(n_bootstrap_iterations, bootstrap_func, y,\n",
        "                         n_subsamples, random_state=None):\n",
        "    for _ in range(n_bootstrap_iterations):\n",
        "        subsample = bootstrap_func(y, n_subsamples, random_state)\n",
        "        if isinstance(subsample, tuple):\n",
        "            for item in subsample:\n",
        "                yield item\n",
        "        else:\n",
        "            yield subsample\n",
        "\n",
        "\n",
        "def _fit_bootstrap_sample(base_estimator, X, y, lambda_name, lambda_value,\n",
        "                          threshold=None):\n",
        "\n",
        "\n",
        "    base_estimator.set_params(**{lambda_name: lambda_value})\n",
        "    base_estimator.fit(X, y)\n",
        "\n",
        "    # TODO: Reconsider if we really want to use SelectFromModel here or not\n",
        "    selector_model = _return_estimator_from_pipeline(base_estimator)\n",
        "    variable_selector = SelectFromModel(estimator=selector_model,\n",
        "                                        threshold=threshold,\n",
        "                                        prefit=True)\n",
        "    return variable_selector.get_support()\n",
        "\n",
        "\n",
        "def plot_stability_path(stability_selection, threshold_highlight=None,\n",
        "                        **kwargs):\n",
        "\n",
        "    check_is_fitted(stability_selection, 'stability_scores_')\n",
        "\n",
        "    threshold = stability_selection.threshold if threshold_highlight is None else threshold_highlight\n",
        "    paths_to_highlight = stability_selection.get_support(threshold=threshold)\n",
        "\n",
        "    x_grid = stability_selection.lambda_grid / np.max(stability_selection.lambda_grid)\n",
        "    print(type(x_grid))\n",
        "    fig, ax = plt.subplots(1, 1, **kwargs)\n",
        "    if not paths_to_highlight.all():\n",
        "        ax.plot(x_grid[::-1], stability_selection.stability_scores_[~paths_to_highlight].T,\n",
        "                'k:', linewidth=0.5)\n",
        "\n",
        "    if paths_to_highlight.any():\n",
        "        ax.plot(x_grid[::-1], stability_selection.stability_scores_[paths_to_highlight].T,\n",
        "                'r-', linewidth=0.5)\n",
        "\n",
        "    if threshold is not None:\n",
        "        ax.plot(x_grid[::-1], threshold * np.ones_like(stability_selection.lambda_grid),\n",
        "                'b--', linewidth=0.5)\n",
        "\n",
        "    ax.set_ylabel('Stability score')\n",
        "    ax.set_xlabel('Lambda / max(Lambda)')\n",
        "\n",
        "    fig.tight_layout()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "class StabilitySelection(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, base_estimator=LogisticRegression(penalty='l2'), lambda_name='C',\n",
        "                 lambda_grid=np.logspace(-5, -2, 25), n_bootstrap_iterations=100,\n",
        "                 sample_fraction=0.5, threshold=0.6, bootstrap_func=bootstrap_without_replacement,\n",
        "                 bootstrap_threshold=None, verbose=0, n_jobs=1, pre_dispatch='2*n_jobs',\n",
        "                 random_state=None):\n",
        "        self.base_estimator = base_estimator\n",
        "        self.lambda_name = lambda_name\n",
        "        self.lambda_grid = lambda_grid\n",
        "        self.n_bootstrap_iterations = n_bootstrap_iterations\n",
        "        self.sample_fraction = sample_fraction\n",
        "        self.threshold = threshold\n",
        "        self.bootstrap_func = bootstrap_func\n",
        "        self.bootstrap_threshold = bootstrap_threshold\n",
        "        self.verbose = verbose\n",
        "        self.n_jobs = n_jobs\n",
        "        self.pre_dispatch = pre_dispatch\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def _validate_input(self):\n",
        "        if not isinstance(self.n_bootstrap_iterations, int) or self.n_bootstrap_iterations <= 0:\n",
        "            raise ValueError('n_bootstrap_iterations should be a positive integer, got %s' %\n",
        "                             self.n_bootstrap_iterations)\n",
        "\n",
        "        if not isinstance(self.sample_fraction, float) or not (0.0 < self.sample_fraction <= 1.0):\n",
        "            raise ValueError('sample_fraction should be a float in (0, 1], got %s' % self.sample_fraction)\n",
        "\n",
        "        if not isinstance(self.threshold, float) or not (0.0 < self.threshold <= 1.0):\n",
        "            raise ValueError('threshold should be a float in (0, 1], got %s' % self.threshold)\n",
        "\n",
        "        if self.lambda_name not in self.base_estimator.get_params().keys():\n",
        "            raise ValueError('lambda_name is set to %s, but base_estimator %s '\n",
        "                             'does not have a parameter '\n",
        "                             'with that name' % (self.lambda_name,\n",
        "                                                 self.base_estimator.__class__.__name__))\n",
        "\n",
        "        if isinstance(self.bootstrap_func, str):\n",
        "            if self.bootstrap_func not in BOOTSTRAP_FUNC_MAPPING.keys():\n",
        "                raise ValueError('bootstrap_func is set to %s, but must be one of '\n",
        "                                 '%s or a callable' %\n",
        "                                 (self.bootstrap_func, BOOTSTRAP_FUNC_MAPPING.keys()))\n",
        "\n",
        "            self.bootstrap_func = BOOTSTRAP_FUNC_MAPPING[self.bootstrap_func]\n",
        "        elif not callable(self.bootstrap_func):\n",
        "            raise ValueError('bootstrap_func must be one of %s or a callable' %\n",
        "                             BOOTSTRAP_FUNC_MAPPING.keys())\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "\n",
        "        self._validate_input()\n",
        "\n",
        "        X, y = check_X_y(X, y, accept_sparse='csr')\n",
        "\n",
        "        n_samples, n_variables = X.shape\n",
        "        n_subsamples = np.floor(self.sample_fraction * n_samples).astype(int)\n",
        "        n_lambdas = self.lambda_grid.shape[0]\n",
        "\n",
        "        base_estimator = clone(self.base_estimator)\n",
        "        random_state = check_random_state(self.random_state)\n",
        "        stability_scores = np.zeros((n_variables, n_lambdas))\n",
        "\n",
        "        for idx, lambda_value in enumerate(self.lambda_grid):\n",
        "            if self.verbose > 0:\n",
        "                print(\"Fitting estimator for lambda = %.5f (%d / %d) on %d bootstrap samples\" %\n",
        "                      (lambda_value, idx + 1, n_lambdas, self.n_bootstrap_iterations))\n",
        "\n",
        "            bootstrap_samples = _bootstrap_generator(self.n_bootstrap_iterations,\n",
        "                                                     self.bootstrap_func, y,\n",
        "                                                     n_subsamples, random_state=random_state)\n",
        "\n",
        "            selected_variables = Parallel(\n",
        "                n_jobs=self.n_jobs, verbose=self.verbose,\n",
        "                pre_dispatch=self.pre_dispatch\n",
        "            )(delayed(_fit_bootstrap_sample)(clone(base_estimator),\n",
        "                                             X=X[safe_mask(X, subsample), :],\n",
        "                                             y=y[subsample],\n",
        "                                             lambda_name=self.lambda_name,\n",
        "                                             lambda_value=lambda_value,\n",
        "                                             threshold=self.bootstrap_threshold)\n",
        "              for subsample in bootstrap_samples)\n",
        "\n",
        "            stability_scores[:, idx] = np.vstack(selected_variables).mean(axis=0)\n",
        "\n",
        "        self.stability_scores_ = stability_scores\n",
        "        return self\n",
        "\n",
        "    def get_support(self, indices=False, threshold=None):\n",
        "\n",
        "\n",
        "        if threshold is not None and (not isinstance(threshold, float)\n",
        "                                      or not (0.0 < threshold <= 1.0)):\n",
        "            raise ValueError('threshold should be a float in (0, 1], '\n",
        "                             'got %s' % self.threshold)\n",
        "\n",
        "        cutoff = self.threshold if threshold is None else threshold\n",
        "        mask = (self.stability_scores_.max(axis=1) > cutoff)\n",
        "\n",
        "        return mask if not indices else np.where(mask)[0]\n",
        "\n",
        "    def transform(self, X, threshold=None):\n",
        "\n",
        "        X = check_array(X, accept_sparse='csr')\n",
        "        mask = self.get_support(threshold=threshold)\n",
        "\n",
        "        check_is_fitted(self, 'stability_scores_')\n",
        "\n",
        "        if len(mask) != X.shape[1]:\n",
        "            raise ValueError(\"X has a different shape than during fitting.\")\n",
        "\n",
        "        if not mask.any():\n",
        "            warn(\"No features were selected: either the data is\"\n",
        "                 \" too noisy or the selection test too strict.\",\n",
        "                 UserWarning)\n",
        "            return np.empty(0).reshape((X.shape[0], 0))\n",
        "\n",
        "        return X[:, safe_mask(X, mask)]"
      ],
      "metadata": {
        "id": "JMLeuoB4HqVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_estimator = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', RandomizedLasso(weakness=0.2))\n",
        "    ])\n",
        "selector = StabilitySelection(base_estimator=base_estimator, lambda_name='model__alpha',threshold=0.6,lambda_grid=np.logspace(-1, 1, num=100))\n",
        "result=selector.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ufo2V-CMp3O",
        "outputId": "1a8f1ac2-50c2-4fa8-f99f-be1816f080b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.313e+01, tolerance: 1.481e+01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e+01, tolerance: 1.475e+01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.493e+01, tolerance: 1.481e+01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.859e+01, tolerance: 1.474e+01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plot_stability_path(result)\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "t6kLkVuRMqW1",
        "outputId": "2b7b2c9d-91ca-4d23-dbae-28c2ddc300f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_variables = result.get_support(indices=True)\n",
        "selected_scores = result.stability_scores_.max(axis=1)\n",
        "print(selected_variables)\n",
        "print('Selected variables are:')\n",
        "print('-----------------------')\n",
        "\n",
        "for idx, (variable, score) in enumerate(zip(selected_variables, selected_scores[selected_variables])):\n",
        "    print('Variable %d: [%d], score %.3f' % (idx + 1, variable, score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzqV2ifCMqZD",
        "outputId": "1f1d7b5a-1e2c-46a8-f15f-154d3811aa7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  5  7 11]\n",
            "Selected variables are:\n",
            "-----------------------\n",
            "Variable 1: [0], score 0.640\n",
            "Variable 2: [1], score 0.630\n",
            "Variable 3: [5], score 0.630\n",
            "Variable 4: [7], score 0.890\n",
            "Variable 5: [11], score 0.810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "zbSueC3eUKku",
        "outputId": "b0f99ee1-b70f-4527-9816-c41504372227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
              "Period                                                                   \n",
              "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
              "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
              "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
              "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
              "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
              "\n",
              "            RelHum avg 2m  (pct)  2m Rain tot (in)  SolRad avg2m  (w/m^2)  \\\n",
              "Period                                                                      \n",
              "2013-10-23                  81.0              0.02             177.630005   \n",
              "2013-10-24                  75.0              0.00             146.940002   \n",
              "2013-10-25                  78.0              0.00             181.080002   \n",
              "2013-10-26                  76.0              0.00             181.639999   \n",
              "2013-10-27                  78.0              0.00             181.229996   \n",
              "\n",
              "            10m Wind avg (mph)  10m Wind min (mph)  10m Wind max (mph)  \\\n",
              "Period                                                                   \n",
              "2013-10-23                4.90                0.06           16.940001   \n",
              "2013-10-24                2.32                0.02           10.660000   \n",
              "2013-10-25                2.83                0.00           12.820000   \n",
              "2013-10-26                2.57                0.06           10.360000   \n",
              "2013-10-27                1.93                0.02           11.320000   \n",
              "\n",
              "            BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
              "Period                                            \n",
              "2013-10-23       1009.0     0.08       59.970001  \n",
              "2013-10-24       1016.0     0.10       50.910000  \n",
              "2013-10-25       1019.0     0.08       53.060001  \n",
              "2013-10-26       1018.0     0.07       50.770000  \n",
              "2013-10-27       1016.0     0.07       51.209999  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-fbd05aa8-d512-4b9e-8d03-7633e3c6bfb9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>RelHum avg 2m  (pct)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>SolRad avg2m  (w/m^2)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>10m Wind min (mph)</th>\n",
              "      <th>10m Wind max (mph)</th>\n",
              "      <th>BP avg (mb)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.540001</td>\n",
              "      <td>49.500000</td>\n",
              "      <td>74.879997</td>\n",
              "      <td>57.110001</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>177.630005</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.940001</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.810001</td>\n",
              "      <td>46.709999</td>\n",
              "      <td>70.519997</td>\n",
              "      <td>46.720001</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>146.940002</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.660000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.630001</td>\n",
              "      <td>44.169998</td>\n",
              "      <td>73.709999</td>\n",
              "      <td>49.450001</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.080002</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.820000</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.060001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.540001</td>\n",
              "      <td>43.029999</td>\n",
              "      <td>72.099998</td>\n",
              "      <td>46.680000</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.639999</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10.360000</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.080002</td>\n",
              "      <td>41.130001</td>\n",
              "      <td>74.440002</td>\n",
              "      <td>47.099998</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.229996</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.320000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.209999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbd05aa8-d512-4b9e-8d03-7633e3c6bfb9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-211eec36-b0ee-4c4c-9a90-1cd5e9ca980d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-211eec36-b0ee-4c4c-9a90-1cd5e9ca980d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-211eec36-b0ee-4c4c-9a90-1cd5e9ca980d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbd05aa8-d512-4b9e-8d03-7633e3c6bfb9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbd05aa8-d512-4b9e-8d03-7633e3c6bfb9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[X.columns[[0,1,5,7,11]]]"
      ],
      "metadata": {
        "id": "YJABg2jyUKmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "JCUFBFl9UKpH",
        "outputId": "fb693613-fd16-4949-8157-ab9f445b5673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m Rain tot (in)  10m Wind avg (mph)  \\\n",
              "Period                                                                         \n",
              "2013-10-23     64.540001     49.500000              0.02                4.90   \n",
              "2013-10-24     55.810001     46.709999              0.00                2.32   \n",
              "2013-10-25     57.630001     44.169998              0.00                2.83   \n",
              "2013-10-26     55.540001     43.029999              0.00                2.57   \n",
              "2013-10-27     56.080002     41.130001              0.00                1.93   \n",
              "...                  ...           ...               ...                 ...   \n",
              "2023-07-04     82.290001     72.629997              0.04                3.02   \n",
              "2023-07-05     83.589996     73.239998              0.00                3.21   \n",
              "2023-07-06     82.610001     75.489998              0.00                3.62   \n",
              "2023-07-07     80.430000     73.019997              3.55                4.53   \n",
              "2023-07-08     81.379997     73.059998              0.01                4.61   \n",
              "\n",
              "            ET (in)  \n",
              "Period               \n",
              "2013-10-23     0.08  \n",
              "2013-10-24     0.10  \n",
              "2013-10-25     0.08  \n",
              "2013-10-26     0.07  \n",
              "2013-10-27     0.07  \n",
              "...             ...  \n",
              "2023-07-04     0.21  \n",
              "2023-07-05     0.19  \n",
              "2023-07-06     0.18  \n",
              "2023-07-07     0.17  \n",
              "2023-07-08     0.20  \n",
              "\n",
              "[3542 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3a4dbc81-dfe4-4ebc-bc9c-c72bc0ee0c1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>ET (in)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.540001</td>\n",
              "      <td>49.500000</td>\n",
              "      <td>0.02</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.810001</td>\n",
              "      <td>46.709999</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.630001</td>\n",
              "      <td>44.169998</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.540001</td>\n",
              "      <td>43.029999</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.080002</td>\n",
              "      <td>41.130001</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-04</th>\n",
              "      <td>82.290001</td>\n",
              "      <td>72.629997</td>\n",
              "      <td>0.04</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>83.589996</td>\n",
              "      <td>73.239998</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.21</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>82.610001</td>\n",
              "      <td>75.489998</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.62</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>80.430000</td>\n",
              "      <td>73.019997</td>\n",
              "      <td>3.55</td>\n",
              "      <td>4.53</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-08</th>\n",
              "      <td>81.379997</td>\n",
              "      <td>73.059998</td>\n",
              "      <td>0.01</td>\n",
              "      <td>4.61</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3542 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a4dbc81-dfe4-4ebc-bc9c-c72bc0ee0c1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-bc92737a-f44c-49d0-b8b8-da9580ea5ed8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc92737a-f44c-49d0-b8b8-da9580ea5ed8')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-bc92737a-f44c-49d0-b8b8-da9580ea5ed8 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a4dbc81-dfe4-4ebc-bc9c-c72bc0ee0c1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a4dbc81-dfe4-4ebc-bc9c-c72bc0ee0c1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWlGiNa-UKrQ",
        "outputId": "63b959b1-956c-4224-9e44-e53a51208836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Period\n",
              "2013-10-23    75.059998\n",
              "2013-10-24    70.900002\n",
              "2013-10-25    69.709999\n",
              "2013-10-26    69.169998\n",
              "2013-10-27    68.750000\n",
              "                ...    \n",
              "2023-07-04    82.889999\n",
              "2023-07-05    82.559998\n",
              "2023-07-06    82.510002\n",
              "2023-07-07    81.790001\n",
              "2023-07-08    79.879997\n",
              "Name: Tsoil avg-10cm  (F), Length: 3542, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "0xbMM4XNUKuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3Q69vW7Uu9R",
        "outputId": "d130fceb-158f-4523-9548-66747b97d051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.4032232 , -0.7458762 , -0.2933927 ,  0.41611642, -0.62721187],\n",
              "       [-1.2142386 , -0.9646546 , -0.33826303, -1.0666183 , -0.18470922],\n",
              "       [-1.045161  , -1.1638292 , -0.33826303, -0.7735196 , -0.62721187],\n",
              "       ...,\n",
              "       [ 1.2754767 ,  1.292134  , -0.33826303, -0.319504  ,  1.5853014 ],\n",
              "       [ 1.072955  ,  1.0984485 ,  7.626221  ,  0.20347627,  1.3640499 ],\n",
              "       [ 1.1612096 ,  1.1015851 , -0.31582788,  0.24945249,  2.027804  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_size = int(len(X) * 0.8)\n",
        "X_train, y_train = X_scaled[:split_size], y_scaled[:split_size]\n",
        "X_test, y_test = X_scaled[split_size:], y_scaled[split_size:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k75sv6BUxeS",
        "outputId": "f76ced54-5d42-4ba5-89eb-684d50dd4a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2833, 2833, 709, 709)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with Adam"
      ],
      "metadata": {
        "id": "wWdBb__WVN40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wb = Workbook()"
      ],
      "metadata": {
        "id": "d9_4f7188KZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ws1 = wb.create_sheet(\"Model_Results\")\n",
        "ws1['A2']='Stability Selection'\n",
        "ws1['A3']='UMAP'\n",
        "ws1['A4']='Entropy Theory'\n",
        "ws1['B1']='Best Hidden Size'\n",
        "ws1['C1']='MLP_train_RMSE'\n",
        "ws1['D1']='MLP_test_RMSE'\n",
        "ws1['E1']='Best Hidden Size'\n",
        "ws1['F1']='MLP+Adabelief_train_RMSE'\n",
        "ws1['G1']='MLP+Adabelief_test_RMSE'\n",
        "ws1['H1']='Best Hidden Size'\n",
        "ws1['I1']='MLP+RangerAdabelief_train_RMSE'\n",
        "ws1['J1']='MLP+RangerAdabelief_test_RMSE'\n",
        "ws1['K1']='Best Hidden Size'\n",
        "ws1['L1']='LSTM_train_RMSE'\n",
        "ws1['M1']='LSTM_test_RMSE'\n",
        "ws1['N1']='Best Hidden Size'\n",
        "ws1['O1']='N-Beats_train_RMSE'\n",
        "ws1['P1']='N-Beats_test_RMSE'\n",
        "ws2 = wb.create_sheet(\"StabilitySelection_MLP\")\n",
        "ws2['A1']=\"Original Outputs\"\n",
        "ws2['B1']=\"Predicted Outputs\"\n",
        "ws3 = wb.create_sheet(\"StabilitySelection_MLP_AdaBelief\")\n",
        "ws3['A1']=\"Original Outputs\"\n",
        "ws3['B1']=\"Predicted Outputs\"\n",
        "ws4 = wb.create_sheet(\"StabilitySelection_MLP_RangerAdaBelief\")\n",
        "ws4['A1']=\"Original Outputs\"\n",
        "ws4['B1']=\"Predicted Outputs\"\n",
        "ws5 = wb.create_sheet(\"StabilitySelection_LSTM\")\n",
        "ws5['A1']=\"Original Outputs\"\n",
        "ws5['B1']=\"Predicted Outputs\"\n",
        "ws6 = wb.create_sheet(\"StabilitySelection_N_Beats\")\n",
        "ws6['A1']=\"Original Outputs\"\n",
        "ws6['B1']=\"Predicted Outputs\"\n",
        "ws7 = wb.create_sheet(\"UMAP_MLP\")\n",
        "ws7['A1']=\"Original Outputs\"\n",
        "ws7['B1']=\"Predicted Outputs\"\n",
        "ws8 = wb.create_sheet(\"UMAP_MLP_AdaBelief\")\n",
        "ws8['A1']=\"Original Outputs\"\n",
        "ws8['B1']=\"Predicted Outputs\"\n",
        "ws9 = wb.create_sheet(\"UMAP_MLP_RangerAdaBelief\")\n",
        "ws9['A1']=\"Original Outputs\"\n",
        "ws9['B1']=\"Predicted Outputs\"\n",
        "ws10 = wb.create_sheet(\"UMAP_LSTM\")\n",
        "ws10['A1']=\"Original Outputs\"\n",
        "ws10['B1']=\"Predicted Outputs\"\n",
        "ws11 = wb.create_sheet(\"UMAP_N_Beats\")\n",
        "ws11['A1']=\"Original Outputs\"\n",
        "ws11['B1']=\"Predicted Outputs\"\n",
        "ws12 = wb.create_sheet(\"EntropyTheory_MLP\")\n",
        "ws12['A1']=\"Original Outputs\"\n",
        "ws12['B1']=\"Predicted Outputs\"\n",
        "ws13 = wb.create_sheet(\"EntropyTheory_MLP_AdaBelief\")\n",
        "ws13['A1']=\"Original Outputs\"\n",
        "ws13['B1']=\"Predicted Outputs\"\n",
        "ws14 = wb.create_sheet(\"EntropyTheory_MLP_RangerAdaBelief\")\n",
        "ws14['A1']=\"Original Outputs\"\n",
        "ws14['B1']=\"Predicted Outputs\"\n",
        "ws15 = wb.create_sheet(\"EntropyTheory_LSTM\")\n",
        "ws15['A1']=\"Original Outputs\"\n",
        "ws15['B1']=\"Predicted Outputs\"\n",
        "ws16 = wb.create_sheet(\"EntropyTheory_N_Beats\")\n",
        "ws16['A1']=\"Original Outputs\"\n",
        "ws16['B1']=\"Predicted Outputs\"\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxhHnR4h8PC9",
        "outputId": "1c5469c3-59d3-4d0e-fc62-40ab40fc1d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
            "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_rmse=0.999999\n",
        "# Step 2: Create and train the MLP model\n",
        "# Modify the hyperparameters to adjust the model architecture and training process\n",
        "for roh in range(1,21):\n",
        "  mlp = MLPRegressor(hidden_layer_sizes=(roh), activation='relu', solver='adam', max_iter=100, random_state=42)\n",
        "  mlp.fit(X_train, y_train)\n",
        "  train_predictions = mlp.predict(X_train)\n",
        "  test_predictions = mlp.predict(X_test)\n",
        "  train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
        "  test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
        "  print(roh)\n",
        "  print(\"Training RMSE:\", train_rmse)\n",
        "  print(\"Testing RMSE:\", test_rmse)\n",
        "  if test_rmse < best_test_rmse:\n",
        "    best_test_rmse=test_rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=test_predictions\n",
        "ws1['B2']=best_hidden_size\n",
        "ws1['C2']=best_train_rmse\n",
        "ws1['D2']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws2['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws2['B{}'.format(i+2)] = float(prediction)\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eeo-W3Ofp4In",
        "outputId": "c9ac2c0c-b006-40d5-8c64-b753c0c91fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Training RMSE: 0.54340184\n",
            "Testing RMSE: 0.60235626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Training RMSE: 0.5815139\n",
            "Testing RMSE: 0.551103\n",
            "3\n",
            "Training RMSE: 0.34024987\n",
            "Testing RMSE: 0.3937912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "Training RMSE: 0.3254401\n",
            "Testing RMSE: 0.3706294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "Training RMSE: 0.3474331\n",
            "Testing RMSE: 0.41365212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "Training RMSE: 0.3368088\n",
            "Testing RMSE: 0.36851358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "Training RMSE: 0.3408979\n",
            "Testing RMSE: 0.39130992\n",
            "8\n",
            "Training RMSE: 0.3244319\n",
            "Testing RMSE: 0.37596712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "Training RMSE: 0.33176926\n",
            "Testing RMSE: 0.39290458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Training RMSE: 0.32070556\n",
            "Testing RMSE: 0.36919603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "Training RMSE: 0.32388774\n",
            "Testing RMSE: 0.37274364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "Training RMSE: 0.32327318\n",
            "Testing RMSE: 0.3752936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "Training RMSE: 0.32228476\n",
            "Testing RMSE: 0.37602243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "Training RMSE: 0.3256295\n",
            "Testing RMSE: 0.37187096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "Training RMSE: 0.32621545\n",
            "Testing RMSE: 0.369609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "Training RMSE: 0.3202198\n",
            "Testing RMSE: 0.37418678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "Training RMSE: 0.3198931\n",
            "Testing RMSE: 0.3712985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "Training RMSE: 0.32604635\n",
            "Testing RMSE: 0.3844551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "Training RMSE: 0.31891823\n",
            "Testing RMSE: 0.37245086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "Training RMSE: 0.32299182\n",
            "Testing RMSE: 0.37818035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with Adabelief"
      ],
      "metadata": {
        "id": "21g5yfxvV_Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your data to tensors\n",
        "inputs_train = torch.tensor(X_train, dtype=torch.float)\n",
        "labels_train = torch.tensor(y_train, dtype=torch.float)\n",
        "inputs_test = torch.tensor(X_test, dtype=torch.float)\n",
        "labels_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "test_dataset = TensorDataset(inputs_test, labels_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  # Create ELM model\n",
        "  input_dim = inputs_train.shape[1]\n",
        "  hidden_dim = [roh]\n",
        "  output_dim = 1  # Set output_size to 1 for a single regression target\n",
        "\n",
        "  # Create an instance of the MLP model\n",
        "  model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "  # Define your loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print(\"hello\")\n",
        "  print(model.parameters())\n",
        "  # Create an instance of the AdaBelief optimizer\n",
        "  optimizer = AdaBelief(model.parameters(),lr=0.01, betas = (0.9,0.999), eps=1e-8, weight_decouple = True, rectify = False)\n",
        "\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 100\n",
        "  best_loss = float('inf')  # Initialize with a very high loss\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      #print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
        "      # Check if current loss is the lowest so far\n",
        "      if avg_loss < best_loss:\n",
        "          best_loss = avg_loss\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "  train_predictions=[]\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          train_predictions.extend(output.numpy())\n",
        "  train_predictions = np.array(train_predictions)\n",
        "  if roh==1:\n",
        "    labels_train = labels_train.numpy()\n",
        "  else:\n",
        "    labels_train = labels_train\n",
        "  # Load the state of the best model\n",
        "  train_rmse = np.sqrt(mean_squared_error(labels_train, train_predictions))\n",
        "\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          predictions.extend(output.numpy())\n",
        "\n",
        "  predictions = np.array(predictions)\n",
        "  if roh==1:\n",
        "    labels_test = labels_test.numpy()\n",
        "  else:\n",
        "    labels_test = labels_test\n",
        "  rmse = np.sqrt(mean_squared_error(labels_test, predictions))\n",
        "  print(roh)\n",
        "  print(\"train RMSE\",train_rmse)\n",
        "  print(f\"Test RMSE: {rmse}\")\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=predictions\n",
        "ws1['E2']=best_hidden_size\n",
        "ws1['F2']=best_train_rmse\n",
        "ws1['G2']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws3['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws3['B{}'.format(i+2)] = float(prediction)\n",
        "\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "id": "wi8mHTkVUxm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45da8e3-b758-4309-ce80-eec182b8ec18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "<generator object Module.parameters at 0x7876908198c0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "1\n",
            "train RMSE 1.3811305\n",
            "Test RMSE: 0.4386563003063202\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670f20>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "2\n",
            "train RMSE 1.3785751\n",
            "Test RMSE: 0.3601585328578949\n",
            "hello\n",
            "<generator object Module.parameters at 0x7876908198c0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "3\n",
            "train RMSE 1.4167751\n",
            "Test RMSE: 0.37698426842689514\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "4\n",
            "train RMSE 1.3853421\n",
            "Test RMSE: 0.34483271837234497\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "5\n",
            "train RMSE 1.3876346\n",
            "Test RMSE: 0.34284263849258423\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "6\n",
            "train RMSE 1.3652755\n",
            "Test RMSE: 0.3442044258117676\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "7\n",
            "train RMSE 1.4025024\n",
            "Test RMSE: 0.3355858623981476\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "8\n",
            "train RMSE 1.4092178\n",
            "Test RMSE: 0.37254688143730164\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "9\n",
            "train RMSE 1.4062135\n",
            "Test RMSE: 0.3706812858581543\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "10\n",
            "train RMSE 1.4094748\n",
            "Test RMSE: 0.35490554571151733\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "11\n",
            "train RMSE 1.3647611\n",
            "Test RMSE: 0.3804228901863098\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "12\n",
            "train RMSE 1.3698595\n",
            "Test RMSE: 0.3782275319099426\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "13\n",
            "train RMSE 1.3816644\n",
            "Test RMSE: 0.36511117219924927\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "14\n",
            "train RMSE 1.4257642\n",
            "Test RMSE: 0.35447409749031067\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "15\n",
            "train RMSE 1.3960054\n",
            "Test RMSE: 0.35995039343833923\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "16\n",
            "train RMSE 1.3716754\n",
            "Test RMSE: 0.3756439685821533\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "17\n",
            "train RMSE 1.4034535\n",
            "Test RMSE: 0.3619470000267029\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "18\n",
            "train RMSE 1.4089562\n",
            "Test RMSE: 0.3495885729789734\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "19\n",
            "train RMSE 1.3661561\n",
            "Test RMSE: 0.41377586126327515\n",
            "hello\n",
            "<generator object Module.parameters at 0x787690670d60>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "20\n",
            "train RMSE 1.3604361\n",
            "Test RMSE: 0.3968277871608734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with RangerAdaBelief"
      ],
      "metadata": {
        "id": "eVk6xlxXoQqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your data to tensors\n",
        "inputs_train = torch.tensor(X_train, dtype=torch.float)\n",
        "labels_train = torch.tensor(y_train, dtype=torch.float)\n",
        "inputs_test = torch.tensor(X_test, dtype=torch.float)\n",
        "labels_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "test_dataset = TensorDataset(inputs_test, labels_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  # Create ELM model\n",
        "  input_dim = inputs_train.shape[1]\n",
        "  hidden_dim = [roh]\n",
        "  output_dim = 1  # Set output_size to 1 for a single regression target\n",
        "\n",
        "  # Create an instance of the MLP model\n",
        "  model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "  # Define your loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print(\"hello\")\n",
        "  print(model.parameters())\n",
        "  # Create an instance of the AdaBelief optimizer\n",
        "  optimizer = RangerAdaBelief(model.parameters(), lr=1e-2, eps=1e-12, betas=(0.9,0.999),weight_decouple = False)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 100\n",
        "  best_loss = float('inf')  # Initialize with a very high loss\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      #print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
        "      # Check if current loss is the lowest so far\n",
        "      if avg_loss < best_loss:\n",
        "          best_loss = avg_loss\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "  # Load the state of the best model\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "\n",
        "  train_predictions=[]\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          train_predictions.extend(output.numpy())\n",
        "  train_predictions = np.array(train_predictions)\n",
        "  if roh==1:\n",
        "    labels_train = labels_train.numpy()\n",
        "  else:\n",
        "    labels_train = labels_train\n",
        "  # Load the state of the best model\n",
        "  train_rmse = np.sqrt(mean_squared_error(labels_train, train_predictions))\n",
        "\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          predictions.extend(output.numpy())\n",
        "\n",
        "  predictions = np.array(predictions)\n",
        "  if roh==1:\n",
        "    labels_test = labels_test.numpy()\n",
        "  else:\n",
        "    labels_test = labels_test\n",
        "  rmse = np.sqrt(mean_squared_error(labels_test, predictions))\n",
        "  print(roh)\n",
        "  print(f\"Test RMSE: {rmse}\")\n",
        "  print(\"train RMSE:\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=predictions\n",
        "\n",
        "ws1['H2']=best_hidden_size\n",
        "ws1['I2']=best_train_rmse\n",
        "ws1['J2']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws4['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws4['B{}'.format(i+2)] = float(prediction)\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzrdVuHkoUK5",
        "outputId": "c4a1b6d6-2646-4a36-a24e-91ecaf86b6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "<generator object Module.parameters at 0x78769070c970>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "1\n",
            "Test RMSE: 0.8254187107086182\n",
            "train RMSE: 1.3070633\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769069b370>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "2\n",
            "Test RMSE: 0.38015732169151306\n",
            "train RMSE: 1.4089181\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070cb30>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "3\n",
            "Test RMSE: 0.3638211488723755\n",
            "train RMSE: 1.3741174\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070cb30>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "4\n",
            "Test RMSE: 0.3803347051143646\n",
            "train RMSE: 1.4538323\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070cb30>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "5\n",
            "Test RMSE: 0.3680240213871002\n",
            "train RMSE: 1.3631346\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070cb30>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "6\n",
            "Test RMSE: 0.3791099190711975\n",
            "train RMSE: 1.4178151\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "7\n",
            "Test RMSE: 0.35433125495910645\n",
            "train RMSE: 1.4087349\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "8\n",
            "Test RMSE: 0.37606361508369446\n",
            "train RMSE: 1.4091467\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "9\n",
            "Test RMSE: 0.3594088852405548\n",
            "train RMSE: 1.3866425\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "10\n",
            "Test RMSE: 0.400675892829895\n",
            "train RMSE: 1.4127837\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "11\n",
            "Test RMSE: 0.3543725311756134\n",
            "train RMSE: 1.4149952\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "12\n",
            "Test RMSE: 0.3583650588989258\n",
            "train RMSE: 1.400422\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "13\n",
            "Test RMSE: 0.36248549818992615\n",
            "train RMSE: 1.4018424\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "14\n",
            "Test RMSE: 0.3612208962440491\n",
            "train RMSE: 1.4198161\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "15\n",
            "Test RMSE: 0.37407931685447693\n",
            "train RMSE: 1.4160129\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "16\n",
            "Test RMSE: 0.35758528113365173\n",
            "train RMSE: 1.3925542\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "17\n",
            "Test RMSE: 0.38457128405570984\n",
            "train RMSE: 1.3918314\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "18\n",
            "Test RMSE: 0.3749687969684601\n",
            "train RMSE: 1.3950316\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "19\n",
            "Test RMSE: 0.35017943382263184\n",
            "train RMSE: 1.4147584\n",
            "hello\n",
            "<generator object Module.parameters at 0x78769070c9e0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "20\n",
            "Test RMSE: 0.36148178577423096\n",
            "train RMSE: 1.4060557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "ri4WAtzFFEUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we pass our data to the Conv1D layer, we have to reshape it in order to make sure it works\n",
        "x = tf.constant(X_train)\n",
        "expand_dims_layer = layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) # add an extra dimension for timesteps\n",
        "print(f\"Original shape: {x.shape}\") # (WINDOW_SIZE)\n",
        "print(f\"Expanded shape: {expand_dims_layer(x).shape}\") # (WINDOW_SIZE, input_dim)\n",
        "print(f\"Original values with expanded shape:\\n {expand_dims_layer(x)}\")\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create model\n",
        "model_4 = tf.keras.Sequential([\n",
        "  # Create Lambda layer to reshape inputs, without this layer, the model will error\n",
        "  layers.Lambda(lambda x: tf.expand_dims(x, axis=1)), # resize the inputs to adjust for window size / Conv1D 3D input requirements\n",
        "  layers.Conv1D(filters=12, kernel_size=5, padding=\"causal\", activation=\"relu\"),\n",
        "  layers.Dense(HORIZON)\n",
        "], name=\"model_4_conv1D\")\n",
        "\n",
        "# Compile model\n",
        "model_4.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "# Fit model\n",
        "model_4.fit(X_train,\n",
        "            y_train,\n",
        "            batch_size=128,\n",
        "            epochs=100,\n",
        "            verbose=0,\n",
        "            validation_data=(X_test, y_test),\n",
        "            callbacks=[create_model_checkpoint(model_name=model_4.name)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkNe8_ihoURL",
        "outputId": "3d4bce8a-7c47-4974-ff4d-754b455f31bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (2833, 5)\n",
            "Expanded shape: (2833, 1, 5)\n",
            "Original values with expanded shape:\n",
            " [[[-0.4032232  -0.7458762  -0.2933927   0.41611642 -0.62721187]]\n",
            "\n",
            " [[-1.2142386  -0.9646546  -0.33826303 -1.0666183  -0.18470922]]\n",
            "\n",
            " [[-1.045161   -1.1638292  -0.33826303 -0.7735196  -0.62721187]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.8657881   1.2097985   5.023742   -0.45168564 -0.18470922]]\n",
            "\n",
            " [[ 0.84627926  1.1651019   1.277069   -0.54938525  0.2577933 ]]\n",
            "\n",
            " [[ 0.99027425  1.1690223  -0.31582788 -0.681567    1.3640499 ]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x787697b49f30>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqWCOoCtoUTu",
        "outputId": "5daf2ddc-f9d3-4d50-e149-4c722e605945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1353 - root_mean_squared_error: 0.3678\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13527968525886536, 0.3678038716316223]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # Let's build an LSTM model with the Functional API\n",
        "  inputs = layers.Input(shape=(5))\n",
        "  x = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(inputs) # expand input dimension to be compatible with LSTM\n",
        "  # print(x.shape)\n",
        "  # x = layers.LSTM(128, activation=\"relu\", return_sequences=True)(x) # this layer will error if the inputs are not the right shape\n",
        "  x = layers.LSTM(roh, activation=\"relu\")(x) # using the tanh loss function results in a massive error\n",
        "  # print(x.shape)\n",
        "\n",
        "\n",
        "  output = layers.Dense(HORIZON)(x)\n",
        "  model_5 = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_5_lstm\")\n",
        "\n",
        "  # Compile model\n",
        "  model_5.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  # Seems when saving the model several warnings are appearing: https://github.com/tensorflow/tensorflow/issues/47554\n",
        "  model_5.fit(X_train,\n",
        "              y_train,\n",
        "              epochs=100,\n",
        "              verbose=0,\n",
        "              batch_size=128,\n",
        "              validation_data=(X_test, y_test),\n",
        "              callbacks=[create_model_checkpoint(model_name=model_5.name)])\n",
        "  print(roh)\n",
        "  rmse=model_5.evaluate(X_test, y_test)\n",
        "  rmse=rmse[1]\n",
        "  print(\"test rmse\",rmse)\n",
        "  train_rmse=model_5.evaluate(X_train, y_train)\n",
        "  train_rmse=train_rmse[1]\n",
        "  print(\"train rmse\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=model_5.predict(X_test)\n",
        "\n",
        "ws1['K2']=best_hidden_size\n",
        "ws1['L2']=best_train_rmse\n",
        "ws1['M2']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws5['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws5['B{}'.format(i+2)] = float(prediction)\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaSPSEdVoUWM",
        "outputId": "ff7b222f-b272-4108-cf27-8a10230b55f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1674 - root_mean_squared_error: 0.4092\n",
            "test rmse 0.4091818034648895\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1341 - root_mean_squared_error: 0.3661\n",
            "train rmse 0.3661395013332367\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1665 - root_mean_squared_error: 0.4080\n",
            "test rmse 0.40804967284202576\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1235 - root_mean_squared_error: 0.3514\n",
            "train rmse 0.3513810336589813\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1393 - root_mean_squared_error: 0.3732\n",
            "test rmse 0.3731881380081177\n",
            "89/89 [==============================] - 0s 3ms/step - loss: 0.1015 - root_mean_squared_error: 0.3185\n",
            "train rmse 0.31854018568992615\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1341 - root_mean_squared_error: 0.3662\n",
            "test rmse 0.3661622405052185\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1019 - root_mean_squared_error: 0.3192\n",
            "train rmse 0.31921544671058655\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1366 - root_mean_squared_error: 0.3695\n",
            "test rmse 0.3695487678050995\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1051 - root_mean_squared_error: 0.3243\n",
            "train rmse 0.32425254583358765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1359 - root_mean_squared_error: 0.3686\n",
            "test rmse 0.36861652135849\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1007 - root_mean_squared_error: 0.3173\n",
            "train rmse 0.3172840178012848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1342 - root_mean_squared_error: 0.3663\n",
            "test rmse 0.36629506945610046\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1006 - root_mean_squared_error: 0.3171\n",
            "train rmse 0.31712624430656433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1344 - root_mean_squared_error: 0.3666\n",
            "test rmse 0.3666192889213562\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1001 - root_mean_squared_error: 0.3165\n",
            "train rmse 0.3164522349834442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1352 - root_mean_squared_error: 0.3677\n",
            "test rmse 0.3676794469356537\n",
            "89/89 [==============================] - 0s 3ms/step - loss: 0.1008 - root_mean_squared_error: 0.3175\n",
            "train rmse 0.31751549243927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1352 - root_mean_squared_error: 0.3677\n",
            "test rmse 0.367652952671051\n",
            "89/89 [==============================] - 0s 3ms/step - loss: 0.0998 - root_mean_squared_error: 0.3160\n",
            "train rmse 0.315951406955719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1338 - root_mean_squared_error: 0.3658\n",
            "test rmse 0.3657640516757965\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1011 - root_mean_squared_error: 0.3180\n",
            "train rmse 0.31800758838653564\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1340 - root_mean_squared_error: 0.3660\n",
            "test rmse 0.3660247325897217\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1004 - root_mean_squared_error: 0.3169\n",
            "train rmse 0.316851943731308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1356 - root_mean_squared_error: 0.3682\n",
            "test rmse 0.36818987131118774\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1003 - root_mean_squared_error: 0.3167\n",
            "train rmse 0.3167181611061096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1338 - root_mean_squared_error: 0.3658\n",
            "test rmse 0.36581844091415405\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1000 - root_mean_squared_error: 0.3162\n",
            "train rmse 0.3162004351615906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1354 - root_mean_squared_error: 0.3680\n",
            "test rmse 0.3680233955383301\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.0999 - root_mean_squared_error: 0.3161\n",
            "train rmse 0.3160739243030548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1328 - root_mean_squared_error: 0.3644\n",
            "test rmse 0.3643898665904999\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.0993 - root_mean_squared_error: 0.3151\n",
            "train rmse 0.31513527035713196\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1311 - root_mean_squared_error: 0.3621\n",
            "test rmse 0.3621216416358948\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.0987 - root_mean_squared_error: 0.3142\n",
            "train rmse 0.31416019797325134\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1339 - root_mean_squared_error: 0.3659\n",
            "test rmse 0.36590775847435\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.0994 - root_mean_squared_error: 0.3152\n",
            "train rmse 0.31520357728004456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1316 - root_mean_squared_error: 0.3628\n",
            "test rmse 0.36281654238700867\n",
            "89/89 [==============================] - 0s 3ms/step - loss: 0.0985 - root_mean_squared_error: 0.3139\n",
            "train rmse 0.3139232397079468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1343 - root_mean_squared_error: 0.3664\n",
            "test rmse 0.36643868684768677\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.0996 - root_mean_squared_error: 0.3155\n",
            "train rmse 0.3155164122581482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N-Beats"
      ],
      "metadata": {
        "id": "lJ3ZserOFOVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "train_labels_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
        "\n",
        "test_features_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "test_labels_dataset = tf.data.Dataset.from_tensor_slices(y_test)\n",
        "\n",
        "# 2. Combine features & labels\n",
        "train_dataset = tf.data.Dataset.zip((train_features_dataset, train_labels_dataset))\n",
        "test_dataset = tf.data.Dataset.zip((test_features_dataset, test_labels_dataset))\n",
        "\n",
        "# 3. Batch and prefetch for optimal performance\n",
        "BATCH_SIZE = 1024 # taken from Appendix D in N-BEATS paper\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vvg9QPKs7AW",
        "outputId": "c074a421-5908-43a7-c72d-1de30d2fd6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
              " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  # Values from N-BEATS paper Figure 1 and Table 18/Appendix D\n",
        "  N_EPOCHS = 100 # called \"Iterations\" in Table 18\n",
        "  N_NEURONS = roh # called \"Width\" in Table 18\n",
        "  N_LAYERS = 2\n",
        "  N_STACKS = 1\n",
        "  INPUT_SIZE = WINDOW_SIZE * HORIZON # called \"Lookback\" in Table 18\n",
        "  THETA_SIZE = INPUT_SIZE + HORIZON\n",
        "\n",
        "  INPUT_SIZE, THETA_SIZE\n",
        "\n",
        "\n",
        "  # %%time\n",
        "\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # 1. Setup N-BEATS Block layer\n",
        "  nbeats_block_layer = NBeatsBlock(input_size=INPUT_SIZE,\n",
        "                                  theta_size=THETA_SIZE,\n",
        "                                  horizon=HORIZON,\n",
        "                                  n_neurons=N_NEURONS,\n",
        "                                  n_layers=N_LAYERS,\n",
        "                                  name=\"InitialBlock\")\n",
        "\n",
        "  # 2. Create input to stacks\n",
        "  stack_input = layers.Input(shape=(5), name=\"stack_input\")\n",
        "\n",
        "  # 3. Create initial backcast and forecast input (backwards predictions are referred to as residuals in the paper)\n",
        "  backcast, forecast = nbeats_block_layer(stack_input)\n",
        "  # Add in subtraction residual link, thank you to: https://github.com/mrdbourke/tensorflow-deep-learning/discussions/174\n",
        "  residuals = layers.subtract([stack_input, backcast], name=f\"subtract_00\")\n",
        "\n",
        "  # 4. Create stacks of blocks\n",
        "  for i, _ in enumerate(range(N_STACKS-1)): # first stack is already creted in (3)\n",
        "\n",
        "    # 5. Use the NBeatsBlock to calculate the backcast as well as block forecast\n",
        "    backcast, block_forecast = NBeatsBlock(\n",
        "        input_size=INPUT_SIZE,\n",
        "        theta_size=THETA_SIZE,\n",
        "        horizon=HORIZON,\n",
        "        n_neurons=N_NEURONS,\n",
        "        n_layers=N_LAYERS,\n",
        "        name=f\"NBeatsBlock_{i}\"\n",
        "    )(residuals) # pass it in residuals (the backcast)\n",
        "\n",
        "    # 6. Create the double residual stacking\n",
        "    residuals = layers.subtract([residuals, backcast], name=f\"subtract_{i}\")\n",
        "    forecast = layers.add([forecast, block_forecast], name=f\"add_{i}\")\n",
        "\n",
        "  # 7. Put the stack model together\n",
        "  model_6 = tf.keras.Model(inputs=stack_input,\n",
        "                          outputs=forecast,\n",
        "                          name=\"model_6_N-BEATS\")\n",
        "\n",
        "  # 8. Compile with MAE loss and Adam optimizer\n",
        "  model_6.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  # 9. Fit the model with EarlyStopping and ReduceLROnPlateau callbacks\n",
        "  model_6.fit(train_dataset,\n",
        "              epochs=N_EPOCHS,\n",
        "              validation_data=test_dataset,\n",
        "              verbose=0, # prevent large amounts of training outputs\n",
        "              # callbacks=[create_model_checkpoint(model_name=stack_model.name)] # saving model every epoch consumes far too much time\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100, verbose=1)])\n",
        "  print(roh)\n",
        "  # Evaluate N-BEATS model on the test dataset\n",
        "  rmse=model_6.evaluate(test_dataset)\n",
        "  rmse=rmse[1]\n",
        "  print(\"test RMSE:\",rmse)\n",
        "  train_rmse=model_6.evaluate(train_dataset)\n",
        "  train_rmse=train_rmse[1]\n",
        "  print(\"train RMSE:\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=model_6.predict(X_test)\n",
        "\n",
        "ws1['N2']=best_hidden_size\n",
        "ws1['O2']=best_train_rmse\n",
        "ws1['P2']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws6['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws6['B{}'.format(i+2)] = float(prediction)\n",
        "\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-rJRU8Ks7DI",
        "outputId": "74d75f05-d12f-40b7-f966-57428241d895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4520 - root_mean_squared_error: 0.6723\n",
            "test RMSE: 0.6723209619522095\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.3876 - root_mean_squared_error: 0.6225\n",
            "train RMSE: 0.6225499510765076\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "2\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.9082 - root_mean_squared_error: 0.9530\n",
            "test RMSE: 0.9530202746391296\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.0258 - root_mean_squared_error: 1.0128\n",
            "train RMSE: 1.0128064155578613\n",
            "3\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5049 - root_mean_squared_error: 0.7106\n",
            "test RMSE: 0.7105886936187744\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4937 - root_mean_squared_error: 0.7027\n",
            "train RMSE: 0.7026656270027161\n",
            "4\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2595 - root_mean_squared_error: 0.5094\n",
            "test RMSE: 0.5093941688537598\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2127 - root_mean_squared_error: 0.4611\n",
            "train RMSE: 0.46114683151245117\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "5\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1931 - root_mean_squared_error: 0.4395\n",
            "test RMSE: 0.43947741389274597\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1439 - root_mean_squared_error: 0.3794\n",
            "train RMSE: 0.37940704822540283\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "6\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1592 - root_mean_squared_error: 0.3989\n",
            "test RMSE: 0.398949533700943\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1275 - root_mean_squared_error: 0.3571\n",
            "train RMSE: 0.3570866286754608\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "7\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1821 - root_mean_squared_error: 0.4267\n",
            "test RMSE: 0.42674657702445984\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1403 - root_mean_squared_error: 0.3745\n",
            "train RMSE: 0.37452054023742676\n",
            "8\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1932 - root_mean_squared_error: 0.4396\n",
            "test RMSE: 0.4395526647567749\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1621 - root_mean_squared_error: 0.4026\n",
            "train RMSE: 0.40259674191474915\n",
            "9\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1717 - root_mean_squared_error: 0.4144\n",
            "test RMSE: 0.41441285610198975\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1316 - root_mean_squared_error: 0.3628\n",
            "train RMSE: 0.36280155181884766\n",
            "10\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1521 - root_mean_squared_error: 0.3900\n",
            "test RMSE: 0.38996195793151855\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1183 - root_mean_squared_error: 0.3439\n",
            "train RMSE: 0.3439403474330902\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "11\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1581 - root_mean_squared_error: 0.3976\n",
            "test RMSE: 0.3975927233695984\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1243 - root_mean_squared_error: 0.3525\n",
            "train RMSE: 0.3525359034538269\n",
            "12\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1433 - root_mean_squared_error: 0.3786\n",
            "test RMSE: 0.378581702709198\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1050 - root_mean_squared_error: 0.3240\n",
            "train RMSE: 0.32398197054862976\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "13\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1475 - root_mean_squared_error: 0.3841\n",
            "test RMSE: 0.38409891724586487\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1132 - root_mean_squared_error: 0.3365\n",
            "train RMSE: 0.33651062846183777\n",
            "14\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1340 - root_mean_squared_error: 0.3661\n",
            "test RMSE: 0.36608588695526123\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1098 - root_mean_squared_error: 0.3314\n",
            "train RMSE: 0.33136826753616333\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "15\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1428 - root_mean_squared_error: 0.3779\n",
            "test RMSE: 0.37793537974357605\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1070 - root_mean_squared_error: 0.3271\n",
            "train RMSE: 0.3270837962627411\n",
            "16\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1352 - root_mean_squared_error: 0.3677\n",
            "test RMSE: 0.36767005920410156\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1054 - root_mean_squared_error: 0.3247\n",
            "train RMSE: 0.3246558606624603\n",
            "17\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1350 - root_mean_squared_error: 0.3675\n",
            "test RMSE: 0.3674813508987427\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1011 - root_mean_squared_error: 0.3179\n",
            "train RMSE: 0.3179161548614502\n",
            "18\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1351 - root_mean_squared_error: 0.3676\n",
            "test RMSE: 0.3675682544708252\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1043 - root_mean_squared_error: 0.3230\n",
            "train RMSE: 0.3229677081108093\n",
            "19\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1295 - root_mean_squared_error: 0.3599\n",
            "test RMSE: 0.35990944504737854\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1019 - root_mean_squared_error: 0.3191\n",
            "train RMSE: 0.31914085149765015\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "20\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1343 - root_mean_squared_error: 0.3665\n",
            "test RMSE: 0.3665248155593872\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0990 - root_mean_squared_error: 0.3147\n",
            "train RMSE: 0.31470441818237305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UMAP**"
      ],
      "metadata": {
        "id": "dtJQQjJsK0wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFwey5vSCgbk",
        "outputId": "bc54f22b-c85e-4de5-f4f7-645e0e64244b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
            "Period                                                                   \n",
            "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
            "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
            "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
            "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
            "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
            "\n",
            "            RelHum avg 2m  (pct)  2m Rain tot (in)  SolRad avg2m  (w/m^2)  \\\n",
            "Period                                                                      \n",
            "2013-10-23                  81.0              0.02             177.630005   \n",
            "2013-10-24                  75.0              0.00             146.940002   \n",
            "2013-10-25                  78.0              0.00             181.080002   \n",
            "2013-10-26                  76.0              0.00             181.639999   \n",
            "2013-10-27                  78.0              0.00             181.229996   \n",
            "\n",
            "            10m Wind avg (mph)  10m Wind min (mph)  10m Wind max (mph)  \\\n",
            "Period                                                                   \n",
            "2013-10-23                4.90                0.06           16.940001   \n",
            "2013-10-24                2.32                0.02           10.660000   \n",
            "2013-10-25                2.83                0.00           12.820000   \n",
            "2013-10-26                2.57                0.06           10.360000   \n",
            "2013-10-27                1.93                0.02           11.320000   \n",
            "\n",
            "            BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
            "Period                                            \n",
            "2013-10-23       1009.0     0.08       59.970001  \n",
            "2013-10-24       1016.0     0.10       50.910000  \n",
            "2013-10-25       1019.0     0.08       53.060001  \n",
            "2013-10-26       1018.0     0.07       50.770000  \n",
            "2013-10-27       1016.0     0.07       51.209999  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "4HgtJEK2SoRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reducer=umap.UMAP(n_components=3,min_dist=0.3)"
      ],
      "metadata": {
        "id": "tAo2WXIvRY8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding=reducer.fit_transform(X_scaled)"
      ],
      "metadata": {
        "id": "8SJP4HoJRY-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E9gMVR8RZAd",
        "outputId": "74c627c1-1b55-4b9b-8847-4d24147ea2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.2777395,  7.064147 ,  7.686953 ],\n",
              "       [ 3.760841 ,  7.037383 ,  8.778119 ],\n",
              "       [ 3.9987442,  7.0571957,  8.612235 ],\n",
              "       ...,\n",
              "       [10.715552 ,  8.453825 ,  5.001571 ],\n",
              "       [ 8.891207 ,  3.8618762,  4.413666 ],\n",
              "       [ 9.573575 ,  8.110842 ,  4.451232 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_size = int(len(X) * 0.8)\n",
        "X_train, y_train = embedding[:split_size], y_scaled[:split_size]\n",
        "X_test, y_test = embedding[split_size:], y_scaled[split_size:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2SkNnV2RZC0",
        "outputId": "870c8013-c125-44bb-fd34-2fc60f89317c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2833, 2833, 709, 709)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train,X_test,y_train,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8bTk7WvTUwQ",
        "outputId": "cc4ba2cf-6bcd-420a-db84-f0abd0b98b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5.2777395  7.064147   7.686953 ]\n",
            " [ 3.760841   7.037383   8.778119 ]\n",
            " [ 3.9987442  7.0571957  8.612235 ]\n",
            " ...\n",
            " [ 8.403631   3.6383753  4.625739 ]\n",
            " [ 9.366631   5.143866   4.5672317]\n",
            " [10.334435   7.454608   5.063755 ]] [[10.103461   8.38369    5.13876  ]\n",
            " [ 9.672463   8.1154785  4.9196014]\n",
            " [ 9.357774   5.989756   4.640501 ]\n",
            " ...\n",
            " [10.715552   8.453825   5.001571 ]\n",
            " [ 8.891207   3.8618762  4.413666 ]\n",
            " [ 9.573575   8.110842   4.451232 ]] [[ 0.3417217 ]\n",
            " [-0.11407956]\n",
            " [-0.24446538]\n",
            " ...\n",
            " [ 0.91366524]\n",
            " [ 0.84135103]\n",
            " [ 0.9563966 ]] [[ 1.1284178 ]\n",
            " [ 1.151427  ]\n",
            " [ 1.0758258 ]\n",
            " [ 0.98159754]\n",
            " [ 0.7493137 ]\n",
            " [ 0.7646531 ]\n",
            " [ 0.69452983]\n",
            " [ 0.66166   ]\n",
            " [ 0.7493137 ]\n",
            " [ 0.90709144]\n",
            " [ 1.0823996 ]\n",
            " [ 1.1459491 ]\n",
            " [ 1.098835  ]\n",
            " [ 1.0999309 ]\n",
            " [ 1.073634  ]\n",
            " [ 0.9673532 ]\n",
            " [ 0.9388662 ]\n",
            " [ 0.8807955 ]\n",
            " [ 0.83039355]\n",
            " [ 0.9750229 ]\n",
            " [ 1.0834955 ]\n",
            " [ 1.1119826 ]\n",
            " [ 1.1426622 ]\n",
            " [ 1.0484339 ]\n",
            " [ 0.98707545]\n",
            " [ 0.9377703 ]\n",
            " [ 0.78985405]\n",
            " [ 0.7701318 ]\n",
            " [ 0.82710665]\n",
            " [ 0.89613485]\n",
            " [ 1.0100853 ]\n",
            " [ 1.0593905 ]\n",
            " [ 0.97831064]\n",
            " [ 0.72849554]\n",
            " [ 0.7295915 ]\n",
            " [ 0.87641263]\n",
            " [ 0.8479248 ]\n",
            " [ 0.7876622 ]\n",
            " [ 0.7745146 ]\n",
            " [ 0.68357325]\n",
            " [ 0.71206105]\n",
            " [ 0.6441288 ]\n",
            " [ 0.7372612 ]\n",
            " [ 0.7339743 ]\n",
            " [ 0.7328784 ]\n",
            " [ 0.71096516]\n",
            " [ 0.66932976]\n",
            " [ 0.61892784]\n",
            " [ 0.68138224]\n",
            " [ 0.6978167 ]\n",
            " [ 0.72192174]\n",
            " [ 0.6419378 ]\n",
            " [ 0.6485116 ]\n",
            " [ 0.69343394]\n",
            " [ 0.71315616]\n",
            " [ 0.7054864 ]\n",
            " [ 0.49182975]\n",
            " [ 0.5214127 ]\n",
            " [ 0.50936013]\n",
            " [ 0.40198427]\n",
            " [ 0.36363575]\n",
            " [ 0.36582673]\n",
            " [ 0.37349644]\n",
            " [ 0.38993177]\n",
            " [ 0.38116613]\n",
            " [ 0.36144394]\n",
            " [ 0.38445303]\n",
            " [ 0.36911362]\n",
            " [ 0.409654  ]\n",
            " [ 0.4184196 ]\n",
            " [ 0.47320342]\n",
            " [ 0.38116613]\n",
            " [ 0.28145996]\n",
            " [ 0.22448428]\n",
            " [ 0.3395307 ]\n",
            " [ 0.32309538]\n",
            " [ 0.35815704]\n",
            " [ 0.30994695]\n",
            " [ 0.22448428]\n",
            " [ 0.09409927]\n",
            " [-0.2598048 ]\n",
            " [-0.22255135]\n",
            " [-0.2609007 ]\n",
            " [-0.15571582]\n",
            " [-0.09216634]\n",
            " [-0.0669654 ]\n",
            " [-0.09874014]\n",
            " [ 0.10176898]\n",
            " [ 0.10067306]\n",
            " [-0.22255135]\n",
            " [-0.3397896 ]\n",
            " [-0.3474593 ]\n",
            " [-0.54687256]\n",
            " [-0.79011214]\n",
            " [-0.7955909 ]\n",
            " [-0.62247366]\n",
            " [-0.6137089 ]\n",
            " [-0.58083826]\n",
            " [-0.74628574]\n",
            " [-1.3237072 ]\n",
            " [-1.1735996 ]\n",
            " [-1.2152354 ]\n",
            " [-1.2470098 ]\n",
            " [-1.0782758 ]\n",
            " [-0.79668677]\n",
            " [-0.69697976]\n",
            " [-0.7703899 ]\n",
            " [-1.0925193 ]\n",
            " [-1.2689233 ]\n",
            " [-1.2908369 ]\n",
            " [-1.1790779 ]\n",
            " [-0.96103835]\n",
            " [-0.7583383 ]\n",
            " [-0.9303591 ]\n",
            " [-0.7857302 ]\n",
            " [-0.7572423 ]\n",
            " [-1.0727971 ]\n",
            " [-1.4025961 ]\n",
            " [-1.2908369 ]\n",
            " [-1.3138461 ]\n",
            " [-1.5242163 ]\n",
            " [-1.5307901 ]\n",
            " [-1.3883522 ]\n",
            " [-1.6140618 ]\n",
            " [-1.6085835 ]\n",
            " [-1.5066855 ]\n",
            " [-1.41684   ]\n",
            " [-1.2996022 ]\n",
            " [-1.2502971 ]\n",
            " [-1.2174264 ]\n",
            " [-0.99829096]\n",
            " [-0.86461824]\n",
            " [-0.89858437]\n",
            " [-0.8744798 ]\n",
            " [-0.77258176]\n",
            " [-0.6991716 ]\n",
            " [-0.79011214]\n",
            " [-0.87228835]\n",
            " [-0.8087393 ]\n",
            " [-0.66958785]\n",
            " [-0.6323352 ]\n",
            " [-0.69478875]\n",
            " [-0.6104212 ]\n",
            " [-0.8284615 ]\n",
            " [-1.2798804 ]\n",
            " [-1.3828739 ]\n",
            " [-1.5483209 ]\n",
            " [-1.4913456 ]\n",
            " [-1.444232  ]\n",
            " [-1.240436  ]\n",
            " [-1.1494945 ]\n",
            " [-1.1144329 ]\n",
            " [-1.0519793 ]\n",
            " [-0.8394181 ]\n",
            " [-0.6827363 ]\n",
            " [-0.66410995]\n",
            " [-0.638909  ]\n",
            " [-0.8459919 ]\n",
            " [-1.300698  ]\n",
            " [-1.2711147 ]\n",
            " [-1.4069788 ]\n",
            " [-1.2601582 ]\n",
            " [-1.4277966 ]\n",
            " [-1.2886455 ]\n",
            " [-1.1308682 ]\n",
            " [-1.4135526 ]\n",
            " [-1.5121638 ]\n",
            " [-1.4113613 ]\n",
            " [-1.5406512 ]\n",
            " [-1.6294012 ]\n",
            " [-1.520929  ]\n",
            " [-1.7795087 ]\n",
            " [-1.9307123 ]\n",
            " [-1.9164684 ]\n",
            " [-1.7203422 ]\n",
            " [-1.5570866 ]\n",
            " [-1.8211446 ]\n",
            " [-1.9778265 ]\n",
            " [-2.1334124 ]\n",
            " [-1.9438603 ]\n",
            " [-1.8244315 ]\n",
            " [-1.7575952 ]\n",
            " [-1.809092  ]\n",
            " [-2.0753417 ]\n",
            " [-2.3404953 ]\n",
            " [-2.1728568 ]\n",
            " [-2.053428  ]\n",
            " [-1.8704501 ]\n",
            " [-1.596531  ]\n",
            " [-1.3302814 ]\n",
            " [-1.3642471 ]\n",
            " [-1.6962376 ]\n",
            " [-1.8288143 ]\n",
            " [-1.8627805 ]\n",
            " [-1.8835982 ]\n",
            " [-1.938382  ]\n",
            " [-1.8671628 ]\n",
            " [-1.7006204 ]\n",
            " [-1.4935371 ]\n",
            " [-1.7795087 ]\n",
            " [-1.9197557 ]\n",
            " [-1.7773174 ]\n",
            " [-1.494633  ]\n",
            " [-1.1429207 ]\n",
            " [-1.1692168 ]\n",
            " [-1.5296946 ]\n",
            " [-1.3795869 ]\n",
            " [-1.1790779 ]\n",
            " [-1.0070566 ]\n",
            " [-0.9292636 ]\n",
            " [-0.894202  ]\n",
            " [-0.8974889 ]\n",
            " [-0.791208  ]\n",
            " [-0.96761215]\n",
            " [-1.1253899 ]\n",
            " [-1.213044  ]\n",
            " [-1.2196178 ]\n",
            " [-1.1440163 ]\n",
            " [-0.93364644]\n",
            " [-0.8383222 ]\n",
            " [-0.7342332 ]\n",
            " [-0.5698816 ]\n",
            " [-0.47346154]\n",
            " [-0.7188938 ]\n",
            " [-0.80764335]\n",
            " [-0.77586865]\n",
            " [-1.263445  ]\n",
            " [-1.2754976 ]\n",
            " [-1.1462076 ]\n",
            " [-0.9522727 ]\n",
            " [-0.80326056]\n",
            " [-0.7320414 ]\n",
            " [-0.62247366]\n",
            " [-0.5523504 ]\n",
            " [-0.791208  ]\n",
            " [-0.7583383 ]\n",
            " [-0.6509615 ]\n",
            " [-0.716702  ]\n",
            " [-0.816409  ]\n",
            " [-0.9018717 ]\n",
            " [-0.9018717 ]\n",
            " [-0.78353834]\n",
            " [-0.5534463 ]\n",
            " [-0.48332307]\n",
            " [-0.5359151 ]\n",
            " [-0.45264423]\n",
            " [-0.61261296]\n",
            " [-0.6334303 ]\n",
            " [-0.5359151 ]\n",
            " [-0.3869029 ]\n",
            " [-0.25103918]\n",
            " [-0.10969675]\n",
            " [-0.36389378]\n",
            " [-0.65644026]\n",
            " [-0.78134733]\n",
            " [-0.6575353 ]\n",
            " [-0.42306045]\n",
            " [-0.30253613]\n",
            " [-0.23679568]\n",
            " [-0.17105523]\n",
            " [-0.11298364]\n",
            " [ 0.00644477]\n",
            " [-0.077922  ]\n",
            " [-0.18201184]\n",
            " [-0.42744327]\n",
            " [-0.38799882]\n",
            " [-0.355129  ]\n",
            " [-0.30691895]\n",
            " [-0.20282997]\n",
            " [-0.11407956]\n",
            " [-0.02204307]\n",
            " [ 0.05355892]\n",
            " [ 0.10834277]\n",
            " [-0.05819978]\n",
            " [ 0.00644477]\n",
            " [ 0.08314183]\n",
            " [ 0.16093564]\n",
            " [ 0.25625902]\n",
            " [ 0.3219995 ]\n",
            " [ 0.39869738]\n",
            " [ 0.29570347]\n",
            " [ 0.3132347 ]\n",
            " [ 0.24639833]\n",
            " [ 0.26940745]\n",
            " [ 0.14778721]\n",
            " [ 0.09848125]\n",
            " [ 0.11820346]\n",
            " [ 0.14450032]\n",
            " [ 0.16750944]\n",
            " [ 0.334052  ]\n",
            " [ 0.2365368 ]\n",
            " [ 0.39979246]\n",
            " [ 0.61564094]\n",
            " [ 0.6517985 ]\n",
            " [ 0.61125815]\n",
            " [ 0.5509964 ]\n",
            " [ 0.39979246]\n",
            " [ 0.5531874 ]\n",
            " [ 0.69014704]\n",
            " [ 0.70877415]\n",
            " [ 0.66166   ]\n",
            " [ 0.5312742 ]\n",
            " [ 0.4666288 ]\n",
            " [ 0.5663358 ]\n",
            " [ 0.666042  ]\n",
            " [ 0.6517985 ]\n",
            " [ 0.67699945]\n",
            " [ 0.68686014]\n",
            " [ 0.7295915 ]\n",
            " [ 0.7011036 ]\n",
            " [ 0.7317833 ]\n",
            " [ 0.78875816]\n",
            " [ 0.6989126 ]\n",
            " [ 0.8391592 ]\n",
            " [ 0.88189054]\n",
            " [ 0.7843753 ]\n",
            " [ 0.71315616]\n",
            " [ 0.6748076 ]\n",
            " [ 0.78985405]\n",
            " [ 0.89503896]\n",
            " [ 0.8084804 ]\n",
            " [ 1.1108875 ]\n",
            " [ 1.1174613 ]\n",
            " [ 1.0670602 ]\n",
            " [ 1.0078936 ]\n",
            " [ 1.0243288 ]\n",
            " [ 0.97064096]\n",
            " [ 1.0024148 ]\n",
            " [ 1.0977391 ]\n",
            " [ 1.0911653 ]\n",
            " [ 0.9377703 ]\n",
            " [ 0.98378855]\n",
            " [ 0.947631  ]\n",
            " [ 1.047338  ]\n",
            " [ 1.173341  ]\n",
            " [ 1.0966431 ]\n",
            " [ 1.0550077 ]\n",
            " [ 0.9651622 ]\n",
            " [ 0.9761188 ]\n",
            " [ 1.0878783 ]\n",
            " [ 1.1558098 ]\n",
            " [ 1.1919674 ]\n",
            " [ 1.3672755 ]\n",
            " [ 1.2018288 ]\n",
            " [ 1.0363814 ]\n",
            " [ 0.95420563]\n",
            " [ 0.93010056]\n",
            " [ 1.0002239 ]\n",
            " [ 1.095548  ]\n",
            " [ 1.1678623 ]\n",
            " [ 1.1032177 ]\n",
            " [ 1.0133723 ]\n",
            " [ 0.97721475]\n",
            " [ 1.0451471 ]\n",
            " [ 0.995841  ]\n",
            " [ 0.89613485]\n",
            " [ 0.943249  ]\n",
            " [ 1.0539118 ]\n",
            " [ 0.9158571 ]\n",
            " [ 0.8796995 ]\n",
            " [ 0.87531674]\n",
            " [ 1.0133723 ]\n",
            " [ 0.93010056]\n",
            " [ 1.049529  ]\n",
            " [ 1.1086956 ]\n",
            " [ 1.147045  ]\n",
            " [ 1.199637  ]\n",
            " [ 1.2861956 ]\n",
            " [ 1.3442664 ]\n",
            " [ 1.3212572 ]\n",
            " [ 1.1371835 ]\n",
            " [ 1.2127855 ]\n",
            " [ 1.1580017 ]\n",
            " [ 1.1163653 ]\n",
            " [ 1.1086956 ]\n",
            " [ 1.0747299 ]\n",
            " [ 1.1590967 ]\n",
            " [ 1.0265199 ]\n",
            " [ 0.996937  ]\n",
            " [ 0.9629712 ]\n",
            " [ 0.94544   ]\n",
            " [ 1.0484339 ]\n",
            " [ 1.022137  ]\n",
            " [ 1.0571986 ]\n",
            " [ 0.92900467]\n",
            " [ 0.8282026 ]\n",
            " [ 0.9925541 ]\n",
            " [ 0.93996125]\n",
            " [ 0.8325854 ]\n",
            " [ 0.8019066 ]\n",
            " [ 0.921335  ]\n",
            " [ 0.8544986 ]\n",
            " [ 0.88846517]\n",
            " [ 0.86436015]\n",
            " [ 0.921335  ]\n",
            " [ 0.90489966]\n",
            " [ 0.93667436]\n",
            " [ 0.947631  ]\n",
            " [ 0.91366524]\n",
            " [ 0.8457338 ]\n",
            " [ 0.8479248 ]\n",
            " [ 0.8117673 ]\n",
            " [ 0.90051764]\n",
            " [ 1.0385724 ]\n",
            " [ 1.0506248 ]\n",
            " [ 0.8325854 ]\n",
            " [ 0.66275513]\n",
            " [ 0.5849621 ]\n",
            " [ 0.6791904 ]\n",
            " [ 0.74493086]\n",
            " [ 0.6539903 ]\n",
            " [ 0.6485116 ]\n",
            " [ 0.6167369 ]\n",
            " [ 0.5499005 ]\n",
            " [ 0.49730846]\n",
            " [ 0.4326631 ]\n",
            " [ 0.5575702 ]\n",
            " [ 0.6682338 ]\n",
            " [ 0.61125815]\n",
            " [ 0.61235404]\n",
            " [ 0.5915359 ]\n",
            " [ 0.4458115 ]\n",
            " [ 0.47977722]\n",
            " [ 0.58167523]\n",
            " [ 0.5400398 ]\n",
            " [ 0.05465483]\n",
            " [-0.41210386]\n",
            " [-0.24227357]\n",
            " [-0.05929569]\n",
            " [ 0.00315787]\n",
            " [-0.02313815]\n",
            " [-0.1359936 ]\n",
            " [-0.18639465]\n",
            " [-0.11079266]\n",
            " [-0.02752096]\n",
            " [-0.00560775]\n",
            " [ 0.01740137]\n",
            " [ 0.08642957]\n",
            " [ 0.13573469]\n",
            " [ 0.2409196 ]\n",
            " [ 0.26392874]\n",
            " [ 0.19490136]\n",
            " [ 0.01192349]\n",
            " [-0.01327746]\n",
            " [ 0.05355892]\n",
            " [-0.02204307]\n",
            " [-0.49208868]\n",
            " [-0.714511  ]\n",
            " [-0.7616251 ]\n",
            " [-0.7638161 ]\n",
            " [-0.6356221 ]\n",
            " [-0.48332307]\n",
            " [-0.39238164]\n",
            " [-0.28062293]\n",
            " [-0.17543805]\n",
            " [-0.11079266]\n",
            " [-0.18858562]\n",
            " [-0.19844715]\n",
            " [-0.06806131]\n",
            " [-0.01766026]\n",
            " [-0.02971278]\n",
            " [ 0.03602768]\n",
            " [-0.13380177]\n",
            " [-0.06587032]\n",
            " [ 0.02835798]\n",
            " [-0.02094716]\n",
            " [-0.1644806 ]\n",
            " [-0.31349275]\n",
            " [-0.4394958 ]\n",
            " [-0.359511  ]\n",
            " [-0.255422  ]\n",
            " [-0.41210386]\n",
            " [-0.792304  ]\n",
            " [-0.57426447]\n",
            " [-0.47894025]\n",
            " [-0.8843409 ]\n",
            " [-1.0749885 ]\n",
            " [-1.2930284 ]\n",
            " [-1.3193244 ]\n",
            " [-1.2809758 ]\n",
            " [-1.0136307 ]\n",
            " [-0.85804445]\n",
            " [-0.66301405]\n",
            " [-0.46798363]\n",
            " [-0.41429484]\n",
            " [-0.38799882]\n",
            " [-0.6958847 ]\n",
            " [-0.76929486]\n",
            " [-0.68383217]\n",
            " [-0.8700969 ]\n",
            " [-1.0300657 ]\n",
            " [-0.9051586 ]\n",
            " [-0.81750405]\n",
            " [-0.67397064]\n",
            " [-0.5698816 ]\n",
            " [-0.58960384]\n",
            " [-0.6487705 ]\n",
            " [-0.65972716]\n",
            " [-0.70793635]\n",
            " [-0.7188938 ]\n",
            " [-0.7933999 ]\n",
            " [-0.87995803]\n",
            " [-0.8262697 ]\n",
            " [-0.7287545 ]\n",
            " [-1.1462076 ]\n",
            " [-1.4091699 ]\n",
            " [-1.4036915 ]\n",
            " [-1.623923  ]\n",
            " [-1.4650496 ]\n",
            " [-1.481485  ]\n",
            " [-1.4606669 ]\n",
            " [-1.381778  ]\n",
            " [-2.0742462 ]\n",
            " [-2.359122  ]\n",
            " [-2.383227  ]\n",
            " [-2.3295388 ]\n",
            " [-2.1969619 ]\n",
            " [-1.9274254 ]\n",
            " [-1.6195401 ]\n",
            " [-1.3478122 ]\n",
            " [-1.1210071 ]\n",
            " [-1.0278744 ]\n",
            " [-0.9248808 ]\n",
            " [-0.8470878 ]\n",
            " [-0.9270722 ]\n",
            " [-1.3971177 ]\n",
            " [-1.6294012 ]\n",
            " [-1.6118704 ]\n",
            " [-1.3916391 ]\n",
            " [-1.5351729 ]\n",
            " [-1.6261144 ]\n",
            " [-1.507781  ]\n",
            " [-1.4146487 ]\n",
            " [-1.9591998 ]\n",
            " [-2.1673787 ]\n",
            " [-2.1125946 ]\n",
            " [-1.9975487 ]\n",
            " [-1.5844785 ]\n",
            " [-1.4606669 ]\n",
            " [-1.1637385 ]\n",
            " [-1.531886  ]\n",
            " [-1.3576733 ]\n",
            " [-1.2568709 ]\n",
            " [-1.6162533 ]\n",
            " [-1.2996022 ]\n",
            " [-1.3401425 ]\n",
            " [-1.7882744 ]\n",
            " [-1.95153   ]\n",
            " [-1.5088769 ]\n",
            " [-1.0837541 ]\n",
            " [-0.87228835]\n",
            " [-0.88543636]\n",
            " [-0.86900103]\n",
            " [-0.9391247 ]\n",
            " [-1.572426  ]\n",
            " [-1.3609602 ]\n",
            " [-1.3160375 ]\n",
            " [-1.381778  ]\n",
            " [-1.4497102 ]\n",
            " [-0.9117328 ]\n",
            " [-0.9654207 ]\n",
            " [-1.0278744 ]\n",
            " [-1.2930284 ]\n",
            " [-1.6206356 ]\n",
            " [-1.5910527 ]\n",
            " [-1.3609602 ]\n",
            " [-1.0552663 ]\n",
            " [-0.87228835]\n",
            " [-1.3565774 ]\n",
            " [-1.3916391 ]\n",
            " [-1.1812693 ]\n",
            " [-0.931455  ]\n",
            " [-0.67725754]\n",
            " [-0.67068374]\n",
            " [-0.45373932]\n",
            " [-0.4997584 ]\n",
            " [-0.461409  ]\n",
            " [-0.45702705]\n",
            " [-0.35184127]\n",
            " [-0.30253613]\n",
            " [-0.40333822]\n",
            " [-0.50523627]\n",
            " [-0.3584159 ]\n",
            " [-0.40443414]\n",
            " [-0.33869368]\n",
            " [-0.27185732]\n",
            " [-0.2861008 ]\n",
            " [-0.49866247]\n",
            " [-0.5424897 ]\n",
            " [-0.50194937]\n",
            " [-0.67506653]\n",
            " [-0.6323352 ]\n",
            " [-0.931455  ]\n",
            " [-1.0267788 ]\n",
            " [-1.0717015 ]\n",
            " [-0.86461824]\n",
            " [-0.77696455]\n",
            " [-1.1045718 ]\n",
            " [-1.1538774 ]\n",
            " [-1.2349576 ]\n",
            " [-0.7221807 ]\n",
            " [-0.45264423]\n",
            " [-0.39457345]\n",
            " [-0.29815334]\n",
            " [-0.12941897]\n",
            " [-0.12174926]\n",
            " [-0.13818458]\n",
            " [-0.2619958 ]\n",
            " [-0.3430765 ]\n",
            " [-0.32992807]\n",
            " [-0.21597756]\n",
            " [-0.02204307]\n",
            " [-0.08559171]\n",
            " [-0.05162599]\n",
            " [ 0.1324478 ]\n",
            " [ 0.232154  ]\n",
            " [ 0.26392874]\n",
            " [ 0.16750944]\n",
            " [-0.22693415]\n",
            " [-0.5753595 ]\n",
            " [-0.5183847 ]\n",
            " [-0.40114725]\n",
            " [-0.20502095]\n",
            " [-0.06915722]\n",
            " [-0.03190377]\n",
            " [ 0.14997819]\n",
            " [ 0.15874381]\n",
            " [-0.1316108 ]\n",
            " [-0.1579068 ]\n",
            " [-0.09326225]\n",
            " [-0.04395628]\n",
            " [ 0.1324478 ]\n",
            " [ 0.08204675]\n",
            " [-0.07354003]\n",
            " [-0.10312294]\n",
            " [ 0.0557499 ]\n",
            " [ 0.01521038]\n",
            " [-0.07682693]\n",
            " [ 0.0382195 ]\n",
            " [-0.049435  ]\n",
            " [-0.09874014]\n",
            " [ 0.05136793]\n",
            " [ 0.08204675]\n",
            " [ 0.04260231]\n",
            " [ 0.06561143]\n",
            " [ 0.17408322]\n",
            " [ 0.15874381]\n",
            " [ 0.26502463]\n",
            " [ 0.32857412]\n",
            " [ 0.4677247 ]\n",
            " [ 0.41074988]\n",
            " [ 0.42280242]\n",
            " [ 0.52689135]\n",
            " [ 0.6748076 ]\n",
            " [ 0.7021995 ]\n",
            " [ 0.7241136 ]\n",
            " [ 0.6452247 ]\n",
            " [ 0.38226205]\n",
            " [ 0.5071691 ]\n",
            " [ 0.7197308 ]\n",
            " [ 0.82272387]\n",
            " [ 0.537848  ]\n",
            " [ 0.27488533]\n",
            " [ 0.28474686]\n",
            " [ 0.3209044 ]\n",
            " [ 0.21900639]\n",
            " [ 0.23105891]\n",
            " [ 0.3417217 ]\n",
            " [ 0.4414287 ]\n",
            " [ 0.6068762 ]\n",
            " [ 0.6408419 ]\n",
            " [ 0.6309804 ]\n",
            " [ 0.49073383]\n",
            " [ 0.57729244]\n",
            " [ 0.57400554]\n",
            " [ 0.4666288 ]\n",
            " [ 0.65289444]\n",
            " [ 0.7558875 ]\n",
            " [ 0.8249157 ]\n",
            " [ 0.70439136]\n",
            " [ 0.4490984 ]\n",
            " [ 0.68357325]\n",
            " [ 0.71096516]\n",
            " [ 0.88189054]\n",
            " [ 0.9465359 ]\n",
            " [ 0.49402073]\n",
            " [ 0.29132065]\n",
            " [ 0.4129409 ]\n",
            " [ 0.68466914]\n",
            " [ 0.79642785]\n",
            " [ 0.5477095 ]\n",
            " [ 0.42389748]\n",
            " [ 0.02068827]\n",
            " [ 0.21133669]\n",
            " [ 0.4458115 ]\n",
            " [ 0.67699945]\n",
            " [ 0.87093395]\n",
            " [ 0.80409753]\n",
            " [ 1.0276158 ]\n",
            " [ 1.0144674 ]\n",
            " [ 1.0057026 ]\n",
            " [ 1.0396683 ]\n",
            " [ 1.098835  ]\n",
            " [ 1.178819  ]\n",
            " [ 1.199637  ]\n",
            " [ 1.1634796 ]\n",
            " [ 1.1580017 ]\n",
            " [ 1.0791128 ]\n",
            " [ 0.869838  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with Adam"
      ],
      "metadata": {
        "id": "BgKiljbpGvcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_rmse=1\n",
        "# Step 2: Create and train the MLP model\n",
        "# Modify the hyperparameters to adjust the model architecture and training process\n",
        "for roh in range(1,21):\n",
        "  mlp = MLPRegressor(hidden_layer_sizes=(roh), activation='relu', solver='adam', max_iter=100, random_state=0)\n",
        "  mlp.fit(X_train, y_train)\n",
        "  train_predictions = mlp.predict(X_train)\n",
        "  test_predictions = mlp.predict(X_test)\n",
        "  train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
        "  test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
        "  print(roh)\n",
        "  print(\"Training RMSE:\", train_rmse)\n",
        "  print(\"Testing RMSE:\", test_rmse)\n",
        "  if test_rmse < best_test_rmse:\n",
        "    best_test_rmse=test_rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=test_predictions\n",
        "ws1['B3']=best_hidden_size\n",
        "ws1['C3']=best_train_rmse\n",
        "ws1['D3']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws7['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws7['B{}'.format(i+2)] = float(prediction)\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxYaWsZGRZE8",
        "outputId": "ce1a83df-e103-468c-b37b-843460ed2500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Training RMSE: 0.55644906\n",
            "Testing RMSE: 0.5288904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Training RMSE: 0.43633527\n",
            "Testing RMSE: 0.4652451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Training RMSE: 0.44123632\n",
            "Testing RMSE: 0.46373972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "Training RMSE: 0.48568702\n",
            "Testing RMSE: 0.5229585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "Training RMSE: 0.64118606\n",
            "Testing RMSE: 0.6422695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "Training RMSE: 0.42297423\n",
            "Testing RMSE: 0.4571601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "Training RMSE: 0.44572842\n",
            "Testing RMSE: 0.4711104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "Training RMSE: 0.43935478\n",
            "Testing RMSE: 0.46240047\n",
            "9\n",
            "Training RMSE: 0.4693641\n",
            "Testing RMSE: 0.5127286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Training RMSE: 0.7004936\n",
            "Testing RMSE: 0.6986103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "Training RMSE: 0.43093145\n",
            "Testing RMSE: 0.4523169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "Training RMSE: 0.46465757\n",
            "Testing RMSE: 0.4973391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "Training RMSE: 0.5037193\n",
            "Testing RMSE: 0.552183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "Training RMSE: 0.5083541\n",
            "Testing RMSE: 0.53421885\n",
            "15\n",
            "Training RMSE: 0.4238452\n",
            "Testing RMSE: 0.45313814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "Training RMSE: 0.44479793\n",
            "Testing RMSE: 0.48885083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "Training RMSE: 0.43384168\n",
            "Testing RMSE: 0.43555406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "Training RMSE: 0.4299016\n",
            "Testing RMSE: 0.4854492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "Training RMSE: 0.43296534\n",
            "Testing RMSE: 0.4600932\n",
            "20\n",
            "Training RMSE: 0.44303742\n",
            "Testing RMSE: 0.45890936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with AdaBelief"
      ],
      "metadata": {
        "id": "B2Lc7oIKHUfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your data to tensors\n",
        "inputs_train = torch.tensor(X_train, dtype=torch.float)\n",
        "labels_train = torch.tensor(y_train, dtype=torch.float)\n",
        "inputs_test = torch.tensor(X_test, dtype=torch.float)\n",
        "labels_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "test_dataset = TensorDataset(inputs_test, labels_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  # Create ELM model\n",
        "  input_dim = inputs_train.shape[1]\n",
        "  hidden_dim = [roh]\n",
        "  output_dim = 1  # Set output_size to 1 for a single regression target\n",
        "\n",
        "  # Create an instance of the MLP model\n",
        "  model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "  # Define your loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print(\"hello\")\n",
        "  print(model.parameters())\n",
        "  # Create an instance of the AdaBelief optimizer\n",
        "  optimizer = AdaBelief(model.parameters(),lr=0.01, betas = (0.9,0.999), eps=1e-8, weight_decouple = True, rectify = False)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 100\n",
        "  best_loss = float('inf')  # Initialize with a very high loss\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      #print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
        "      # Check if current loss is the lowest so far\n",
        "      if avg_loss < best_loss:\n",
        "          best_loss = avg_loss\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "  # Load the state of the best model\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "\n",
        "  train_predictions=[]\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          train_predictions.extend(output.numpy())\n",
        "  train_predictions = np.array(train_predictions)\n",
        "  if roh==1:\n",
        "    labels_train = labels_train.numpy()\n",
        "  else:\n",
        "    labels_train = labels_train\n",
        "  # Load the state of the best model\n",
        "  train_rmse = np.sqrt(mean_squared_error(labels_train, train_predictions))\n",
        "\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          predictions.extend(output.numpy())\n",
        "\n",
        "  predictions = np.array(predictions)\n",
        "  if roh==1:\n",
        "    labels_test = labels_test.numpy()\n",
        "  else:\n",
        "    labels_test = labels_test\n",
        "  rmse = np.sqrt(mean_squared_error(labels_test, predictions))\n",
        "  print(roh)\n",
        "  print(f\"Test RMSE: {rmse}\")\n",
        "  print(\"train RMSE:\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=predictions\n",
        "ws1['E3']=best_hidden_size\n",
        "ws1['F3']=best_train_rmse\n",
        "ws1['G3']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws8['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws8['B{}'.format(i+2)] = float(prediction)\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrBvf2w1RZNe",
        "outputId": "61b1a0d0-4705-4dbf-b0b7-de6a07e694ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "1\n",
            "Test RMSE: 0.42040953040122986\n",
            "train RMSE: 1.3423388\n",
            "hello\n",
            "<generator object Module.parameters at 0x787695e8fa70>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "2\n",
            "Test RMSE: 0.9549409747123718\n",
            "train RMSE: 1.0128582\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "3\n",
            "Test RMSE: 0.4287091791629791\n",
            "train RMSE: 1.3488274\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "4\n",
            "Test RMSE: 0.45903822779655457\n",
            "train RMSE: 1.3703396\n",
            "hello\n",
            "<generator object Module.parameters at 0x787695e8fa70>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "5\n",
            "Test RMSE: 0.44530919194221497\n",
            "train RMSE: 1.3673955\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "6\n",
            "Test RMSE: 0.41724079847335815\n",
            "train RMSE: 1.3529451\n",
            "hello\n",
            "<generator object Module.parameters at 0x787695e8fa70>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "7\n",
            "Test RMSE: 0.4329972565174103\n",
            "train RMSE: 1.3381108\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "8\n",
            "Test RMSE: 0.4468061327934265\n",
            "train RMSE: 1.3972256\n",
            "hello\n",
            "<generator object Module.parameters at 0x787695e8fa70>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "9\n",
            "Test RMSE: 0.4662496745586395\n",
            "train RMSE: 1.3400182\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "10\n",
            "Test RMSE: 0.4371695816516876\n",
            "train RMSE: 1.3562922\n",
            "hello\n",
            "<generator object Module.parameters at 0x787695e8fa70>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "11\n",
            "Test RMSE: 0.5009174346923828\n",
            "train RMSE: 1.374657\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "12\n",
            "Test RMSE: 0.402065634727478\n",
            "train RMSE: 1.4052181\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "13\n",
            "Test RMSE: 0.4101032614707947\n",
            "train RMSE: 1.4082733\n",
            "hello\n",
            "<generator object Module.parameters at 0x787695e8fa70>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "14\n",
            "Test RMSE: 0.4537658393383026\n",
            "train RMSE: 1.3673043\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "15\n",
            "Test RMSE: 0.38796520233154297\n",
            "train RMSE: 1.3686024\n",
            "hello\n",
            "<generator object Module.parameters at 0x787695e8fa70>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "16\n",
            "Test RMSE: 0.4851788282394409\n",
            "train RMSE: 1.4298463\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "17\n",
            "Test RMSE: 0.4750412106513977\n",
            "train RMSE: 1.3757796\n",
            "hello\n",
            "<generator object Module.parameters at 0x787695e8fa70>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "18\n",
            "Test RMSE: 0.39131540060043335\n",
            "train RMSE: 1.344288\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767efd85f0>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "19\n",
            "Test RMSE: 0.4675293564796448\n",
            "train RMSE: 1.3911828\n",
            "hello\n",
            "<generator object Module.parameters at 0x787695e8fa70>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "20\n",
            "Test RMSE: 0.37462538480758667\n",
            "train RMSE: 1.3630308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with RangerAdaBelief"
      ],
      "metadata": {
        "id": "YDhukbeaHnHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your data to tensors\n",
        "inputs_train = torch.tensor(X_train, dtype=torch.float)\n",
        "labels_train = torch.tensor(y_train, dtype=torch.float)\n",
        "inputs_test = torch.tensor(X_test, dtype=torch.float)\n",
        "labels_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "test_dataset = TensorDataset(inputs_test, labels_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  # Create ELM model\n",
        "  input_dim = inputs_train.shape[1]\n",
        "  hidden_dim = [roh]\n",
        "  output_dim = 1  # Set output_size to 1 for a single regression target\n",
        "\n",
        "  # Create an instance of the MLP model\n",
        "  model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "  # Define your loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print(\"hello\")\n",
        "  print(model.parameters())\n",
        "  # Create an instance of the AdaBelief optimizer\n",
        "  optimizer = RangerAdaBelief(model.parameters(), lr=1e-2, eps=1e-12, betas=(0.9,0.999),weight_decouple = False)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 100\n",
        "  best_loss = float('inf')  # Initialize with a very high loss\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      #print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
        "      # Check if current loss is the lowest so far\n",
        "      if avg_loss < best_loss:\n",
        "          best_loss = avg_loss\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "  # Load the state of the best model\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "\n",
        "  train_predictions=[]\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          train_predictions.extend(output.numpy())\n",
        "  train_predictions = np.array(train_predictions)\n",
        "  if roh==1:\n",
        "    labels_train = labels_train.numpy()\n",
        "  else:\n",
        "    labels_train = labels_train\n",
        "  # Load the state of the best model\n",
        "  train_rmse = np.sqrt(mean_squared_error(labels_train, train_predictions))\n",
        "\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          predictions.extend(output.numpy())\n",
        "\n",
        "  predictions = np.array(predictions)\n",
        "  if roh==1:\n",
        "    labels_test = labels_test.numpy()\n",
        "  else:\n",
        "    labels_test = labels_test\n",
        "  rmse = np.sqrt(mean_squared_error(labels_test, predictions))\n",
        "  print(roh)\n",
        "  print(f\"Test RMSE: {rmse}\")\n",
        "  print(\"train RMSE:\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=predictions\n",
        "\n",
        "ws1['H3']=best_hidden_size\n",
        "ws1['I3']=best_train_rmse\n",
        "ws1['J3']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws9['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws9['B{}'.format(i+2)] = float(prediction)\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "id": "lYMCkywsRZP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2f459a-4582-40f5-bc22-39a3a5670da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "<generator object Module.parameters at 0x78767aee9150>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "1\n",
            "Test RMSE: 0.561600387096405\n",
            "train RMSE: 1.3785999\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee94d0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "2\n",
            "Test RMSE: 0.504366934299469\n",
            "train RMSE: 1.3783522\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee92a0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "3\n",
            "Test RMSE: 0.43661388754844666\n",
            "train RMSE: 1.3496143\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee95b0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "4\n",
            "Test RMSE: 0.5012459754943848\n",
            "train RMSE: 1.3645748\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee93f0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "5\n",
            "Test RMSE: 0.4537319242954254\n",
            "train RMSE: 1.3898367\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee8f90>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "6\n",
            "Test RMSE: 0.45503097772598267\n",
            "train RMSE: 1.3375057\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee9150>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "7\n",
            "Test RMSE: 0.47037145495414734\n",
            "train RMSE: 1.3825936\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee94d0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "8\n",
            "Test RMSE: 0.45068106055259705\n",
            "train RMSE: 1.3410017\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee92a0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "9\n",
            "Test RMSE: 0.47308871150016785\n",
            "train RMSE: 1.3696412\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee95b0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "10\n",
            "Test RMSE: 0.44939589500427246\n",
            "train RMSE: 1.3599505\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee93f0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "11\n",
            "Test RMSE: 0.4683954119682312\n",
            "train RMSE: 1.3163007\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee8f90>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "12\n",
            "Test RMSE: 0.444886714220047\n",
            "train RMSE: 1.3890655\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee9150>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "13\n",
            "Test RMSE: 0.40917953848838806\n",
            "train RMSE: 1.3764932\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee94d0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "14\n",
            "Test RMSE: 0.4677625894546509\n",
            "train RMSE: 1.3583972\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee92a0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "15\n",
            "Test RMSE: 0.46638551354408264\n",
            "train RMSE: 1.3721578\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee95b0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "16\n",
            "Test RMSE: 0.41391217708587646\n",
            "train RMSE: 1.4029921\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee93f0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "17\n",
            "Test RMSE: 0.39191997051239014\n",
            "train RMSE: 1.4030918\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee8f90>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "18\n",
            "Test RMSE: 0.3963852822780609\n",
            "train RMSE: 1.3767647\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee9150>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "19\n",
            "Test RMSE: 0.4323120415210724\n",
            "train RMSE: 1.3292621\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767aee94d0>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "20\n",
            "Test RMSE: 0.4301810562610626\n",
            "train RMSE: 1.4216748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "oJfPb8G9IE6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we pass our data to the Conv1D layer, we have to reshape it in order to make sure it works\n",
        "x = tf.constant(X_train)\n",
        "expand_dims_layer = layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) # add an extra dimension for timesteps\n",
        "print(f\"Original shape: {x.shape}\") # (WINDOW_SIZE)\n",
        "print(f\"Expanded shape: {expand_dims_layer(x).shape}\") # (WINDOW_SIZE, input_dim)\n",
        "print(f\"Original values with expanded shape:\\n {expand_dims_layer(x)}\")\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create model\n",
        "model_7 = tf.keras.Sequential([\n",
        "  # Create Lambda layer to reshape inputs, without this layer, the model will error\n",
        "  layers.Lambda(lambda x: tf.expand_dims(x, axis=1)), # resize the inputs to adjust for window size / Conv1D 3D input requirements\n",
        "  layers.Conv1D(filters=12, kernel_size=5, padding=\"causal\", activation=\"relu\"),\n",
        "  layers.Dense(HORIZON)\n",
        "], name=\"model_7_conv1D\")\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "# Fit model\n",
        "model_7.fit(X_train,\n",
        "            y_train,\n",
        "            batch_size=128,\n",
        "            epochs=100,\n",
        "            verbose=0,\n",
        "            validation_data=(X_test, y_test),\n",
        "            callbacks=[create_model_checkpoint(model_name=model_7.name)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PISVxRkfHhvs",
        "outputId": "cfd8089e-eef7-45dd-998e-91d4d927cc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (2833, 3)\n",
            "Expanded shape: (2833, 1, 3)\n",
            "Original values with expanded shape:\n",
            " [[[ 5.2777395  7.064147   7.686953 ]]\n",
            "\n",
            " [[ 3.760841   7.037383   8.778119 ]]\n",
            "\n",
            " [[ 3.9987442  7.0571957  8.612235 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 8.403631   3.6383753  4.625739 ]]\n",
            "\n",
            " [[ 9.366631   5.143866   4.5672317]]\n",
            "\n",
            " [[10.334435   7.454608   5.063755 ]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78767e7dd750>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTaKIESDHiLP",
        "outputId": "c19faa3c-181e-4eaa-9010-032402e79ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2135 - root_mean_squared_error: 0.4621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21353715658187866, 0.4621008038520813]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # Let's build an LSTM model with the Functional API\n",
        "  inputs = layers.Input(shape=(3))\n",
        "  x = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(inputs) # expand input dimension to be compatible with LSTM\n",
        "  # print(x.shape)\n",
        "  # x = layers.LSTM(128, activation=\"relu\", return_sequences=True)(x) # this layer will error if the inputs are not the right shape\n",
        "  x = layers.LSTM(roh, activation=\"relu\")(x) # using the tanh loss function results in a massive error\n",
        "  # print(x.shape)\n",
        "\n",
        "\n",
        "  output = layers.Dense(HORIZON)(x)\n",
        "  model_8 = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_8_lstm\")\n",
        "\n",
        "  # Compile model\n",
        "  model_8.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  # Seems when saving the model several warnings are appearing: https://github.com/tensorflow/tensorflow/issues/47554\n",
        "  model_8.fit(X_train,\n",
        "              y_train,\n",
        "              epochs=100,\n",
        "              verbose=0,\n",
        "              batch_size=128,\n",
        "              validation_data=(X_test, y_test),\n",
        "              callbacks=[create_model_checkpoint(model_name=model_8.name)])\n",
        "  print(roh)\n",
        "  rmse=model_8.evaluate(X_test, y_test)\n",
        "  rmse=rmse[1]\n",
        "  print(\"test rmse\",rmse)\n",
        "  train_rmse=model_8.evaluate(X_train, y_train)\n",
        "  train_rmse=train_rmse[1]\n",
        "  print(\"train rmse\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=model_8.predict(X_test)\n",
        "\n",
        "ws1['K3']=best_hidden_size\n",
        "ws1['L3']=best_train_rmse\n",
        "ws1['M3']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws10['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws10['B{}'.format(i+2)] = float(prediction)\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq0sXFVQIH9T",
        "outputId": "36350194-d83e-42ff-c013-a8a23c4f9adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2815 - root_mean_squared_error: 0.5306\n",
            "test rmse 0.5305757522583008\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.2655 - root_mean_squared_error: 0.5152\n",
            "train rmse 0.5152348279953003\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2463 - root_mean_squared_error: 0.4963\n",
            "test rmse 0.49633485078811646\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.2257 - root_mean_squared_error: 0.4750\n",
            "train rmse 0.4750312864780426\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2090 - root_mean_squared_error: 0.4572\n",
            "test rmse 0.4572189748287201\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1682 - root_mean_squared_error: 0.4101\n",
            "train rmse 0.4100867509841919\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2153 - root_mean_squared_error: 0.4640\n",
            "test rmse 0.46403995156288147\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1698 - root_mean_squared_error: 0.4121\n",
            "train rmse 0.41212552785873413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2109 - root_mean_squared_error: 0.4593\n",
            "test rmse 0.4592660367488861\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1845 - root_mean_squared_error: 0.4295\n",
            "train rmse 0.4295089840888977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2112 - root_mean_squared_error: 0.4596\n",
            "test rmse 0.45960018038749695\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1794 - root_mean_squared_error: 0.4235\n",
            "train rmse 0.4235471189022064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2031 - root_mean_squared_error: 0.4506\n",
            "test rmse 0.45063862204551697\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1958 - root_mean_squared_error: 0.4425\n",
            "train rmse 0.442514032125473\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2079 - root_mean_squared_error: 0.4560\n",
            "test rmse 0.4559720754623413\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1784 - root_mean_squared_error: 0.4224\n",
            "train rmse 0.42235246300697327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2242 - root_mean_squared_error: 0.4735\n",
            "test rmse 0.473471999168396\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1957 - root_mean_squared_error: 0.4424\n",
            "train rmse 0.4423941969871521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2125 - root_mean_squared_error: 0.4610\n",
            "test rmse 0.46098729968070984\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1899 - root_mean_squared_error: 0.4358\n",
            "train rmse 0.435807466506958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2051 - root_mean_squared_error: 0.4529\n",
            "test rmse 0.4528919756412506\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1688 - root_mean_squared_error: 0.4108\n",
            "train rmse 0.4108318090438843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2084 - root_mean_squared_error: 0.4565\n",
            "test rmse 0.45650869607925415\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1730 - root_mean_squared_error: 0.4160\n",
            "train rmse 0.4159916639328003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2104 - root_mean_squared_error: 0.4587\n",
            "test rmse 0.4587171971797943\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1699 - root_mean_squared_error: 0.4121\n",
            "train rmse 0.41214194893836975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2008 - root_mean_squared_error: 0.4481\n",
            "test rmse 0.4480630159378052\n",
            "89/89 [==============================] - 0s 3ms/step - loss: 0.1640 - root_mean_squared_error: 0.4050\n",
            "train rmse 0.40501710772514343\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2064 - root_mean_squared_error: 0.4543\n",
            "test rmse 0.45428571105003357\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1722 - root_mean_squared_error: 0.4150\n",
            "train rmse 0.41501614451408386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2033 - root_mean_squared_error: 0.4509\n",
            "test rmse 0.4508562684059143\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1696 - root_mean_squared_error: 0.4118\n",
            "train rmse 0.4118330776691437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2010 - root_mean_squared_error: 0.4483\n",
            "test rmse 0.4483252167701721\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1706 - root_mean_squared_error: 0.4131\n",
            "train rmse 0.41305768489837646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2052 - root_mean_squared_error: 0.4530\n",
            "test rmse 0.4530199468135834\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1699 - root_mean_squared_error: 0.4122\n",
            "train rmse 0.4121972620487213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2099 - root_mean_squared_error: 0.4582\n",
            "test rmse 0.45820143818855286\n",
            "89/89 [==============================] - 0s 3ms/step - loss: 0.1694 - root_mean_squared_error: 0.4115\n",
            "train rmse 0.41153234243392944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2031 - root_mean_squared_error: 0.4507\n",
            "test rmse 0.4506945013999939\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1705 - root_mean_squared_error: 0.4129\n",
            "train rmse 0.41287368535995483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N-Beats"
      ],
      "metadata": {
        "id": "76EA7yg5Isg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "train_labels_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
        "\n",
        "test_features_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "test_labels_dataset = tf.data.Dataset.from_tensor_slices(y_test)\n",
        "\n",
        "# 2. Combine features & labels\n",
        "train_dataset = tf.data.Dataset.zip((train_features_dataset, train_labels_dataset))\n",
        "test_dataset = tf.data.Dataset.zip((test_features_dataset, test_labels_dataset))\n",
        "\n",
        "# 3. Batch and prefetch for optimal performance\n",
        "BATCH_SIZE = 1024 # taken from Appendix D in N-BEATS paper\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "id": "jtEkYWL8IIAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb32699e-3d6d-430f-92c0-2ebc0059be71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
              " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  # Values from N-BEATS paper Figure 1 and Table 18/Appendix D\n",
        "  N_EPOCHS = 100 # called \"Iterations\" in Table 18\n",
        "  N_NEURONS = roh # called \"Width\" in Table 18\n",
        "  N_LAYERS = 2\n",
        "  N_STACKS = 1\n",
        "  INPUT_SIZE = WINDOW_SIZE * HORIZON # called \"Lookback\" in Table 18\n",
        "  THETA_SIZE = INPUT_SIZE + HORIZON\n",
        "\n",
        "  INPUT_SIZE, THETA_SIZE\n",
        "\n",
        "\n",
        "  # %%time\n",
        "\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # 1. Setup N-BEATS Block layer\n",
        "  nbeats_block_layer = NBeatsBlock(input_size=INPUT_SIZE,\n",
        "                                  theta_size=THETA_SIZE,\n",
        "                                  horizon=HORIZON,\n",
        "                                  n_neurons=N_NEURONS,\n",
        "                                  n_layers=N_LAYERS,\n",
        "                                  name=\"InitialBlock\")\n",
        "\n",
        "  # 2. Create input to stacks\n",
        "  stack_input = layers.Input(shape=(3), name=\"stack_input\")\n",
        "\n",
        "  # 3. Create initial backcast and forecast input (backwards predictions are referred to as residuals in the paper)\n",
        "  backcast, forecast = nbeats_block_layer(stack_input)\n",
        "  # Add in subtraction residual link, thank you to: https://github.com/mrdbourke/tensorflow-deep-learning/discussions/174\n",
        "  residuals = layers.subtract([stack_input, backcast], name=f\"subtract_00\")\n",
        "\n",
        "  # 4. Create stacks of blocks\n",
        "  for i, _ in enumerate(range(N_STACKS-1)): # first stack is already creted in (3)\n",
        "\n",
        "    # 5. Use the NBeatsBlock to calculate the backcast as well as block forecast\n",
        "    backcast, block_forecast = NBeatsBlock(\n",
        "        input_size=INPUT_SIZE,\n",
        "        theta_size=THETA_SIZE,\n",
        "        horizon=HORIZON,\n",
        "        n_neurons=N_NEURONS,\n",
        "        n_layers=N_LAYERS,\n",
        "        name=f\"NBeatsBlock_{i}\"\n",
        "    )(residuals) # pass it in residuals (the backcast)\n",
        "\n",
        "    # 6. Create the double residual stacking\n",
        "    residuals = layers.subtract([residuals, backcast], name=f\"subtract_{i}\")\n",
        "    forecast = layers.add([forecast, block_forecast], name=f\"add_{i}\")\n",
        "\n",
        "  # 7. Put the stack model together\n",
        "  model_9 = tf.keras.Model(inputs=stack_input,\n",
        "                          outputs=forecast,\n",
        "                          name=\"model_9_N-BEATS\")\n",
        "\n",
        "  # 8. Compile with MAE loss and Adam optimizer\n",
        "  model_9.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  # 9. Fit the model with EarlyStopping and ReduceLROnPlateau callbacks\n",
        "  model_9.fit(train_dataset,\n",
        "              epochs=N_EPOCHS,\n",
        "              validation_data=test_dataset,\n",
        "              verbose=0, # prevent large amounts of training outputs\n",
        "              # callbacks=[create_model_checkpoint(model_name=stack_model.name)] # saving model every epoch consumes far too much time\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100, verbose=1)])\n",
        "  print(roh)\n",
        "  # Evaluate N-BEATS model on the test dataset\n",
        "  rmse=model_9.evaluate(test_dataset)\n",
        "  rmse=rmse[1]\n",
        "  print(\"test RMSE:\",rmse)\n",
        "  train_rmse=model_9.evaluate(train_dataset)\n",
        "  train_rmse=train_rmse[1]\n",
        "  print(\"train RMSE:\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=model_9.predict(X_test)\n",
        "\n",
        "ws1['N3']=best_hidden_size\n",
        "ws1['O3']=best_train_rmse\n",
        "ws1['P3']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws11['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws11['B{}'.format(i+2)] = float(prediction)\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "id": "F8X99iD_IIG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0cc27bd-f886-45bc-90cf-f74787580b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9082 - root_mean_squared_error: 0.9530\n",
            "test RMSE: 0.9530202746391296\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.0258 - root_mean_squared_error: 1.0128\n",
            "train RMSE: 1.0128064155578613\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "2\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9245 - root_mean_squared_error: 0.9615\n",
            "test RMSE: 0.9614877700805664\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.0314 - root_mean_squared_error: 1.0156\n",
            "train RMSE: 1.0155980587005615\n",
            "3\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8915 - root_mean_squared_error: 0.9442\n",
            "test RMSE: 0.9441664218902588\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.9664 - root_mean_squared_error: 0.9831\n",
            "train RMSE: 0.9830785393714905\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "4\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7793 - root_mean_squared_error: 0.8828\n",
            "test RMSE: 0.8827567100524902\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7906 - root_mean_squared_error: 0.8892\n",
            "train RMSE: 0.8891680240631104\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "5\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1205 - root_mean_squared_error: 1.0586\n",
            "test RMSE: 1.0585553646087646\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.9699 - root_mean_squared_error: 0.9848\n",
            "train RMSE: 0.9848129749298096\n",
            "6\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2472 - root_mean_squared_error: 0.4972\n",
            "test RMSE: 0.49720704555511475\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2287 - root_mean_squared_error: 0.4782\n",
            "train RMSE: 0.47820553183555603\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "7\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6832 - root_mean_squared_error: 0.8266\n",
            "test RMSE: 0.8265624642372131\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.8796 - root_mean_squared_error: 0.9379\n",
            "train RMSE: 0.9378939867019653\n",
            "8\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3437 - root_mean_squared_error: 0.5863\n",
            "test RMSE: 0.5862655639648438\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3507 - root_mean_squared_error: 0.5922\n",
            "train RMSE: 0.5921670198440552\n",
            "9\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2424 - root_mean_squared_error: 0.4923\n",
            "test RMSE: 0.49233242869377136\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2195 - root_mean_squared_error: 0.4685\n",
            "train RMSE: 0.46847814321517944\n",
            "23/23 [==============================] - 0s 3ms/step\n",
            "10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2490 - root_mean_squared_error: 0.4990\n",
            "test RMSE: 0.4990447461605072\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2222 - root_mean_squared_error: 0.4714\n",
            "train RMSE: 0.4713846445083618\n",
            "11\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2500 - root_mean_squared_error: 0.5000\n",
            "test RMSE: 0.5000260472297668\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2198 - root_mean_squared_error: 0.4688\n",
            "train RMSE: 0.46878618001937866\n",
            "12\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2261 - root_mean_squared_error: 0.4755\n",
            "test RMSE: 0.4754727780818939\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2047 - root_mean_squared_error: 0.4524\n",
            "train RMSE: 0.45238280296325684\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "13\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2429 - root_mean_squared_error: 0.4928\n",
            "test RMSE: 0.49284765124320984\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2089 - root_mean_squared_error: 0.4571\n",
            "train RMSE: 0.45710113644599915\n",
            "14\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2699 - root_mean_squared_error: 0.5195\n",
            "test RMSE: 0.5194745659828186\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2501 - root_mean_squared_error: 0.5001\n",
            "train RMSE: 0.5000686645507812\n",
            "15\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2469 - root_mean_squared_error: 0.4969\n",
            "test RMSE: 0.49686911702156067\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2117 - root_mean_squared_error: 0.4602\n",
            "train RMSE: 0.4601564109325409\n",
            "16\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2506 - root_mean_squared_error: 0.5006\n",
            "test RMSE: 0.5006458759307861\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2116 - root_mean_squared_error: 0.4600\n",
            "train RMSE: 0.45996344089508057\n",
            "17\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2404 - root_mean_squared_error: 0.4903\n",
            "test RMSE: 0.49030062556266785\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2136 - root_mean_squared_error: 0.4622\n",
            "train RMSE: 0.4622081518173218\n",
            "18\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2354 - root_mean_squared_error: 0.4852\n",
            "test RMSE: 0.48516231775283813\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2101 - root_mean_squared_error: 0.4583\n",
            "train RMSE: 0.45832759141921997\n",
            "19\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2325 - root_mean_squared_error: 0.4822\n",
            "test RMSE: 0.48217013478279114\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2047 - root_mean_squared_error: 0.4524\n",
            "train RMSE: 0.4524330198764801\n",
            "20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2272 - root_mean_squared_error: 0.4767\n",
            "test RMSE: 0.47667956352233887\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1962 - root_mean_squared_error: 0.4429\n",
            "train RMSE: 0.44294577836990356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fEI6dmQRHiON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stability** **Selection** with **Random** **Forest** **Regressor**"
      ],
      "metadata": {
        "id": "cHgT0WGLK6MU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "wtdhNDcZVn4v",
        "outputId": "1d6f1787-0e6f-40e7-f0d7-5c606fe5413e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  Tsoil avg-10cm  (F)  \\\n",
              "Period                                                                      \n",
              "2013-10-23         64.54         49.50         74.88                75.06   \n",
              "2013-10-24         55.81         46.71         70.52                70.90   \n",
              "2013-10-25         57.63         44.17         73.71                69.71   \n",
              "2013-10-26         55.54         43.03         72.10                69.17   \n",
              "2013-10-27         56.08         41.13         74.44                68.75   \n",
              "...                  ...           ...           ...                  ...   \n",
              "2023-07-04         82.29         72.63         96.03                82.89   \n",
              "2023-07-05         83.59         73.24         93.70                82.56   \n",
              "2023-07-06         82.61         75.49         93.33                82.51   \n",
              "2023-07-07         80.43         73.02         93.65                81.79   \n",
              "2023-07-08         81.38         73.06         92.86                79.88   \n",
              "\n",
              "            Tsoil min(avg)-10cm  (F)  Tsoil max(avg)-10cm  (F)  \\\n",
              "Period                                                           \n",
              "2013-10-23                     72.81                     76.64   \n",
              "2013-10-24                     69.15                     72.68   \n",
              "2013-10-25                     67.19                     72.41   \n",
              "2013-10-26                     66.58                     71.98   \n",
              "2013-10-27                     65.97                     71.64   \n",
              "...                              ...                       ...   \n",
              "2023-07-04                     79.41                     86.88   \n",
              "2023-07-05                     79.27                     85.78   \n",
              "2023-07-06                     79.95                     85.91   \n",
              "2023-07-07                     78.75                     85.01   \n",
              "2023-07-08                     76.62                     83.93   \n",
              "\n",
              "            2m DewPt avg (F)  RelHum avg 2m  (pct)  2m Rain tot (in)  \\\n",
              "Period                                                                 \n",
              "2013-10-23             57.11                  81.0              0.02   \n",
              "2013-10-24             46.72                  75.0              0.00   \n",
              "2013-10-25             49.45                  78.0              0.00   \n",
              "2013-10-26             46.68                  76.0              0.00   \n",
              "2013-10-27             47.10                  78.0              0.00   \n",
              "...                      ...                   ...               ...   \n",
              "2023-07-04             74.57                  80.0              0.04   \n",
              "2023-07-05             75.47                  78.0              0.00   \n",
              "2023-07-06             76.08                  82.0              0.00   \n",
              "2023-07-07             74.57                  83.0              3.55   \n",
              "2023-07-08             75.19                  83.0              0.01   \n",
              "\n",
              "            SolRad avg2m  (w/m^2)  10m Wind avg (mph)  10m Wind min (mph)  \\\n",
              "Period                                                                      \n",
              "2013-10-23                 177.63                4.90                0.06   \n",
              "2013-10-24                 146.94                2.32                0.02   \n",
              "2013-10-25                 181.08                2.83                0.00   \n",
              "2013-10-26                 181.64                2.57                0.06   \n",
              "2013-10-27                 181.23                1.93                0.02   \n",
              "...                           ...                 ...                 ...   \n",
              "2023-07-04                 279.92                3.02                0.05   \n",
              "2023-07-05                 250.34                3.21                0.00   \n",
              "2023-07-06                 223.97                3.62                0.02   \n",
              "2023-07-07                 213.76                4.53                0.00   \n",
              "2023-07-08                 277.76                4.61                0.02   \n",
              "\n",
              "            10m Wind max (mph)  BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
              "Period                                                                \n",
              "2013-10-23               16.94         1009     0.08           59.97  \n",
              "2013-10-24               10.66         1016     0.10           50.91  \n",
              "2013-10-25               12.82         1019     0.08           53.06  \n",
              "2013-10-26               10.36         1018     0.07           50.77  \n",
              "2013-10-27               11.32         1016     0.07           51.21  \n",
              "...                        ...          ...      ...             ...  \n",
              "2023-07-04               25.05         1015     0.21           76.66  \n",
              "2023-07-05               13.58         1015     0.19           77.62  \n",
              "2023-07-06               15.75         1013     0.18           77.80  \n",
              "2023-07-07               40.15         1011     0.17           76.16  \n",
              "2023-07-08               23.71         1011     0.20           76.85  \n",
              "\n",
              "[3542 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-a8a8f01b-8a0b-4b72-84e9-3165cdd56465\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>Tsoil avg-10cm  (F)</th>\n",
              "      <th>Tsoil min(avg)-10cm  (F)</th>\n",
              "      <th>Tsoil max(avg)-10cm  (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>RelHum avg 2m  (pct)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>SolRad avg2m  (w/m^2)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>10m Wind min (mph)</th>\n",
              "      <th>10m Wind max (mph)</th>\n",
              "      <th>BP avg (mb)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.54</td>\n",
              "      <td>49.50</td>\n",
              "      <td>74.88</td>\n",
              "      <td>75.06</td>\n",
              "      <td>72.81</td>\n",
              "      <td>76.64</td>\n",
              "      <td>57.11</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>177.63</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.94</td>\n",
              "      <td>1009</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.81</td>\n",
              "      <td>46.71</td>\n",
              "      <td>70.52</td>\n",
              "      <td>70.90</td>\n",
              "      <td>69.15</td>\n",
              "      <td>72.68</td>\n",
              "      <td>46.72</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>146.94</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.66</td>\n",
              "      <td>1016</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.63</td>\n",
              "      <td>44.17</td>\n",
              "      <td>73.71</td>\n",
              "      <td>69.71</td>\n",
              "      <td>67.19</td>\n",
              "      <td>72.41</td>\n",
              "      <td>49.45</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.08</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.82</td>\n",
              "      <td>1019</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.54</td>\n",
              "      <td>43.03</td>\n",
              "      <td>72.10</td>\n",
              "      <td>69.17</td>\n",
              "      <td>66.58</td>\n",
              "      <td>71.98</td>\n",
              "      <td>46.68</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.64</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10.36</td>\n",
              "      <td>1018</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.08</td>\n",
              "      <td>41.13</td>\n",
              "      <td>74.44</td>\n",
              "      <td>68.75</td>\n",
              "      <td>65.97</td>\n",
              "      <td>71.64</td>\n",
              "      <td>47.10</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.23</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.32</td>\n",
              "      <td>1016</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-04</th>\n",
              "      <td>82.29</td>\n",
              "      <td>72.63</td>\n",
              "      <td>96.03</td>\n",
              "      <td>82.89</td>\n",
              "      <td>79.41</td>\n",
              "      <td>86.88</td>\n",
              "      <td>74.57</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.04</td>\n",
              "      <td>279.92</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>25.05</td>\n",
              "      <td>1015</td>\n",
              "      <td>0.21</td>\n",
              "      <td>76.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>83.59</td>\n",
              "      <td>73.24</td>\n",
              "      <td>93.70</td>\n",
              "      <td>82.56</td>\n",
              "      <td>79.27</td>\n",
              "      <td>85.78</td>\n",
              "      <td>75.47</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>250.34</td>\n",
              "      <td>3.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.58</td>\n",
              "      <td>1015</td>\n",
              "      <td>0.19</td>\n",
              "      <td>77.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>82.61</td>\n",
              "      <td>75.49</td>\n",
              "      <td>93.33</td>\n",
              "      <td>82.51</td>\n",
              "      <td>79.95</td>\n",
              "      <td>85.91</td>\n",
              "      <td>76.08</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>223.97</td>\n",
              "      <td>3.62</td>\n",
              "      <td>0.02</td>\n",
              "      <td>15.75</td>\n",
              "      <td>1013</td>\n",
              "      <td>0.18</td>\n",
              "      <td>77.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>80.43</td>\n",
              "      <td>73.02</td>\n",
              "      <td>93.65</td>\n",
              "      <td>81.79</td>\n",
              "      <td>78.75</td>\n",
              "      <td>85.01</td>\n",
              "      <td>74.57</td>\n",
              "      <td>83.0</td>\n",
              "      <td>3.55</td>\n",
              "      <td>213.76</td>\n",
              "      <td>4.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>40.15</td>\n",
              "      <td>1011</td>\n",
              "      <td>0.17</td>\n",
              "      <td>76.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-08</th>\n",
              "      <td>81.38</td>\n",
              "      <td>73.06</td>\n",
              "      <td>92.86</td>\n",
              "      <td>79.88</td>\n",
              "      <td>76.62</td>\n",
              "      <td>83.93</td>\n",
              "      <td>75.19</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>277.76</td>\n",
              "      <td>4.61</td>\n",
              "      <td>0.02</td>\n",
              "      <td>23.71</td>\n",
              "      <td>1011</td>\n",
              "      <td>0.20</td>\n",
              "      <td>76.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3542 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8a8f01b-8a0b-4b72-84e9-3165cdd56465')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-21d46844-719b-495b-b877-68c6e88353a0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21d46844-719b-495b-b877-68c6e88353a0')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-21d46844-719b-495b-b877-68c6e88353a0 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8a8f01b-8a0b-4b72-84e9-3165cdd56465 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8a8f01b-8a0b-4b72-84e9-3165cdd56465');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "1j1Ti_a1Vn7F",
        "outputId": "cc3b6acb-ff4b-4dde-ce2c-f303ee396c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
              "Period                                                                   \n",
              "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
              "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
              "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
              "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
              "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
              "\n",
              "            RelHum avg 2m  (pct)  2m Rain tot (in)  SolRad avg2m  (w/m^2)  \\\n",
              "Period                                                                      \n",
              "2013-10-23                  81.0              0.02             177.630005   \n",
              "2013-10-24                  75.0              0.00             146.940002   \n",
              "2013-10-25                  78.0              0.00             181.080002   \n",
              "2013-10-26                  76.0              0.00             181.639999   \n",
              "2013-10-27                  78.0              0.00             181.229996   \n",
              "\n",
              "            10m Wind avg (mph)  10m Wind min (mph)  10m Wind max (mph)  \\\n",
              "Period                                                                   \n",
              "2013-10-23                4.90                0.06           16.940001   \n",
              "2013-10-24                2.32                0.02           10.660000   \n",
              "2013-10-25                2.83                0.00           12.820000   \n",
              "2013-10-26                2.57                0.06           10.360000   \n",
              "2013-10-27                1.93                0.02           11.320000   \n",
              "\n",
              "            BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
              "Period                                            \n",
              "2013-10-23       1009.0     0.08       59.970001  \n",
              "2013-10-24       1016.0     0.10       50.910000  \n",
              "2013-10-25       1019.0     0.08       53.060001  \n",
              "2013-10-26       1018.0     0.07       50.770000  \n",
              "2013-10-27       1016.0     0.07       51.209999  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3988d4ee-f533-48ff-b0d0-1130d6129cc1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>RelHum avg 2m  (pct)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>SolRad avg2m  (w/m^2)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>10m Wind min (mph)</th>\n",
              "      <th>10m Wind max (mph)</th>\n",
              "      <th>BP avg (mb)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.540001</td>\n",
              "      <td>49.500000</td>\n",
              "      <td>74.879997</td>\n",
              "      <td>57.110001</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>177.630005</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.940001</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.810001</td>\n",
              "      <td>46.709999</td>\n",
              "      <td>70.519997</td>\n",
              "      <td>46.720001</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>146.940002</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.660000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.630001</td>\n",
              "      <td>44.169998</td>\n",
              "      <td>73.709999</td>\n",
              "      <td>49.450001</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.080002</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.820000</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.060001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.540001</td>\n",
              "      <td>43.029999</td>\n",
              "      <td>72.099998</td>\n",
              "      <td>46.680000</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.639999</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10.360000</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.080002</td>\n",
              "      <td>41.130001</td>\n",
              "      <td>74.440002</td>\n",
              "      <td>47.099998</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.229996</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.320000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.209999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3988d4ee-f533-48ff-b0d0-1130d6129cc1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-20417df6-eaf5-427f-b4eb-a99caa447039\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20417df6-eaf5-427f-b4eb-a99caa447039')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-20417df6-eaf5-427f-b4eb-a99caa447039 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3988d4ee-f533-48ff-b0d0-1130d6129cc1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3988d4ee-f533-48ff-b0d0-1130d6129cc1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Bry32DNVn9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "y = y.to_numpy()\n",
        "# Define the number of subsamples and iterations\n",
        "n_subsamples = 100  # Number of subsamples\n",
        "n_iterations = 10  # Number of iterations for each subsample\n",
        "\n",
        "# Define the number of bins for discretization\n",
        "n_bins = 5  # Number of bins for discretization\n",
        "\n",
        "# Perform discretization\n",
        "discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal')\n",
        "y_discrete = discretizer.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Create an array to store the feature selection scores\n",
        "feature_scores = np.zeros(X.shape[1])\n",
        "\n",
        "# Stability selection loop\n",
        "for _ in range(n_subsamples):\n",
        "    # Generate a random subsample with replacement\n",
        "    X_subsample, y_subsample = resample(X, y_discrete, replace=True)\n",
        "\n",
        "    # Initialize an array to store the feature importances for each iteration\n",
        "    iteration_scores = np.zeros(X.shape[1])\n",
        "\n",
        "    # Random Forest feature selection\n",
        "    for _ in range(n_iterations):\n",
        "        model = RandomForestClassifier(n_estimators=100)\n",
        "        model.fit(X_subsample, y_subsample)\n",
        "        iteration_scores += model.feature_importances_\n",
        "\n",
        "    # Accumulate the feature importances\n",
        "    feature_scores += iteration_scores / n_iterations\n",
        "\n",
        "# Calculate the average feature importances\n",
        "average_scores = feature_scores / n_subsamples\n",
        "\n",
        "# Set a threshold to determine the selected features\n",
        "threshold = 0.85  # Set your desired threshold\n",
        "\n",
        "# Select the features based on the threshold\n",
        "selected_features = np.where(average_scores > threshold)[0]\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Selected Features:\", selected_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__J3Gf_uVn_G",
        "outputId": "4d0e1603-4118-4ff9-abdc-7afa1564a817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_D8nWIh7JYd",
        "outputId": "39b789d5-9ece-4706-edc1-193908496e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.17154711, 0.11181347, 0.1099453 , 0.1003745 , 0.03992627,\n",
              "       0.01894832, 0.06779263, 0.05106441, 0.03792909, 0.04808669,\n",
              "       0.03985203, 0.0718571 , 0.13086307])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = [f\"feature {i}\" for i in range(X.shape[1])]\n",
        "feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSjeTLkz9UOV",
        "outputId": "a862bcb2-673c-4d0b-aa7e-3b93a4b2c8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['feature 0',\n",
              " 'feature 1',\n",
              " 'feature 2',\n",
              " 'feature 3',\n",
              " 'feature 4',\n",
              " 'feature 5',\n",
              " 'feature 6',\n",
              " 'feature 7',\n",
              " 'feature 8',\n",
              " 'feature 9',\n",
              " 'feature 10',\n",
              " 'feature 11',\n",
              " 'feature 12']"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forest_importances = pd.Series(average_scores, index=feature_names)"
      ],
      "metadata": {
        "id": "omBbCZkN9LiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest_importances"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaJ2lRay9cro",
        "outputId": "0ee9cd54-aac0-4688-cfbe-352109706dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature 0     0.171547\n",
              "feature 1     0.111813\n",
              "feature 2     0.109945\n",
              "feature 3     0.100375\n",
              "feature 4     0.039926\n",
              "feature 5     0.018948\n",
              "feature 6     0.067793\n",
              "feature 7     0.051064\n",
              "feature 8     0.037929\n",
              "feature 9     0.048087\n",
              "feature 10    0.039852\n",
              "feature 11    0.071857\n",
              "feature 12    0.130863\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)"
      ],
      "metadata": {
        "id": "L4fcYmnb9qnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "urpXr11291oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "forest_importances.plot.bar(yerr=std, ax=ax)\n",
        "ax.set_title(\"Feature importances using MDI\")\n",
        "ax.set_ylabel(\"Mean decrease in impurity\")\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ZQ8WgJ1-9uuC",
        "outputId": "23a9cd76-8f01-48d0-c4f4-681ce7d45db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance"
      ],
      "metadata": {
        "id": "poCVKu1-CCAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "QEhyz3AQCefO",
        "outputId": "91006857-a545-4fb9-d727-0abbf1791057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0c1cdefd54ea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "y = y.to_numpy()\n",
        "# Define the number of subsamples and iterations\n",
        "n_subsamples = 100  # Number of subsamples\n",
        "n_iterations = 10  # Number of iterations for each subsample\n",
        "\n",
        "# Define the number of bins for discretization\n",
        "n_bins = 5  # Number of bins for discretization\n",
        "\n",
        "# Perform discretization\n",
        "discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal')\n",
        "y_discrete = discretizer.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Create an array to store the feature selection scores\n",
        "feature_scores = np.zeros(X.shape[1])\n",
        "\n",
        "# Stability selection loop\n",
        "for _ in range(n_subsamples):\n",
        "    # Generate a random subsample with replacement\n",
        "    X_subsample, y_subsample = resample(X, y_discrete, replace=True)\n",
        "\n",
        "    # Initialize an array to store the feature importances for each iteration\n",
        "    iteration_scores = np.zeros(X.shape[1])\n",
        "\n",
        "    # Permutation importance calculation\n",
        "    for _ in range(n_iterations):\n",
        "        model1 = RandomForestClassifier(n_estimators=100)\n",
        "        model1.fit(X_subsample, y_subsample)\n",
        "        perm_scores = permutation_importance(model1, X_subsample, y_subsample, n_repeats=10, random_state=0)\n",
        "        iteration_scores += perm_scores.importances_mean\n",
        "\n",
        "    # Accumulate the feature importances\n",
        "    feature_scores += iteration_scores / n_iterations\n",
        "\n",
        "# Calculate the average feature importances\n",
        "average_scores = feature_scores / n_subsamples\n",
        "\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Selected Features:\", average_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUlSqLgMCCC1",
        "outputId": "5810d4ab-e9ec-4771-f425-2dcaafd93ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: [0.0549889  0.03326008 0.03664898 0.00773187 0.00367493 0.00129218\n",
            " 0.01978213 0.00943526 0.00759876 0.00770881 0.00865655 0.04935121\n",
            " 0.01863495]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8UsUYLnrCCFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RnDaDSi8Y2T",
        "outputId": "770fd2bf-77c4-4607-b304-5ead2f8f728c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3542, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "yNIsRuj_8eKM",
        "outputId": "280af71e-4e92-47fa-9669-7933c1556c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
              "Period                                                                   \n",
              "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
              "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
              "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
              "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
              "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
              "\n",
              "            RelHum avg 2m  (pct)  2m Rain tot (in)  SolRad avg2m  (w/m^2)  \\\n",
              "Period                                                                      \n",
              "2013-10-23                  81.0              0.02             177.630005   \n",
              "2013-10-24                  75.0              0.00             146.940002   \n",
              "2013-10-25                  78.0              0.00             181.080002   \n",
              "2013-10-26                  76.0              0.00             181.639999   \n",
              "2013-10-27                  78.0              0.00             181.229996   \n",
              "\n",
              "            10m Wind avg (mph)  10m Wind min (mph)  10m Wind max (mph)  \\\n",
              "Period                                                                   \n",
              "2013-10-23                4.90                0.06           16.940001   \n",
              "2013-10-24                2.32                0.02           10.660000   \n",
              "2013-10-25                2.83                0.00           12.820000   \n",
              "2013-10-26                2.57                0.06           10.360000   \n",
              "2013-10-27                1.93                0.02           11.320000   \n",
              "\n",
              "            BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
              "Period                                            \n",
              "2013-10-23       1009.0     0.08       59.970001  \n",
              "2013-10-24       1016.0     0.10       50.910000  \n",
              "2013-10-25       1019.0     0.08       53.060001  \n",
              "2013-10-26       1018.0     0.07       50.770000  \n",
              "2013-10-27       1016.0     0.07       51.209999  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f7d912d5-b5e0-4821-94c8-f8b1c30ce45e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>RelHum avg 2m  (pct)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>SolRad avg2m  (w/m^2)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>10m Wind min (mph)</th>\n",
              "      <th>10m Wind max (mph)</th>\n",
              "      <th>BP avg (mb)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.540001</td>\n",
              "      <td>49.500000</td>\n",
              "      <td>74.879997</td>\n",
              "      <td>57.110001</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>177.630005</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.940001</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.810001</td>\n",
              "      <td>46.709999</td>\n",
              "      <td>70.519997</td>\n",
              "      <td>46.720001</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>146.940002</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.660000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.630001</td>\n",
              "      <td>44.169998</td>\n",
              "      <td>73.709999</td>\n",
              "      <td>49.450001</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.080002</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.820000</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.060001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.540001</td>\n",
              "      <td>43.029999</td>\n",
              "      <td>72.099998</td>\n",
              "      <td>46.680000</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.639999</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10.360000</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.080002</td>\n",
              "      <td>41.130001</td>\n",
              "      <td>74.440002</td>\n",
              "      <td>47.099998</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.229996</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.320000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.209999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7d912d5-b5e0-4821-94c8-f8b1c30ce45e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-66199923-83ef-43df-a6db-51b02cbb6963\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66199923-83ef-43df-a6db-51b02cbb6963')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-66199923-83ef-43df-a6db-51b02cbb6963 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7d912d5-b5e0-4821-94c8-f8b1c30ce45e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7d912d5-b5e0-4821-94c8-f8b1c30ce45e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[X.columns[[0,1,2,3,12]]]"
      ],
      "metadata": {
        "id": "vf1z9OXL8LoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "-qanlP4E8Lqo",
        "outputId": "d118fc3a-7f6c-41ee-db23-85af7d22e14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
              "Period                                                                   \n",
              "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
              "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
              "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
              "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
              "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
              "\n",
              "            2m WetBulb (F)  \n",
              "Period                      \n",
              "2013-10-23       59.970001  \n",
              "2013-10-24       50.910000  \n",
              "2013-10-25       53.060001  \n",
              "2013-10-26       50.770000  \n",
              "2013-10-27       51.209999  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-eefc51a5-418b-4921-865c-6fb7179d6913\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.540001</td>\n",
              "      <td>49.500000</td>\n",
              "      <td>74.879997</td>\n",
              "      <td>57.110001</td>\n",
              "      <td>59.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.810001</td>\n",
              "      <td>46.709999</td>\n",
              "      <td>70.519997</td>\n",
              "      <td>46.720001</td>\n",
              "      <td>50.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.630001</td>\n",
              "      <td>44.169998</td>\n",
              "      <td>73.709999</td>\n",
              "      <td>49.450001</td>\n",
              "      <td>53.060001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.540001</td>\n",
              "      <td>43.029999</td>\n",
              "      <td>72.099998</td>\n",
              "      <td>46.680000</td>\n",
              "      <td>50.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.080002</td>\n",
              "      <td>41.130001</td>\n",
              "      <td>74.440002</td>\n",
              "      <td>47.099998</td>\n",
              "      <td>51.209999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eefc51a5-418b-4921-865c-6fb7179d6913')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-5e07fc40-b227-4144-8c9f-8756c68095f1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e07fc40-b227-4144-8c9f-8756c68095f1')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-5e07fc40-b227-4144-8c9f-8756c68095f1 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eefc51a5-418b-4921-865c-6fb7179d6913 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eefc51a5-418b-4921-865c-6fb7179d6913');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klXvi2My8Lsx",
        "outputId": "3af595b9-2805-40a9-c73f-677ce0072f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Period\n",
              "2013-10-23    75.059998\n",
              "2013-10-24    70.900002\n",
              "2013-10-25    69.709999\n",
              "2013-10-26    69.169998\n",
              "2013-10-27    68.750000\n",
              "Name: Tsoil avg-10cm  (F), dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWOA0INH8Luw",
        "outputId": "71e4b9cd-282d-4b8c-f55d-ca3cb56d3e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3542,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "P54KNTUH85ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make train and test sets\n",
        "split_size = int(len(X) * 0.8)\n",
        "X_train, y_train = X_scaled[:split_size], y_scaled[:split_size]\n",
        "X_test, y_test = X_scaled[split_size:], y_scaled[split_size:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc17xppI85pB",
        "outputId": "665f4329-35e6-40de-b734-48b56464a9a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2833, 2833, 709, 709)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "        in_features = input_size\n",
        "        for hidden_size in hidden_sizes:\n",
        "            self.hidden_layers.append(nn.Linear(in_features, hidden_size))\n",
        "            self.hidden_layers.append(nn.ReLU())\n",
        "            in_features = hidden_size\n",
        "        self.output_layer = nn.Linear(in_features, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = layer(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "SQtmu19t85xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from adabelief_pytorch import AdaBelief\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "import pandas as pd\n",
        "from torch.nn.init import xavier_uniform_\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# Assuming y is your target variable\n",
        "\n",
        "# Step 2: Feature selection\n",
        "# Perform feature selection techniques such as selecting top-k features based on feature importance or domain knowledge\n",
        "\n",
        "# Convert your data to tensors\n",
        "inputs_train = torch.tensor(X_train, dtype=torch.float)\n",
        "labels_train = torch.tensor(y_train, dtype=torch.float)\n",
        "inputs_test = torch.tensor(X_test, dtype=torch.float)\n",
        "labels_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "test_dataset = TensorDataset(inputs_test, labels_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "for roh in range(1,21):\n",
        "  # Create ELM model\n",
        "  input_dim = inputs_train.shape[1]\n",
        "  hidden_dim = [roh]\n",
        "  output_dim = 1  # Set output_size to 1 for a single regression target\n",
        "\n",
        "  # Create an instance of the MLP model\n",
        "  model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "  # Define your loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print(\"hello\")\n",
        "  print(model.parameters())\n",
        "  # Create an instance of the AdaBelief optimizer\n",
        "  optimizer = AdaBelief(model.parameters(), lr=0.0005, eps=1e-16, betas=(0.9, 0.999), weight_decouple=False, rectify=False)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 100\n",
        "  best_loss = float('inf')  # Initialize with a very high loss\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      #print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
        "      # Check if current loss is the lowest so far\n",
        "      if avg_loss < best_loss:\n",
        "          best_loss = avg_loss\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "  # Load the state of the best model\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          predictions.extend(output.numpy())\n",
        "\n",
        "  predictions = np.array(predictions)\n",
        "  if roh==1:\n",
        "    labels_test = labels_test.numpy()\n",
        "  else:\n",
        "    labels_test = labels_test\n",
        "  rmse = np.sqrt(mean_squared_error(labels_test, predictions))\n",
        "  print(roh)\n",
        "  print(f\"Test RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF4W2kO885zO",
        "outputId": "74de9156-e9fa-4b21-904a-6ac90e8e56b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "1\n",
            "Test RMSE: 0.4526866674423218\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "2\n",
            "Test RMSE: 0.446797639131546\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "3\n",
            "Test RMSE: 0.4344451129436493\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "4\n",
            "Test RMSE: 0.39966481924057007\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "5\n",
            "Test RMSE: 0.4016519784927368\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "6\n",
            "Test RMSE: 0.395170658826828\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "7\n",
            "Test RMSE: 0.3841233551502228\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "8\n",
            "Test RMSE: 0.38886338472366333\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "9\n",
            "Test RMSE: 0.3926445245742798\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "10\n",
            "Test RMSE: 0.3862500786781311\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "11\n",
            "Test RMSE: 0.3888522684574127\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "12\n",
            "Test RMSE: 0.3889608681201935\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "13\n",
            "Test RMSE: 0.3827357590198517\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "14\n",
            "Test RMSE: 0.3889676630496979\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "15\n",
            "Test RMSE: 0.3829188942909241\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "16\n",
            "Test RMSE: 0.37991344928741455\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "17\n",
            "Test RMSE: 0.38068684935569763\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "18\n",
            "Test RMSE: 0.38234439492225647\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "19\n",
            "Test RMSE: 0.3768804371356964\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888350>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "20\n",
            "Test RMSE: 0.39203986525535583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from adabelief_pytorch import AdaBelief\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "import pandas as pd\n",
        "from torch.optim import SGD, Adam, RMSprop\n",
        "from torch.nn.init import xavier_uniform_\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# Assuming y is your target variable\n",
        "\n",
        "# Step 2: Feature selection\n",
        "# Perform feature selection techniques such as selecting top-k features based on feature importance or domain knowledge\n",
        "\n",
        "# Convert your data to tensors\n",
        "inputs_train = torch.tensor(X_train, dtype=torch.float)\n",
        "labels_train = torch.tensor(y_train, dtype=torch.float)\n",
        "inputs_test = torch.tensor(X_test, dtype=torch.float)\n",
        "labels_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "test_dataset = TensorDataset(inputs_test, labels_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "for roh in range(15,21):\n",
        "  # Create ELM model\n",
        "  input_dim = inputs_train.shape[1]\n",
        "  hidden_dim = [roh]\n",
        "  output_dim = 1  # Set output_size to 1 for a single regression target\n",
        "\n",
        "  # Create an instance of the MLP model\n",
        "  model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "  # Define your loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print(\"hello\")\n",
        "  print(model.parameters())\n",
        "  # Create an instance of the AdaBelief optimizer\n",
        "  optimizer = Adam(model.parameters(), lr=0.00005)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 100\n",
        "  best_loss = float('inf')  # Initialize with a very high loss\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      #print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
        "      # Check if current loss is the lowest so far\n",
        "      if avg_loss < best_loss:\n",
        "          best_loss = avg_loss\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "  # Load the state of the best model\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          predictions.extend(output.numpy())\n",
        "\n",
        "  predictions = np.array(predictions)\n",
        "  if roh==1:\n",
        "    labels_test = labels_test.numpy()\n",
        "  else:\n",
        "    labels_test = labels_test\n",
        "  rmse = np.sqrt(mean_squared_error(labels_test, predictions))\n",
        "  print(roh)\n",
        "  print(f\"Test RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4tUSaleOFQm",
        "outputId": "523797da-d53f-45b9-bb94-6c8073fe7bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888740>\n",
            "15\n",
            "Test RMSE: 0.4048241972923279\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888740>\n",
            "16\n",
            "Test RMSE: 0.4117588400840759\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888740>\n",
            "17\n",
            "Test RMSE: 0.4026045501232147\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888740>\n",
            "18\n",
            "Test RMSE: 0.40728652477264404\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888740>\n",
            "19\n",
            "Test RMSE: 0.4008120894432068\n",
            "hello\n",
            "<generator object Module.parameters at 0x7f3463888740>\n",
            "20\n",
            "Test RMSE: 0.4134555757045746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQCe-kPA851V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE=1\n",
        "HORIZON=1"
      ],
      "metadata": {
        "id": "I42b6kkJ855n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Create a function to implement a ModelCheckpoint callback with a specific filename\n",
        "def create_model_checkpoint(model_name, save_path=\"model_experiments\"):\n",
        "  return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, model_name), # create filepath to save model\n",
        "                                            verbose=0, # only output a limited amount of text\n",
        "                                            save_best_only=True) # save only the best model to file"
      ],
      "metadata": {
        "id": "mBBkNVfL8576"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we pass our data to the Conv1D layer, we have to reshape it in order to make sure it works\n",
        "x = tf.constant(X_train)\n",
        "expand_dims_layer = layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) # add an extra dimension for timesteps\n",
        "print(f\"Original shape: {x.shape}\") # (WINDOW_SIZE)\n",
        "print(f\"Expanded shape: {expand_dims_layer(x).shape}\") # (WINDOW_SIZE, input_dim)\n",
        "print(f\"Original values with expanded shape:\\n {expand_dims_layer(x)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYifcM6A85-T",
        "outputId": "b0dfe044-fdbe-4224-bc83-bdc8bd5868ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (2833, 5)\n",
            "Expanded shape: (2833, 1, 5)\n",
            "Original values with expanded shape:\n",
            " [[[-0.4032232  -0.7458762  -0.53653353 -0.4248603  -0.4421828 ]]\n",
            "\n",
            " [[-1.2142386  -0.9646546  -0.9517654  -1.2762262  -1.2763008 ]]\n",
            "\n",
            " [[-1.045161   -1.1638292  -0.64796025 -1.0525275  -1.0783588 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.8657881   1.2097985   0.6939246   1.1369331   1.0990016 ]]\n",
            "\n",
            " [[ 0.84627926  1.1651019   0.8205888   1.0828525   1.0502068 ]]\n",
            "\n",
            " [[ 0.99027425  1.1690223   1.0320144   1.0894073   1.093478  ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create model\n",
        "model_8 = tf.keras.Sequential([\n",
        "  # Create Lambda layer to reshape inputs, without this layer, the model will error\n",
        "  layers.Lambda(lambda x: tf.expand_dims(x, axis=1)), # resize the inputs to adjust for window size / Conv1D 3D input requirements\n",
        "  layers.Conv1D(filters=128, kernel_size=5, padding=\"causal\", activation=\"relu\"),\n",
        "  layers.Dense(HORIZON)\n",
        "], name=\"model_8_conv1D\")\n",
        "\n",
        "# Compile model\n",
        "model_8.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "# Fit model\n",
        "model_8.fit(X_train,\n",
        "            y_train,\n",
        "            batch_size=128,\n",
        "            epochs=10,\n",
        "            verbose=0,\n",
        "            validation_data=(X_test, y_test),\n",
        "            callbacks=[create_model_checkpoint(model_name=model_8.name)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945snx8o86Ab",
        "outputId": "5e499f32-11c4-4c8f-cb0c-d37fb8fb3f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3479551450>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6GLC3jo86Cw",
        "outputId": "4c3dfbb8-96b1-4bb2-aad3-ff855523bae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1548 - root_mean_squared_error: 0.3935\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1548454761505127, 0.3935041129589081]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Let's build an LSTM model with the Functional API\n",
        "inputs = layers.Input(shape=(5))\n",
        "x = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(inputs) # expand input dimension to be compatible with LSTM\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(128, activation=\"relu\", return_sequences=True)(x) # this layer will error if the inputs are not the right shape\n",
        "x = layers.LSTM(128, activation=\"relu\")(x) # using the tanh loss function results in a massive error\n",
        "# print(x.shape)\n",
        "\n",
        "\n",
        "output = layers.Dense(HORIZON)(x)\n",
        "model_9 = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_9_lstm\")\n",
        "\n",
        "# Compile model\n",
        "model_9.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "# Seems when saving the model several warnings are appearing: https://github.com/tensorflow/tensorflow/issues/47554\n",
        "model_9.fit(X_train,\n",
        "            y_train,\n",
        "            epochs=100,\n",
        "            verbose=0,\n",
        "            batch_size=128,\n",
        "            validation_data=(X_test, y_test),\n",
        "            callbacks=[create_model_checkpoint(model_name=model_9.name)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YVGhsm9_T4O",
        "outputId": "1ae23eab-79ee-4869-b4d4-391daa0feb83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3478d29f60>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_9.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zHEZY4g_T6o",
        "outputId": "53c12a12-afc2-496e-d8a8-f90a349115a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1441 - root_mean_squared_error: 0.3796\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14412009716033936, 0.37963151931762695]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create NBeatsBlock custom layer\n",
        "class NBeatsBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, # the constructor takes all the hyperparameters for the layer\n",
        "               input_size: int,\n",
        "               theta_size: int,\n",
        "               horizon: int,\n",
        "               n_neurons: int,\n",
        "               n_layers: int,\n",
        "               **kwargs): # the **kwargs argument takes care of all of the arguments for the parent class (input_shape, trainable, name)\n",
        "    super().__init__(**kwargs)\n",
        "    self.input_size = input_size\n",
        "    self.theta_size = theta_size\n",
        "    self.horizon = horizon\n",
        "    self.n_neurons = n_neurons\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    # Block contains stack of 4 fully connected layers each has ReLU activation\n",
        "    self.hidden = [tf.keras.layers.Dense(n_neurons, activation=\"relu\") for _ in range(n_layers)]\n",
        "    # Output of block is a theta layer with linear activation\n",
        "    self.theta_layer = tf.keras.layers.Dense(theta_size, activation=\"linear\", name=\"theta\")\n",
        "\n",
        "  def call(self, inputs): # the call method is what runs when the layer is called\n",
        "    x = inputs\n",
        "    for layer in self.hidden: # pass inputs through each hidden layer\n",
        "      x = layer(x)\n",
        "    theta = self.theta_layer(x)\n",
        "    # Output the backcast and forecast from theta\n",
        "    backcast, forecast = theta[:, :self.input_size], theta[:, -self.horizon:]\n",
        "    return backcast, forecast\n",
        "\n",
        "# Set up dummy NBeatsBlock layer to represent inputs and outputs\n",
        "dummy_nbeats_block_layer = NBeatsBlock(input_size=WINDOW_SIZE,\n",
        "                                       theta_size=WINDOW_SIZE+HORIZON, # backcast + forecast\n",
        "                                       horizon=HORIZON,\n",
        "                                       n_neurons=128,\n",
        "                                       n_layers=4)\n",
        "\n",
        "\n",
        "# Create dummy inputs (have to be same size as input_size)\n",
        "dummy_inputs = tf.expand_dims(tf.range(WINDOW_SIZE) + 1, axis=0) # input shape to the model has to reflect Dense layer input requirements (ndim=2)\n",
        "print(dummy_inputs)\n",
        "\n",
        "# Pass dummy inputs to dummy NBeatsBlock layer\n",
        "backcast, forecast = dummy_nbeats_block_layer(dummy_inputs)\n",
        "# These are the activation outputs of the theta layer (they'll be random due to no training of the model)\n",
        "print(f\"Backcast: {tf.squeeze(backcast.numpy())}\")\n",
        "print(f\"Forecast: {tf.squeeze(forecast.numpy())}\")"
      ],
      "metadata": {
        "id": "7fvzrkLE_T8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "train_labels_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
        "\n",
        "test_features_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "test_labels_dataset = tf.data.Dataset.from_tensor_slices(y_test)\n",
        "\n",
        "# 2. Combine features & labels\n",
        "train_dataset = tf.data.Dataset.zip((train_features_dataset, train_labels_dataset))\n",
        "test_dataset = tf.data.Dataset.zip((test_features_dataset, test_labels_dataset))\n",
        "\n",
        "# 3. Batch and prefetch for optimal performance\n",
        "BATCH_SIZE = 1024 # taken from Appendix D in N-BEATS paper\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD6YdJjZ_dQ4",
        "outputId": "b74228a2-92fc-4a46-b503-c8bf246edf96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
              " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for roh in range(15,21):\n",
        "  # Values from N-BEATS paper Figure 1 and Table 18/Appendix D\n",
        "  N_EPOCHS = 100 # called \"Iterations\" in Table 18\n",
        "  N_NEURONS = roh # called \"Width\" in Table 18\n",
        "  N_LAYERS = 20\n",
        "  N_STACKS = 10\n",
        "  INPUT_SIZE = WINDOW_SIZE * HORIZON # called \"Lookback\" in Table 18\n",
        "  THETA_SIZE = INPUT_SIZE + HORIZON\n",
        "\n",
        "  INPUT_SIZE, THETA_SIZE\n",
        "\n",
        "\n",
        "  # %%time\n",
        "\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # 1. Setup N-BEATS Block layer\n",
        "  nbeats_block_layer = NBeatsBlock(input_size=INPUT_SIZE,\n",
        "                                  theta_size=THETA_SIZE,\n",
        "                                  horizon=HORIZON,\n",
        "                                  n_neurons=N_NEURONS,\n",
        "                                  n_layers=N_LAYERS,\n",
        "                                  name=\"InitialBlock\")\n",
        "\n",
        "  # 2. Create input to stacks\n",
        "  stack_input = layers.Input(shape=(5), name=\"stack_input\")\n",
        "\n",
        "  # 3. Create initial backcast and forecast input (backwards predictions are referred to as residuals in the paper)\n",
        "  backcast, forecast = nbeats_block_layer(stack_input)\n",
        "  # Add in subtraction residual link, thank you to: https://github.com/mrdbourke/tensorflow-deep-learning/discussions/174\n",
        "  residuals = layers.subtract([stack_input, backcast], name=f\"subtract_00\")\n",
        "\n",
        "  # 4. Create stacks of blocks\n",
        "  for i, _ in enumerate(range(N_STACKS-1)): # first stack is already creted in (3)\n",
        "\n",
        "    # 5. Use the NBeatsBlock to calculate the backcast as well as block forecast\n",
        "    backcast, block_forecast = NBeatsBlock(\n",
        "        input_size=INPUT_SIZE,\n",
        "        theta_size=THETA_SIZE,\n",
        "        horizon=HORIZON,\n",
        "        n_neurons=N_NEURONS,\n",
        "        n_layers=N_LAYERS,\n",
        "        name=f\"NBeatsBlock_{i}\"\n",
        "    )(residuals) # pass it in residuals (the backcast)\n",
        "\n",
        "    # 6. Create the double residual stacking\n",
        "    residuals = layers.subtract([residuals, backcast], name=f\"subtract_{i}\")\n",
        "    forecast = layers.add([forecast, block_forecast], name=f\"add_{i}\")\n",
        "\n",
        "  # 7. Put the stack model together\n",
        "  model_11 = tf.keras.Model(inputs=stack_input,\n",
        "                          outputs=forecast,\n",
        "                          name=\"model_11_N-BEATS\")\n",
        "\n",
        "  # 8. Compile with MAE loss and Adam optimizer\n",
        "  model_11.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  # 9. Fit the model with EarlyStopping and ReduceLROnPlateau callbacks\n",
        "  model_11.fit(train_dataset,\n",
        "              epochs=N_EPOCHS,\n",
        "              validation_data=test_dataset,\n",
        "              verbose=0, # prevent large amounts of training outputs\n",
        "              # callbacks=[create_model_checkpoint(model_name=stack_model.name)] # saving model every epoch consumes far too much time\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100, verbose=1)])\n",
        "  print(roh)\n",
        "  # Evaluate N-BEATS model on the test dataset\n",
        "  model_11.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "2qgbuUtj_dTF",
        "outputId": "0461db0a-b2b4-4633-8207-dc50d78aabaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1376 - root_mean_squared_error: 0.3710\n",
            "16\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1349 - root_mean_squared_error: 0.3673\n",
            "17\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1435 - root_mean_squared_error: 0.3788\n",
            "18\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1409 - root_mean_squared_error: 0.3754\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-8cc7bfb59135>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;31m# 9. Fit the model with EarlyStopping and ReduceLROnPlateau callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   model_11.fit(train_dataset,\n\u001b[0m\u001b[1;32m     60\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RFE"
      ],
      "metadata": {
        "id": "6ZdU6EmcJgb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "\n",
        "# Create the estimator for RFE\n",
        "estimator = LinearRegression()\n",
        "\n",
        "# Create the RFE model\n",
        "rfe_selector = RFE(estimator, n_features_to_select=5)\n",
        "\n",
        "# Fit the RFE model\n",
        "rfe_selector.fit(X, y)\n",
        "\n",
        "# Get the mask of selected features\n",
        "selected_features_mask = rfe_selector.support_\n",
        "\n",
        "# Get the indices of selected features\n",
        "selected_features_indices = [i for i, selected in enumerate(selected_features_mask) if selected]\n",
        "\n",
        "# Print the selected features\n",
        "selected_features = [f\"Feature {i}\" for i in selected_features_indices]\n",
        "print(\"Selected Features:\", selected_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uei8_VC87Rsh",
        "outputId": "384f67ac-b9ce-4ba1-ad4a-f94356501f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: ['Feature 0', 'Feature 3', 'Feature 8', 'Feature 11', 'Feature 12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RFECV"
      ],
      "metadata": {
        "id": "nHimOUTvJiNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entropy** **Theory**"
      ],
      "metadata": {
        "id": "0gx51ALOLGNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "3hfDzIWVtI_q",
        "outputId": "11f62096-2bb0-4bf4-b6ee-e78f588faea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  Tsoil avg-10cm  (F)  \\\n",
              "Period                                                                      \n",
              "2013-10-23         64.54         49.50         74.88                75.06   \n",
              "2013-10-24         55.81         46.71         70.52                70.90   \n",
              "2013-10-25         57.63         44.17         73.71                69.71   \n",
              "2013-10-26         55.54         43.03         72.10                69.17   \n",
              "2013-10-27         56.08         41.13         74.44                68.75   \n",
              "...                  ...           ...           ...                  ...   \n",
              "2023-07-04         82.29         72.63         96.03                82.89   \n",
              "2023-07-05         83.59         73.24         93.70                82.56   \n",
              "2023-07-06         82.61         75.49         93.33                82.51   \n",
              "2023-07-07         80.43         73.02         93.65                81.79   \n",
              "2023-07-08         81.38         73.06         92.86                79.88   \n",
              "\n",
              "            Tsoil min(avg)-10cm  (F)  Tsoil max(avg)-10cm  (F)  \\\n",
              "Period                                                           \n",
              "2013-10-23                     72.81                     76.64   \n",
              "2013-10-24                     69.15                     72.68   \n",
              "2013-10-25                     67.19                     72.41   \n",
              "2013-10-26                     66.58                     71.98   \n",
              "2013-10-27                     65.97                     71.64   \n",
              "...                              ...                       ...   \n",
              "2023-07-04                     79.41                     86.88   \n",
              "2023-07-05                     79.27                     85.78   \n",
              "2023-07-06                     79.95                     85.91   \n",
              "2023-07-07                     78.75                     85.01   \n",
              "2023-07-08                     76.62                     83.93   \n",
              "\n",
              "            2m DewPt avg (F)  RelHum avg 2m  (pct)  2m Rain tot (in)  \\\n",
              "Period                                                                 \n",
              "2013-10-23             57.11                  81.0              0.02   \n",
              "2013-10-24             46.72                  75.0              0.00   \n",
              "2013-10-25             49.45                  78.0              0.00   \n",
              "2013-10-26             46.68                  76.0              0.00   \n",
              "2013-10-27             47.10                  78.0              0.00   \n",
              "...                      ...                   ...               ...   \n",
              "2023-07-04             74.57                  80.0              0.04   \n",
              "2023-07-05             75.47                  78.0              0.00   \n",
              "2023-07-06             76.08                  82.0              0.00   \n",
              "2023-07-07             74.57                  83.0              3.55   \n",
              "2023-07-08             75.19                  83.0              0.01   \n",
              "\n",
              "            SolRad avg2m  (w/m^2)  10m Wind avg (mph)  10m Wind min (mph)  \\\n",
              "Period                                                                      \n",
              "2013-10-23                 177.63                4.90                0.06   \n",
              "2013-10-24                 146.94                2.32                0.02   \n",
              "2013-10-25                 181.08                2.83                0.00   \n",
              "2013-10-26                 181.64                2.57                0.06   \n",
              "2013-10-27                 181.23                1.93                0.02   \n",
              "...                           ...                 ...                 ...   \n",
              "2023-07-04                 279.92                3.02                0.05   \n",
              "2023-07-05                 250.34                3.21                0.00   \n",
              "2023-07-06                 223.97                3.62                0.02   \n",
              "2023-07-07                 213.76                4.53                0.00   \n",
              "2023-07-08                 277.76                4.61                0.02   \n",
              "\n",
              "            10m Wind max (mph)  BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
              "Period                                                                \n",
              "2013-10-23               16.94         1009     0.08           59.97  \n",
              "2013-10-24               10.66         1016     0.10           50.91  \n",
              "2013-10-25               12.82         1019     0.08           53.06  \n",
              "2013-10-26               10.36         1018     0.07           50.77  \n",
              "2013-10-27               11.32         1016     0.07           51.21  \n",
              "...                        ...          ...      ...             ...  \n",
              "2023-07-04               25.05         1015     0.21           76.66  \n",
              "2023-07-05               13.58         1015     0.19           77.62  \n",
              "2023-07-06               15.75         1013     0.18           77.80  \n",
              "2023-07-07               40.15         1011     0.17           76.16  \n",
              "2023-07-08               23.71         1011     0.20           76.85  \n",
              "\n",
              "[3542 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c34d44b9-6674-4f42-9760-fe27a4b11a28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>Tsoil avg-10cm  (F)</th>\n",
              "      <th>Tsoil min(avg)-10cm  (F)</th>\n",
              "      <th>Tsoil max(avg)-10cm  (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>RelHum avg 2m  (pct)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>SolRad avg2m  (w/m^2)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>10m Wind min (mph)</th>\n",
              "      <th>10m Wind max (mph)</th>\n",
              "      <th>BP avg (mb)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.54</td>\n",
              "      <td>49.50</td>\n",
              "      <td>74.88</td>\n",
              "      <td>75.06</td>\n",
              "      <td>72.81</td>\n",
              "      <td>76.64</td>\n",
              "      <td>57.11</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>177.63</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.94</td>\n",
              "      <td>1009</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.81</td>\n",
              "      <td>46.71</td>\n",
              "      <td>70.52</td>\n",
              "      <td>70.90</td>\n",
              "      <td>69.15</td>\n",
              "      <td>72.68</td>\n",
              "      <td>46.72</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>146.94</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.66</td>\n",
              "      <td>1016</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.63</td>\n",
              "      <td>44.17</td>\n",
              "      <td>73.71</td>\n",
              "      <td>69.71</td>\n",
              "      <td>67.19</td>\n",
              "      <td>72.41</td>\n",
              "      <td>49.45</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.08</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.82</td>\n",
              "      <td>1019</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.54</td>\n",
              "      <td>43.03</td>\n",
              "      <td>72.10</td>\n",
              "      <td>69.17</td>\n",
              "      <td>66.58</td>\n",
              "      <td>71.98</td>\n",
              "      <td>46.68</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.64</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10.36</td>\n",
              "      <td>1018</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.08</td>\n",
              "      <td>41.13</td>\n",
              "      <td>74.44</td>\n",
              "      <td>68.75</td>\n",
              "      <td>65.97</td>\n",
              "      <td>71.64</td>\n",
              "      <td>47.10</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.23</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.32</td>\n",
              "      <td>1016</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-04</th>\n",
              "      <td>82.29</td>\n",
              "      <td>72.63</td>\n",
              "      <td>96.03</td>\n",
              "      <td>82.89</td>\n",
              "      <td>79.41</td>\n",
              "      <td>86.88</td>\n",
              "      <td>74.57</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.04</td>\n",
              "      <td>279.92</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>25.05</td>\n",
              "      <td>1015</td>\n",
              "      <td>0.21</td>\n",
              "      <td>76.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>83.59</td>\n",
              "      <td>73.24</td>\n",
              "      <td>93.70</td>\n",
              "      <td>82.56</td>\n",
              "      <td>79.27</td>\n",
              "      <td>85.78</td>\n",
              "      <td>75.47</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>250.34</td>\n",
              "      <td>3.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.58</td>\n",
              "      <td>1015</td>\n",
              "      <td>0.19</td>\n",
              "      <td>77.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>82.61</td>\n",
              "      <td>75.49</td>\n",
              "      <td>93.33</td>\n",
              "      <td>82.51</td>\n",
              "      <td>79.95</td>\n",
              "      <td>85.91</td>\n",
              "      <td>76.08</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>223.97</td>\n",
              "      <td>3.62</td>\n",
              "      <td>0.02</td>\n",
              "      <td>15.75</td>\n",
              "      <td>1013</td>\n",
              "      <td>0.18</td>\n",
              "      <td>77.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>80.43</td>\n",
              "      <td>73.02</td>\n",
              "      <td>93.65</td>\n",
              "      <td>81.79</td>\n",
              "      <td>78.75</td>\n",
              "      <td>85.01</td>\n",
              "      <td>74.57</td>\n",
              "      <td>83.0</td>\n",
              "      <td>3.55</td>\n",
              "      <td>213.76</td>\n",
              "      <td>4.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>40.15</td>\n",
              "      <td>1011</td>\n",
              "      <td>0.17</td>\n",
              "      <td>76.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-08</th>\n",
              "      <td>81.38</td>\n",
              "      <td>73.06</td>\n",
              "      <td>92.86</td>\n",
              "      <td>79.88</td>\n",
              "      <td>76.62</td>\n",
              "      <td>83.93</td>\n",
              "      <td>75.19</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>277.76</td>\n",
              "      <td>4.61</td>\n",
              "      <td>0.02</td>\n",
              "      <td>23.71</td>\n",
              "      <td>1011</td>\n",
              "      <td>0.20</td>\n",
              "      <td>76.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3542 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c34d44b9-6674-4f42-9760-fe27a4b11a28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-7a694249-556c-493e-8ee7-a2f657d09dc3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a694249-556c-493e-8ee7-a2f657d09dc3')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-7a694249-556c-493e-8ee7-a2f657d09dc3 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c34d44b9-6674-4f42-9760-fe27a4b11a28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c34d44b9-6674-4f42-9760-fe27a4b11a28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "H0mEP-EbtMpm",
        "outputId": "77bd7eda-9f51-43a1-cff9-e2307bd0958f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
              "Period                                                                   \n",
              "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
              "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
              "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
              "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
              "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
              "\n",
              "            RelHum avg 2m  (pct)  2m Rain tot (in)  SolRad avg2m  (w/m^2)  \\\n",
              "Period                                                                      \n",
              "2013-10-23                  81.0              0.02             177.630005   \n",
              "2013-10-24                  75.0              0.00             146.940002   \n",
              "2013-10-25                  78.0              0.00             181.080002   \n",
              "2013-10-26                  76.0              0.00             181.639999   \n",
              "2013-10-27                  78.0              0.00             181.229996   \n",
              "\n",
              "            10m Wind avg (mph)  10m Wind min (mph)  10m Wind max (mph)  \\\n",
              "Period                                                                   \n",
              "2013-10-23                4.90                0.06           16.940001   \n",
              "2013-10-24                2.32                0.02           10.660000   \n",
              "2013-10-25                2.83                0.00           12.820000   \n",
              "2013-10-26                2.57                0.06           10.360000   \n",
              "2013-10-27                1.93                0.02           11.320000   \n",
              "\n",
              "            BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
              "Period                                            \n",
              "2013-10-23       1009.0     0.08       59.970001  \n",
              "2013-10-24       1016.0     0.10       50.910000  \n",
              "2013-10-25       1019.0     0.08       53.060001  \n",
              "2013-10-26       1018.0     0.07       50.770000  \n",
              "2013-10-27       1016.0     0.07       51.209999  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-b29bd296-b09b-47c6-9e7b-c52b1a41b6e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>RelHum avg 2m  (pct)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>SolRad avg2m  (w/m^2)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>10m Wind min (mph)</th>\n",
              "      <th>10m Wind max (mph)</th>\n",
              "      <th>BP avg (mb)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.540001</td>\n",
              "      <td>49.500000</td>\n",
              "      <td>74.879997</td>\n",
              "      <td>57.110001</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>177.630005</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.940001</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.810001</td>\n",
              "      <td>46.709999</td>\n",
              "      <td>70.519997</td>\n",
              "      <td>46.720001</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>146.940002</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.660000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.630001</td>\n",
              "      <td>44.169998</td>\n",
              "      <td>73.709999</td>\n",
              "      <td>49.450001</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.080002</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.820000</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.060001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.540001</td>\n",
              "      <td>43.029999</td>\n",
              "      <td>72.099998</td>\n",
              "      <td>46.680000</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.639999</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10.360000</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.080002</td>\n",
              "      <td>41.130001</td>\n",
              "      <td>74.440002</td>\n",
              "      <td>47.099998</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.229996</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.320000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.209999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b29bd296-b09b-47c6-9e7b-c52b1a41b6e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-2c4e828d-19b6-4e0a-8063-e59be93f34d6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c4e828d-19b6-4e0a-8063-e59be93f34d6')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-2c4e828d-19b6-4e0a-8063-e59be93f34d6 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b29bd296-b09b-47c6-9e7b-c52b1a41b6e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b29bd296-b09b-47c6-9e7b-c52b1a41b6e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "ah763AowCKPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet = wb.create_sheet(\"Entropy_Results\")"
      ],
      "metadata": {
        "id": "mvH29KGwhWxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information)\n",
        "\n",
        "sheet['A1'] = \"average_marginal_entropy\"\n",
        "sheet['B1'] = \"average_joint_entropy\"\n",
        "sheet['C1'] = \"average_conditional_entropy\"\n",
        "sheet['D1'] = \"average_mutual_information\"\n",
        "sheet['E1'] = \"Columns\"\n",
        "sheet['A2'] = average_marginal_entropy\n",
        "sheet['B2'] = average_joint_entropy\n",
        "sheet['C2'] = average_conditional_entropy\n",
        "sheet['D2'] = average_mutual_information\n",
        "sheet['E2'] = \"With all Columns\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAThLH9Kaj0o",
        "outputId": "8133b2b0-bc52-4e6e-e11f-364b31ba9d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.4302237186978669\n",
            "Average Joint Entropy: 0.4302039952756337\n",
            "Average Conditional Entropy: -1.972342223321988e-05\n",
            "Average Mutual Information (Transinformation): 0.43024344212010013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KceBegoSkZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 1"
      ],
      "metadata": {
        "id": "2jFWpddYmqzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "Mp0GWD13Ez1M",
        "outputId": "a7298073-9177-4452-da48-f3c15db07c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  Tsoil avg-10cm  (F)  \\\n",
              "Period                                                                      \n",
              "2013-10-23         64.54         49.50         74.88                75.06   \n",
              "2013-10-24         55.81         46.71         70.52                70.90   \n",
              "2013-10-25         57.63         44.17         73.71                69.71   \n",
              "2013-10-26         55.54         43.03         72.10                69.17   \n",
              "2013-10-27         56.08         41.13         74.44                68.75   \n",
              "...                  ...           ...           ...                  ...   \n",
              "2023-07-04         82.29         72.63         96.03                82.89   \n",
              "2023-07-05         83.59         73.24         93.70                82.56   \n",
              "2023-07-06         82.61         75.49         93.33                82.51   \n",
              "2023-07-07         80.43         73.02         93.65                81.79   \n",
              "2023-07-08         81.38         73.06         92.86                79.88   \n",
              "\n",
              "            Tsoil min(avg)-10cm  (F)  Tsoil max(avg)-10cm  (F)  \\\n",
              "Period                                                           \n",
              "2013-10-23                     72.81                     76.64   \n",
              "2013-10-24                     69.15                     72.68   \n",
              "2013-10-25                     67.19                     72.41   \n",
              "2013-10-26                     66.58                     71.98   \n",
              "2013-10-27                     65.97                     71.64   \n",
              "...                              ...                       ...   \n",
              "2023-07-04                     79.41                     86.88   \n",
              "2023-07-05                     79.27                     85.78   \n",
              "2023-07-06                     79.95                     85.91   \n",
              "2023-07-07                     78.75                     85.01   \n",
              "2023-07-08                     76.62                     83.93   \n",
              "\n",
              "            2m DewPt avg (F)  RelHum avg 2m  (pct)  2m Rain tot (in)  \\\n",
              "Period                                                                 \n",
              "2013-10-23             57.11                  81.0              0.02   \n",
              "2013-10-24             46.72                  75.0              0.00   \n",
              "2013-10-25             49.45                  78.0              0.00   \n",
              "2013-10-26             46.68                  76.0              0.00   \n",
              "2013-10-27             47.10                  78.0              0.00   \n",
              "...                      ...                   ...               ...   \n",
              "2023-07-04             74.57                  80.0              0.04   \n",
              "2023-07-05             75.47                  78.0              0.00   \n",
              "2023-07-06             76.08                  82.0              0.00   \n",
              "2023-07-07             74.57                  83.0              3.55   \n",
              "2023-07-08             75.19                  83.0              0.01   \n",
              "\n",
              "            SolRad avg2m  (w/m^2)  10m Wind avg (mph)  10m Wind min (mph)  \\\n",
              "Period                                                                      \n",
              "2013-10-23                 177.63                4.90                0.06   \n",
              "2013-10-24                 146.94                2.32                0.02   \n",
              "2013-10-25                 181.08                2.83                0.00   \n",
              "2013-10-26                 181.64                2.57                0.06   \n",
              "2013-10-27                 181.23                1.93                0.02   \n",
              "...                           ...                 ...                 ...   \n",
              "2023-07-04                 279.92                3.02                0.05   \n",
              "2023-07-05                 250.34                3.21                0.00   \n",
              "2023-07-06                 223.97                3.62                0.02   \n",
              "2023-07-07                 213.76                4.53                0.00   \n",
              "2023-07-08                 277.76                4.61                0.02   \n",
              "\n",
              "            10m Wind max (mph)  BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
              "Period                                                                \n",
              "2013-10-23               16.94         1009     0.08           59.97  \n",
              "2013-10-24               10.66         1016     0.10           50.91  \n",
              "2013-10-25               12.82         1019     0.08           53.06  \n",
              "2013-10-26               10.36         1018     0.07           50.77  \n",
              "2013-10-27               11.32         1016     0.07           51.21  \n",
              "...                        ...          ...      ...             ...  \n",
              "2023-07-04               25.05         1015     0.21           76.66  \n",
              "2023-07-05               13.58         1015     0.19           77.62  \n",
              "2023-07-06               15.75         1013     0.18           77.80  \n",
              "2023-07-07               40.15         1011     0.17           76.16  \n",
              "2023-07-08               23.71         1011     0.20           76.85  \n",
              "\n",
              "[3542 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-b40841a4-bbba-41ed-adcc-84fce7a9d40c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>Tsoil avg-10cm  (F)</th>\n",
              "      <th>Tsoil min(avg)-10cm  (F)</th>\n",
              "      <th>Tsoil max(avg)-10cm  (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>RelHum avg 2m  (pct)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>SolRad avg2m  (w/m^2)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>10m Wind min (mph)</th>\n",
              "      <th>10m Wind max (mph)</th>\n",
              "      <th>BP avg (mb)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.54</td>\n",
              "      <td>49.50</td>\n",
              "      <td>74.88</td>\n",
              "      <td>75.06</td>\n",
              "      <td>72.81</td>\n",
              "      <td>76.64</td>\n",
              "      <td>57.11</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>177.63</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.94</td>\n",
              "      <td>1009</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.81</td>\n",
              "      <td>46.71</td>\n",
              "      <td>70.52</td>\n",
              "      <td>70.90</td>\n",
              "      <td>69.15</td>\n",
              "      <td>72.68</td>\n",
              "      <td>46.72</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>146.94</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.66</td>\n",
              "      <td>1016</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.63</td>\n",
              "      <td>44.17</td>\n",
              "      <td>73.71</td>\n",
              "      <td>69.71</td>\n",
              "      <td>67.19</td>\n",
              "      <td>72.41</td>\n",
              "      <td>49.45</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.08</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.82</td>\n",
              "      <td>1019</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.54</td>\n",
              "      <td>43.03</td>\n",
              "      <td>72.10</td>\n",
              "      <td>69.17</td>\n",
              "      <td>66.58</td>\n",
              "      <td>71.98</td>\n",
              "      <td>46.68</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.64</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10.36</td>\n",
              "      <td>1018</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.08</td>\n",
              "      <td>41.13</td>\n",
              "      <td>74.44</td>\n",
              "      <td>68.75</td>\n",
              "      <td>65.97</td>\n",
              "      <td>71.64</td>\n",
              "      <td>47.10</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.23</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.32</td>\n",
              "      <td>1016</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-04</th>\n",
              "      <td>82.29</td>\n",
              "      <td>72.63</td>\n",
              "      <td>96.03</td>\n",
              "      <td>82.89</td>\n",
              "      <td>79.41</td>\n",
              "      <td>86.88</td>\n",
              "      <td>74.57</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.04</td>\n",
              "      <td>279.92</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>25.05</td>\n",
              "      <td>1015</td>\n",
              "      <td>0.21</td>\n",
              "      <td>76.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>83.59</td>\n",
              "      <td>73.24</td>\n",
              "      <td>93.70</td>\n",
              "      <td>82.56</td>\n",
              "      <td>79.27</td>\n",
              "      <td>85.78</td>\n",
              "      <td>75.47</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>250.34</td>\n",
              "      <td>3.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.58</td>\n",
              "      <td>1015</td>\n",
              "      <td>0.19</td>\n",
              "      <td>77.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>82.61</td>\n",
              "      <td>75.49</td>\n",
              "      <td>93.33</td>\n",
              "      <td>82.51</td>\n",
              "      <td>79.95</td>\n",
              "      <td>85.91</td>\n",
              "      <td>76.08</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>223.97</td>\n",
              "      <td>3.62</td>\n",
              "      <td>0.02</td>\n",
              "      <td>15.75</td>\n",
              "      <td>1013</td>\n",
              "      <td>0.18</td>\n",
              "      <td>77.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>80.43</td>\n",
              "      <td>73.02</td>\n",
              "      <td>93.65</td>\n",
              "      <td>81.79</td>\n",
              "      <td>78.75</td>\n",
              "      <td>85.01</td>\n",
              "      <td>74.57</td>\n",
              "      <td>83.0</td>\n",
              "      <td>3.55</td>\n",
              "      <td>213.76</td>\n",
              "      <td>4.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>40.15</td>\n",
              "      <td>1011</td>\n",
              "      <td>0.17</td>\n",
              "      <td>76.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-08</th>\n",
              "      <td>81.38</td>\n",
              "      <td>73.06</td>\n",
              "      <td>92.86</td>\n",
              "      <td>79.88</td>\n",
              "      <td>76.62</td>\n",
              "      <td>83.93</td>\n",
              "      <td>75.19</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>277.76</td>\n",
              "      <td>4.61</td>\n",
              "      <td>0.02</td>\n",
              "      <td>23.71</td>\n",
              "      <td>1011</td>\n",
              "      <td>0.20</td>\n",
              "      <td>76.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3542 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b40841a4-bbba-41ed-adcc-84fce7a9d40c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-a07a16be-570d-4f1c-a406-f9b5b7fff318\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a07a16be-570d-4f1c-a406-f9b5b7fff318')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-a07a16be-570d-4f1c-a406-f9b5b7fff318 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b40841a4-bbba-41ed-adcc-84fce7a9d40c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b40841a4-bbba-41ed-adcc-84fce7a9d40c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "Br8pJ_6pEz3i",
        "outputId": "2044ea5d-f29c-4fde-b11a-6c60b187b080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
              "Period                                                                   \n",
              "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
              "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
              "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
              "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
              "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
              "\n",
              "            RelHum avg 2m  (pct)  2m Rain tot (in)  SolRad avg2m  (w/m^2)  \\\n",
              "Period                                                                      \n",
              "2013-10-23                  81.0              0.02             177.630005   \n",
              "2013-10-24                  75.0              0.00             146.940002   \n",
              "2013-10-25                  78.0              0.00             181.080002   \n",
              "2013-10-26                  76.0              0.00             181.639999   \n",
              "2013-10-27                  78.0              0.00             181.229996   \n",
              "\n",
              "            10m Wind avg (mph)  10m Wind min (mph)  10m Wind max (mph)  \\\n",
              "Period                                                                   \n",
              "2013-10-23                4.90                0.06           16.940001   \n",
              "2013-10-24                2.32                0.02           10.660000   \n",
              "2013-10-25                2.83                0.00           12.820000   \n",
              "2013-10-26                2.57                0.06           10.360000   \n",
              "2013-10-27                1.93                0.02           11.320000   \n",
              "\n",
              "            BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
              "Period                                            \n",
              "2013-10-23       1009.0     0.08       59.970001  \n",
              "2013-10-24       1016.0     0.10       50.910000  \n",
              "2013-10-25       1019.0     0.08       53.060001  \n",
              "2013-10-26       1018.0     0.07       50.770000  \n",
              "2013-10-27       1016.0     0.07       51.209999  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-5b1f1391-4a55-4b9e-aa41-1a421908679c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>RelHum avg 2m  (pct)</th>\n",
              "      <th>2m Rain tot (in)</th>\n",
              "      <th>SolRad avg2m  (w/m^2)</th>\n",
              "      <th>10m Wind avg (mph)</th>\n",
              "      <th>10m Wind min (mph)</th>\n",
              "      <th>10m Wind max (mph)</th>\n",
              "      <th>BP avg (mb)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.540001</td>\n",
              "      <td>49.500000</td>\n",
              "      <td>74.879997</td>\n",
              "      <td>57.110001</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>177.630005</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.940001</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.810001</td>\n",
              "      <td>46.709999</td>\n",
              "      <td>70.519997</td>\n",
              "      <td>46.720001</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>146.940002</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.660000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.630001</td>\n",
              "      <td>44.169998</td>\n",
              "      <td>73.709999</td>\n",
              "      <td>49.450001</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.080002</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.820000</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.060001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.540001</td>\n",
              "      <td>43.029999</td>\n",
              "      <td>72.099998</td>\n",
              "      <td>46.680000</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.639999</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10.360000</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.080002</td>\n",
              "      <td>41.130001</td>\n",
              "      <td>74.440002</td>\n",
              "      <td>47.099998</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181.229996</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.320000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.209999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b1f1391-4a55-4b9e-aa41-1a421908679c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-4dbfa836-69a0-4628-abbf-9c86743f7766\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4dbfa836-69a0-4628-abbf-9c86743f7766')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-4dbfa836-69a0-4628-abbf-9c86743f7766 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b1f1391-4a55-4b9e-aa41-1a421908679c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b1f1391-4a55-4b9e-aa41-1a421908679c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW3VELMUljBP",
        "outputId": "44edb1c9-c2a3-4c09-91dc-157d98c85d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
              "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
              "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
              "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"2m T avg (F)\"], axis=1).astype(np.float32)"
      ],
      "metadata": {
        "id": "Vx7o5QJllZZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytxsui4tlpNS",
        "outputId": "33f86fc0-8e5d-4b76-dd65-e9b17fda1c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
              "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
              "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
              "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "eY7KyKy2lrYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy1, average_joint_entropy1, average_conditional_entropy1, average_mutual_information1 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy1)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy1)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy1)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information1)\n",
        "\n",
        "sheet['A3'] = average_marginal_entropy1\n",
        "sheet['B3'] = average_joint_entropy1\n",
        "sheet['C3'] = average_conditional_entropy1\n",
        "sheet['D3'] = average_mutual_information1\n",
        "sheet['E3'] = \"Without Column 1\"\n",
        "wb.save('Results.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3RnqLS2lran",
        "outputId": "3e7fce84-5101-495e-c028-53cd034c26c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.3818077804391913\n",
            "Average Joint Entropy: 0.38202881368850977\n",
            "Average Conditional Entropy: 0.0002210332493184919\n",
            "Average Mutual Information (Transinformation): 0.3815867471898728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 2"
      ],
      "metadata": {
        "id": "AjLheUnMm0Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lotCyim-lrc1",
        "outputId": "5d0057a2-64b7-405c-d158-ce0df2dfc4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"2m T min (F)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX3M3-8flrfB",
        "outputId": "9e6e63d8-9d68-459f-ac43-8c5eefdffc49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy2, average_joint_entropy2, average_conditional_entropy2, average_mutual_information2 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy2)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy2)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy2)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information2)\n",
        "\n",
        "sheet['A4'] = average_marginal_entropy2\n",
        "sheet['B4'] = average_joint_entropy2\n",
        "sheet['C4'] = average_conditional_entropy2\n",
        "sheet['D4'] = average_mutual_information2\n",
        "sheet['E4'] = \"Without Column 2\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfRfDIXUlrhz",
        "outputId": "6ed153f5-6dbc-4eec-b25d-3610a6a25627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.40213335028245795\n",
            "Average Joint Entropy: 0.40215545794222424\n",
            "Average Conditional Entropy: 2.2107659766290588e-05\n",
            "Average Mutual Information (Transinformation): 0.40211124262269166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 3"
      ],
      "metadata": {
        "id": "epBSX96am50G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi3lfabQnRce",
        "outputId": "284a79d0-0264-45ff-bd5f-795c387d75a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"2m T max (F)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHAEX-TxnReX",
        "outputId": "db177b2a-6c97-4a5c-fb24-9d6efdc061ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy3, average_joint_entropy3, average_conditional_entropy3, average_mutual_information3 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy3)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy3)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy3)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information3)\n",
        "sheet['A5'] = average_marginal_entropy3\n",
        "sheet['B5'] = average_joint_entropy3\n",
        "sheet['C5'] = average_conditional_entropy3\n",
        "sheet['D5'] = average_mutual_information3\n",
        "sheet['E5'] = \"Without Column 3\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKV-6U9OnRga",
        "outputId": "1383555e-3f37-416f-caba-55a1e7d0bb33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.39847846397852793\n",
            "Average Joint Entropy: 0.3988820612870234\n",
            "Average Conditional Entropy: 0.0004035973084954847\n",
            "Average Mutual Information (Transinformation): 0.39807486667003245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 4"
      ],
      "metadata": {
        "id": "8dG2hQZHm907"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8bHosk0nhdo",
        "outputId": "0b5ac55f-5412-41d3-f1b9-05104bc3df81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"2m DewPt avg (F)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssskSSRmnhh2",
        "outputId": "22078756-45bd-48a3-9d81-e219bf95f837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', 'RelHum avg 2m  (pct)',\n",
            "       '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)', '10m Wind avg (mph)',\n",
            "       '10m Wind min (mph)', '10m Wind max (mph)', 'BP avg (mb)', 'ET (in)',\n",
            "       '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy4, average_joint_entropy4, average_conditional_entropy4, average_mutual_information4 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy4)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy4)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy4)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information4)\n",
        "sheet['A6'] = average_marginal_entropy4\n",
        "sheet['B6'] = average_joint_entropy4\n",
        "sheet['C6'] = average_conditional_entropy4\n",
        "sheet['D6'] = average_mutual_information4\n",
        "sheet['E6'] = \"Without Column 4\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HEFtMdPnhlw",
        "outputId": "56a58fe2-5aec-4900-d31e-7ed7a3728b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.40267039462548526\n",
            "Average Joint Entropy: 0.4029042247646131\n",
            "Average Conditional Entropy: 0.0002338301391278108\n",
            "Average Mutual Information (Transinformation): 0.40243656448635745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 5"
      ],
      "metadata": {
        "id": "ZgnG9XtAm93G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lntEB4mDniFn",
        "outputId": "cf29ac38-9466-446b-f931-d02ea286f0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"RelHum avg 2m  (pct)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZJTAdZXniH8",
        "outputId": "e7598e29-0aaa-4ecd-b7d8-898bce8c8e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)', '10m Wind avg (mph)',\n",
            "       '10m Wind min (mph)', '10m Wind max (mph)', 'BP avg (mb)', 'ET (in)',\n",
            "       '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy5, average_joint_entropy5, average_conditional_entropy5, average_mutual_information5 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy5)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy5)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy5)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information5)\n",
        "sheet['A7'] = average_marginal_entropy5\n",
        "sheet['B7'] = average_joint_entropy5\n",
        "sheet['C7'] = average_conditional_entropy5\n",
        "sheet['D7'] = average_mutual_information5\n",
        "sheet['E7'] = \"Without Column 5\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3aOim6MniJ9",
        "outputId": "e2bc6f37-4269-4d3d-d894-74a97972f12b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.4559288714949092\n",
            "Average Joint Entropy: 0.45603972081096705\n",
            "Average Conditional Entropy: 0.00011084931605787052\n",
            "Average Mutual Information (Transinformation): 0.4558180221788513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 6"
      ],
      "metadata": {
        "id": "LL7EKtJ3m95h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlH0FsTYnioU",
        "outputId": "5c496926-7355-441e-ac2a-3b21faf8331a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"2m Rain tot (in)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiLWInvXniqt",
        "outputId": "25b5e678-3e01-4ec6-ffa8-d49fc9b812e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', 'SolRad avg2m  (w/m^2)', '10m Wind avg (mph)',\n",
            "       '10m Wind min (mph)', '10m Wind max (mph)', 'BP avg (mb)', 'ET (in)',\n",
            "       '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy6, average_joint_entropy6, average_conditional_entropy6, average_mutual_information6 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy6)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy6)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy6)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information6)\n",
        "sheet['A8'] = average_marginal_entropy6\n",
        "sheet['B8'] = average_joint_entropy6\n",
        "sheet['C8'] = average_conditional_entropy6\n",
        "sheet['D8'] = average_mutual_information6\n",
        "sheet['E8'] = \"Without Column 6\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xaE6dgXniuG",
        "outputId": "f3586974-9005-4b66-a2fc-3540363ad10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.4516785882645277\n",
            "Average Joint Entropy: 0.4523120966469249\n",
            "Average Conditional Entropy: 0.0006335083823971743\n",
            "Average Mutual Information (Transinformation): 0.45104507988213055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 7"
      ],
      "metadata": {
        "id": "aU0eGuitm97Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_x4guD0njL-",
        "outputId": "150b19f0-810f-4928-d68f-4f2f3f61317c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"SolRad avg2m  (w/m^2)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0HViVRqnjRa",
        "outputId": "8257f534-1e81-4d85-ddaa-26db9eec0370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', '10m Wind avg (mph)',\n",
            "       '10m Wind min (mph)', '10m Wind max (mph)', 'BP avg (mb)', 'ET (in)',\n",
            "       '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy7, average_joint_entropy7, average_conditional_entropy7, average_mutual_information7 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy7)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy7)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy7)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information7)\n",
        "sheet['A9'] = average_marginal_entropy7\n",
        "sheet['B9'] = average_joint_entropy7\n",
        "sheet['C9'] = average_conditional_entropy7\n",
        "sheet['D9'] = average_mutual_information7\n",
        "sheet['E9'] = \"Without Column 7\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WweaaI3rnjZY",
        "outputId": "2dfd8d19-8779-4404-a366-e8358a1b7d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.45189198572641204\n",
            "Average Joint Entropy: 0.45139375629695383\n",
            "Average Conditional Entropy: -0.0004982294294582079\n",
            "Average Mutual Information (Transinformation): 0.45239021515587025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 8"
      ],
      "metadata": {
        "id": "n_agQ-VRm99d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9zbzDNunj52",
        "outputId": "6e3b4cb5-7f64-4f03-c9a7-78a1f4184f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"10m Wind avg (mph)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btHKo0qunj8F",
        "outputId": "dc77f7a9-cd6b-4001-d094-8bad2e3fbc62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind min (mph)', '10m Wind max (mph)', 'BP avg (mb)', 'ET (in)',\n",
            "       '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy8, average_joint_entropy8, average_conditional_entropy8, average_mutual_information8 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy8)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy8)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy8)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information8)\n",
        "sheet['A10'] = average_marginal_entropy8\n",
        "sheet['B10'] = average_joint_entropy8\n",
        "sheet['C10'] = average_conditional_entropy8\n",
        "sheet['D10'] = average_mutual_information8\n",
        "sheet['E10'] = \"Without Column 8\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmpTRXQSnj-S",
        "outputId": "e16cbe79-3c84-42e9-8d58-838b02f03630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.4606901049018342\n",
            "Average Joint Entropy: 0.4612470349145992\n",
            "Average Conditional Entropy: 0.0005569300127649668\n",
            "Average Mutual Information (Transinformation): 0.46013317488906924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 9"
      ],
      "metadata": {
        "id": "FV--iSpVm9_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FHWsc-vnkdu",
        "outputId": "adce5eb8-d118-4a9d-ce65-9ec9a136f6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"10m Wind min (mph)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKbsGckDnkgK",
        "outputId": "f524da3e-2cad-4162-a737-78e6625fcbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind max (mph)', 'BP avg (mb)', 'ET (in)',\n",
            "       '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy9, average_joint_entropy9, average_conditional_entropy9, average_mutual_information9 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy9)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy9)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy9)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information9)\n",
        "sheet['A11'] = average_marginal_entropy9\n",
        "sheet['B11'] = average_joint_entropy9\n",
        "sheet['C11'] = average_conditional_entropy9\n",
        "sheet['D11'] = average_mutual_information9\n",
        "sheet['E11'] = \"Without Column 9\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35aO0MZ7nkiK",
        "outputId": "00eb88b8-0799-411d-cbce-f73636771ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.45866653095863735\n",
            "Average Joint Entropy: 0.4586041226996549\n",
            "Average Conditional Entropy: -6.240825898246039e-05\n",
            "Average Mutual Information (Transinformation): 0.4587289392176198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 10"
      ],
      "metadata": {
        "id": "D3LQn1Vim-CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSHWYgvlnlQs",
        "outputId": "68fd2413-c29c-46e8-ed5e-a52cca4dcd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"10m Wind max (mph)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmFdwY1SnlSz",
        "outputId": "ee4e3216-b8a5-4886-d4cc-3882b6c43848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', 'BP avg (mb)', 'ET (in)',\n",
            "       '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy10, average_joint_entropy10, average_conditional_entropy10, average_mutual_information10 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy10)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy10)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy10)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information10)\n",
        "sheet['A12'] = average_marginal_entropy10\n",
        "sheet['B12'] = average_joint_entropy10\n",
        "sheet['C12'] = average_conditional_entropy10\n",
        "sheet['D12'] = average_mutual_information10\n",
        "sheet['E12'] = \"Without Column 10\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG7sDHVznlVB",
        "outputId": "cb73af8b-347d-4eea-b658-e3e78912e267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.46436818283429554\n",
            "Average Joint Entropy: 0.46391703061129114\n",
            "Average Conditional Entropy: -0.00045115222300440294\n",
            "Average Mutual Information (Transinformation): 0.46481933505729994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 11"
      ],
      "metadata": {
        "id": "ICCzX0rOm-D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMs8LCZjnl8K",
        "outputId": "ce404d9c-aa80-4235-f7df-66e9f3d2ff2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"BP avg (mb)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw8nElx_nl-g",
        "outputId": "35744954-e09d-4880-9a01-0ae0c03390f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy11, average_joint_entropy11, average_conditional_entropy11, average_mutual_information11 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy11)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy11)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy11)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information11)\n",
        "sheet['A13'] = average_marginal_entropy11\n",
        "sheet['B13'] = average_joint_entropy11\n",
        "sheet['C13'] = average_conditional_entropy11\n",
        "sheet['D13'] = average_mutual_information11\n",
        "sheet['E13'] = \"Without Column 11\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WKbs8SsnmAu",
        "outputId": "fbccba82-4758-4237-8202-c65471877cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.4548451609552245\n",
            "Average Joint Entropy: 0.454140333060628\n",
            "Average Conditional Entropy: -0.0007048278945964714\n",
            "Average Mutual Information (Transinformation): 0.45554998884982095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 12"
      ],
      "metadata": {
        "id": "Pa-mJeMnm-HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl2y7oPenmb1",
        "outputId": "8aa0ddb9-2867-462e-b00c-e54427f555de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"ET (in)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH-mp-TynmeC",
        "outputId": "6ea71a5d-cc38-4178-be2c-c34ba84449c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy12, average_joint_entropy12, average_conditional_entropy12, average_mutual_information12 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy12)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy12)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy12)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information12)\n",
        "sheet['A14'] = average_marginal_entropy12\n",
        "sheet['B14'] = average_joint_entropy12\n",
        "sheet['C14'] = average_conditional_entropy12\n",
        "sheet['D14'] = average_mutual_information12\n",
        "sheet['E14'] = \"Without Column 12\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3VeUkdhnmgT",
        "outputId": "5f05deba-fbe8-400a-ee9a-c2dcc4f25b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.4177562049607069\n",
            "Average Joint Entropy: 0.4179105115736745\n",
            "Average Conditional Entropy: 0.00015430661296755854\n",
            "Average Mutual Information (Transinformation): 0.41760189834773936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Theory - without Column 13"
      ],
      "metadata": {
        "id": "dvNX1Mkim_77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkpkDx4mnm-_",
        "outputId": "1fcf152d-ec66-4437-ebad-694bcec101bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)', '2m WetBulb (F)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna().drop(columns=[\"2m WetBulb (F)\"], axis=1).astype(np.float32)\n",
        "print(X.columns)\n",
        "len(X.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrN6yQ99nnBa",
        "outputId": "6b4dd221-e5ff-4c02-a019-a6c92c4cb3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['2m T avg (F)', '2m T min (F)', '2m T max (F)', '2m DewPt avg (F)',\n",
            "       'RelHum avg 2m  (pct)', '2m Rain tot (in)', 'SolRad avg2m  (w/m^2)',\n",
            "       '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
            "       'BP avg (mb)', 'ET (in)'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled= scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def calculate_entropy():\n",
        "\n",
        "    # Calculate the joint entropy\n",
        "    joint_entropy = mutual_info_regression(X_scaled, y_scaled)\n",
        "\n",
        "    # Calculate the marginal entropy for each input variable\n",
        "    marginal_entropy = []\n",
        "    for i in range(X_scaled.shape[1]):\n",
        "        entropy = mutual_info_regression(X_scaled[:, i].reshape(-1, 1), y_scaled)\n",
        "        marginal_entropy.append(entropy)\n",
        "\n",
        "    # Calculate the average joint entropy\n",
        "    average_joint_entropy = np.mean(joint_entropy)\n",
        "\n",
        "    # Calculate the average marginal entropy\n",
        "    average_marginal_entropy = np.mean(marginal_entropy)\n",
        "\n",
        "    # Calculate the average conditional entropy\n",
        "    average_conditional_entropy = average_joint_entropy - average_marginal_entropy\n",
        "\n",
        "    # Calculate the average mutual information (transinformation)\n",
        "    average_mutual_information = average_marginal_entropy - average_conditional_entropy\n",
        "\n",
        "    return average_marginal_entropy, average_joint_entropy, average_conditional_entropy, average_mutual_information\n",
        "\n",
        "# Assuming you have a dataset called 'data' with shape (n_samples, 14) where the last column is the output variable\n",
        "\n",
        "average_marginal_entropy13, average_joint_entropy13, average_conditional_entropy13, average_mutual_information13 = calculate_entropy()\n",
        "\n",
        "print(\"Average marginal Entropy:\", average_marginal_entropy13)\n",
        "print(\"Average Joint Entropy:\", average_joint_entropy13)\n",
        "print(\"Average Conditional Entropy:\", average_conditional_entropy13)\n",
        "print(\"Average Mutual Information (Transinformation):\", average_mutual_information13)\n",
        "sheet['A15'] = average_marginal_entropy13\n",
        "sheet['B15'] = average_joint_entropy13\n",
        "sheet['C15'] = average_conditional_entropy13\n",
        "sheet['D15'] = average_mutual_information13\n",
        "sheet['E15'] = \"Without Column 13\"\n",
        "wb.save('Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZdWfX-ynnDp",
        "outputId": "344565f3-71a3-4e96-c30e-d91a1520a231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average marginal Entropy: 0.3907869044230304\n",
            "Average Joint Entropy: 0.39107537677316745\n",
            "Average Conditional Entropy: 0.00028847235013707007\n",
            "Average Mutual Information (Transinformation): 0.3904984320728933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Alachua.csv\",parse_dates=True,index_col=0)\n",
        "X = df.dropna().drop(columns=[\"Tsoil avg-10cm  (F)\", \"Tsoil max(avg)-10cm  (F)\", \"Tsoil min(avg)-10cm  (F)\"], axis=1).astype(np.float32)\n",
        "y = df.dropna()[\"Tsoil avg-10cm  (F)\"].astype(np.float32)\n",
        "print(X.head())\n"
      ],
      "metadata": {
        "id": "JSmvLvZSGZoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a08fac-fb8c-4a0c-83b3-ebfb4893f313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
            "Period                                                                   \n",
            "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
            "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
            "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
            "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
            "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
            "\n",
            "            RelHum avg 2m  (pct)  2m Rain tot (in)  SolRad avg2m  (w/m^2)  \\\n",
            "Period                                                                      \n",
            "2013-10-23                  81.0              0.02             177.630005   \n",
            "2013-10-24                  75.0              0.00             146.940002   \n",
            "2013-10-25                  78.0              0.00             181.080002   \n",
            "2013-10-26                  76.0              0.00             181.639999   \n",
            "2013-10-27                  78.0              0.00             181.229996   \n",
            "\n",
            "            10m Wind avg (mph)  10m Wind min (mph)  10m Wind max (mph)  \\\n",
            "Period                                                                   \n",
            "2013-10-23                4.90                0.06           16.940001   \n",
            "2013-10-24                2.32                0.02           10.660000   \n",
            "2013-10-25                2.83                0.00           12.820000   \n",
            "2013-10-26                2.57                0.06           10.360000   \n",
            "2013-10-27                1.93                0.02           11.320000   \n",
            "\n",
            "            BP avg (mb)  ET (in)  2m WetBulb (F)  \n",
            "Period                                            \n",
            "2013-10-23       1009.0     0.08       59.970001  \n",
            "2013-10-24       1016.0     0.10       50.910000  \n",
            "2013-10-25       1019.0     0.08       53.060001  \n",
            "2013-10-26       1018.0     0.07       50.770000  \n",
            "2013-10-27       1016.0     0.07       51.209999  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[X.columns[[0,1,2,3,11,12]]]"
      ],
      "metadata": {
        "id": "B_3Kz-b9YSmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "W84m4FsIYc08",
        "outputId": "75e5ffc3-40ee-4483-a111-265b0f6a4328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            2m T avg (F)  2m T min (F)  2m T max (F)  2m DewPt avg (F)  \\\n",
              "Period                                                                   \n",
              "2013-10-23     64.540001     49.500000     74.879997         57.110001   \n",
              "2013-10-24     55.810001     46.709999     70.519997         46.720001   \n",
              "2013-10-25     57.630001     44.169998     73.709999         49.450001   \n",
              "2013-10-26     55.540001     43.029999     72.099998         46.680000   \n",
              "2013-10-27     56.080002     41.130001     74.440002         47.099998   \n",
              "...                  ...           ...           ...               ...   \n",
              "2023-07-04     82.290001     72.629997     96.029999         74.570000   \n",
              "2023-07-05     83.589996     73.239998     93.699997         75.470001   \n",
              "2023-07-06     82.610001     75.489998     93.330002         76.080002   \n",
              "2023-07-07     80.430000     73.019997     93.650002         74.570000   \n",
              "2023-07-08     81.379997     73.059998     92.860001         75.190002   \n",
              "\n",
              "            ET (in)  2m WetBulb (F)  \n",
              "Period                               \n",
              "2013-10-23     0.08       59.970001  \n",
              "2013-10-24     0.10       50.910000  \n",
              "2013-10-25     0.08       53.060001  \n",
              "2013-10-26     0.07       50.770000  \n",
              "2013-10-27     0.07       51.209999  \n",
              "...             ...             ...  \n",
              "2023-07-04     0.21       76.660004  \n",
              "2023-07-05     0.19       77.620003  \n",
              "2023-07-06     0.18       77.800003  \n",
              "2023-07-07     0.17       76.160004  \n",
              "2023-07-08     0.20       76.849998  \n",
              "\n",
              "[3542 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-1c30cded-fd0f-491c-97a3-b01439b6afbf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2m T avg (F)</th>\n",
              "      <th>2m T min (F)</th>\n",
              "      <th>2m T max (F)</th>\n",
              "      <th>2m DewPt avg (F)</th>\n",
              "      <th>ET (in)</th>\n",
              "      <th>2m WetBulb (F)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-23</th>\n",
              "      <td>64.540001</td>\n",
              "      <td>49.500000</td>\n",
              "      <td>74.879997</td>\n",
              "      <td>57.110001</td>\n",
              "      <td>0.08</td>\n",
              "      <td>59.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-24</th>\n",
              "      <td>55.810001</td>\n",
              "      <td>46.709999</td>\n",
              "      <td>70.519997</td>\n",
              "      <td>46.720001</td>\n",
              "      <td>0.10</td>\n",
              "      <td>50.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-25</th>\n",
              "      <td>57.630001</td>\n",
              "      <td>44.169998</td>\n",
              "      <td>73.709999</td>\n",
              "      <td>49.450001</td>\n",
              "      <td>0.08</td>\n",
              "      <td>53.060001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-26</th>\n",
              "      <td>55.540001</td>\n",
              "      <td>43.029999</td>\n",
              "      <td>72.099998</td>\n",
              "      <td>46.680000</td>\n",
              "      <td>0.07</td>\n",
              "      <td>50.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-27</th>\n",
              "      <td>56.080002</td>\n",
              "      <td>41.130001</td>\n",
              "      <td>74.440002</td>\n",
              "      <td>47.099998</td>\n",
              "      <td>0.07</td>\n",
              "      <td>51.209999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-04</th>\n",
              "      <td>82.290001</td>\n",
              "      <td>72.629997</td>\n",
              "      <td>96.029999</td>\n",
              "      <td>74.570000</td>\n",
              "      <td>0.21</td>\n",
              "      <td>76.660004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>83.589996</td>\n",
              "      <td>73.239998</td>\n",
              "      <td>93.699997</td>\n",
              "      <td>75.470001</td>\n",
              "      <td>0.19</td>\n",
              "      <td>77.620003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>82.610001</td>\n",
              "      <td>75.489998</td>\n",
              "      <td>93.330002</td>\n",
              "      <td>76.080002</td>\n",
              "      <td>0.18</td>\n",
              "      <td>77.800003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>80.430000</td>\n",
              "      <td>73.019997</td>\n",
              "      <td>93.650002</td>\n",
              "      <td>74.570000</td>\n",
              "      <td>0.17</td>\n",
              "      <td>76.160004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-08</th>\n",
              "      <td>81.379997</td>\n",
              "      <td>73.059998</td>\n",
              "      <td>92.860001</td>\n",
              "      <td>75.190002</td>\n",
              "      <td>0.20</td>\n",
              "      <td>76.849998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3542 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c30cded-fd0f-491c-97a3-b01439b6afbf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-cff2d747-e5ed-46c7-a320-7b5cb954fece\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cff2d747-e5ed-46c7-a320-7b5cb954fece')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-cff2d747-e5ed-46c7-a320-7b5cb954fece button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1c30cded-fd0f-491c-97a3-b01439b6afbf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1c30cded-fd0f-491c-97a3-b01439b6afbf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAVHX44pYmsj",
        "outputId": "721d056f-8b66-463c-c5d6-6ecdc99e46f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Period\n",
              "2013-10-23    75.059998\n",
              "2013-10-24    70.900002\n",
              "2013-10-25    69.709999\n",
              "2013-10-26    69.169998\n",
              "2013-10-27    68.750000\n",
              "                ...    \n",
              "2023-07-04    82.889999\n",
              "2023-07-05    82.559998\n",
              "2023-07-06    82.510002\n",
              "2023-07-07    81.790001\n",
              "2023-07-08    79.879997\n",
              "Name: Tsoil avg-10cm  (F), Length: 3542, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Assuming X is your input data\n",
        "y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "T9GVx3c5YnCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXi0I2wQYzgY",
        "outputId": "8a7a1070-918d-43cb-f515-222b4eb97cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.4032232 , -0.7458762 , -0.53653353, -0.4248603 , -0.62721187,\n",
              "        -0.4421828 ],\n",
              "       [-1.2142386 , -0.9646546 , -0.9517654 , -1.2762262 , -0.18470922,\n",
              "        -1.2763008 ],\n",
              "       [-1.045161  , -1.1638292 , -0.64796025, -1.0525275 , -0.62721187,\n",
              "        -1.0783588 ],\n",
              "       ...,\n",
              "       [ 1.2754767 ,  1.292134  ,  1.2205832 ,  1.1295588 ,  1.5853014 ,\n",
              "         1.1993539 ],\n",
              "       [ 1.072955  ,  1.0984485 ,  1.2510589 ,  1.0058278 ,  1.3640499 ,\n",
              "         1.0483658 ],\n",
              "       [ 1.1612096 ,  1.1015851 ,  1.1758219 ,  1.0566314 ,  2.027804  ,\n",
              "         1.1118908 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_size = int(len(X) * 0.8)\n",
        "X_train, y_train = X_scaled[:split_size], y_scaled[:split_size]\n",
        "X_test, y_test = X_scaled[split_size:], y_scaled[split_size:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t67gU7zPY0S5",
        "outputId": "64dbdb31-5727-42a0-ddd9-22ddc6ebf8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2833, 2833, 709, 709)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NWSvUC4Y2XU",
        "outputId": "f3c4ef83-e8c8-4ad1-cd04-bbd627bd8964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.4032232  -0.7458762  -0.53653353 -0.4248603  -0.62721187 -0.4421828 ]\n",
            " [-1.2142386  -0.9646546  -0.9517654  -1.2762262  -0.18470922 -1.2763008 ]\n",
            " [-1.045161   -1.1638292  -0.64796025 -1.0525275  -0.62721187 -1.0783588 ]\n",
            " ...\n",
            " [ 0.8657881   1.2097985   0.6939246   1.1369331  -0.18470922  1.0990016 ]\n",
            " [ 0.84627926  1.1651019   0.8205888   1.0828525   0.2577933   1.0502068 ]\n",
            " [ 0.99027425  1.1690223   1.0320144   1.0894073   1.3640499   1.093478  ]] [[ 0.3417217 ]\n",
            " [-0.11407956]\n",
            " [-0.24446538]\n",
            " ...\n",
            " [ 0.91366524]\n",
            " [ 0.84135103]\n",
            " [ 0.9563966 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create and train the MLP model\n",
        "# Modify the hyperparameters to adjust the model architecture and training process\n",
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  mlp = MLPRegressor(hidden_layer_sizes=(roh), activation='relu', solver='adam', max_iter=100, random_state=42)\n",
        "  mlp.fit(X_train, y_train)\n",
        "  train_predictions = mlp.predict(X_train)\n",
        "  test_predictions = mlp.predict(X_test)\n",
        "  train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
        "  test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
        "  print(roh)\n",
        "  print(\"Training RMSE:\", train_rmse)\n",
        "  print(\"Testing RMSE:\", test_rmse)\n",
        "  if test_rmse < best_test_rmse:\n",
        "    best_test_rmse=test_rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=test_predictions\n",
        "ws1['B4']=best_hidden_size\n",
        "ws1['C4']=best_train_rmse\n",
        "ws1['D4']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws12['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws12['B{}'.format(i+2)] = float(prediction)\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUuq-bNbY4NN",
        "outputId": "f3e9c134-2e96-4046-a26f-d48c13e6e02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Training RMSE: 0.49555665\n",
            "Testing RMSE: 0.519096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Training RMSE: 0.6461244\n",
            "Testing RMSE: 0.57404935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Training RMSE: 0.40270916\n",
            "Testing RMSE: 0.40743604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "Training RMSE: 0.34699205\n",
            "Testing RMSE: 0.41194472\n",
            "5\n",
            "Training RMSE: 0.3514576\n",
            "Testing RMSE: 0.4051833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "Training RMSE: 0.3316158\n",
            "Testing RMSE: 0.39058852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "Training RMSE: 0.34217837\n",
            "Testing RMSE: 0.40413827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "Training RMSE: 0.5429259\n",
            "Testing RMSE: 0.47135746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "Training RMSE: 0.33620745\n",
            "Testing RMSE: 0.3703122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Training RMSE: 0.3306877\n",
            "Testing RMSE: 0.38499558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "Training RMSE: 0.3403053\n",
            "Testing RMSE: 0.39504418\n",
            "12\n",
            "Training RMSE: 0.33372882\n",
            "Testing RMSE: 0.38435993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "Training RMSE: 0.33312893\n",
            "Testing RMSE: 0.37740335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "Training RMSE: 0.32448176\n",
            "Testing RMSE: 0.38008896\n",
            "15\n",
            "Training RMSE: 0.3209163\n",
            "Testing RMSE: 0.38440222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "Training RMSE: 0.32186604\n",
            "Testing RMSE: 0.3743261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "Training RMSE: 0.3182657\n",
            "Testing RMSE: 0.37735653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "Training RMSE: 0.32572582\n",
            "Testing RMSE: 0.38181397\n",
            "19\n",
            "Training RMSE: 0.332365\n",
            "Testing RMSE: 0.3785786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "Training RMSE: 0.331574\n",
            "Testing RMSE: 0.39455274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your data to tensors\n",
        "inputs_train = torch.tensor(X_train, dtype=torch.float)\n",
        "labels_train = torch.tensor(y_train, dtype=torch.float)\n",
        "inputs_test = torch.tensor(X_test, dtype=torch.float)\n",
        "labels_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "test_dataset = TensorDataset(inputs_test, labels_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  # Create ELM model\n",
        "  input_dim = inputs_train.shape[1]\n",
        "  hidden_dim = [roh]\n",
        "  output_dim = 1  # Set output_size to 1 for a single regression target\n",
        "\n",
        "  # Create an instance of the MLP model\n",
        "  model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "  # Define your loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print(\"hello\")\n",
        "  print(model.parameters())\n",
        "  # Create an instance of the AdaBelief optimizer\n",
        "  optimizer = AdaBelief(model.parameters(),lr=0.01, betas = (0.9,0.999), eps=1e-8, weight_decouple = True, rectify = False)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 100\n",
        "  best_loss = float('inf')  # Initialize with a very high loss\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      #print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
        "      # Check if current loss is the lowest so far\n",
        "      if avg_loss < best_loss:\n",
        "          best_loss = avg_loss\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "  # Load the state of the best model\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "\n",
        "  train_predictions=[]\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          train_predictions.extend(output.numpy())\n",
        "  train_predictions = np.array(train_predictions)\n",
        "  if roh==1:\n",
        "    labels_train = labels_train.numpy()\n",
        "  else:\n",
        "    labels_train = labels_train\n",
        "  # Load the state of the best model\n",
        "  train_rmse = np.sqrt(mean_squared_error(labels_train, train_predictions))\n",
        "\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          predictions.extend(output.numpy())\n",
        "\n",
        "  predictions = np.array(predictions)\n",
        "  if roh==1:\n",
        "    labels_test = labels_test.numpy()\n",
        "  else:\n",
        "    labels_test = labels_test\n",
        "  rmse = np.sqrt(mean_squared_error(labels_test, predictions))\n",
        "  print(roh)\n",
        "  print(f\"Test RMSE: {rmse}\")\n",
        "  print(\"train RMSE:\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=predictions\n",
        "ws1['E4']=best_hidden_size\n",
        "ws1['F4']=best_train_rmse\n",
        "ws1['G4']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws13['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws13['B{}'.format(i+2)] = float(prediction)\n",
        "\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oOz_ekFZNmc",
        "outputId": "cf4d1f4f-9ae5-4dae-82af-0b96c81b4735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "1\n",
            "Test RMSE: 0.44652611017227173\n",
            "train RMSE: 1.3966017\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "2\n",
            "Test RMSE: 0.4141824543476105\n",
            "train RMSE: 1.3830482\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "3\n",
            "Test RMSE: 0.40340036153793335\n",
            "train RMSE: 1.3582135\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "4\n",
            "Test RMSE: 0.3874192535877228\n",
            "train RMSE: 1.3929032\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "5\n",
            "Test RMSE: 0.3822179436683655\n",
            "train RMSE: 1.3850338\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "6\n",
            "Test RMSE: 0.3815411329269409\n",
            "train RMSE: 1.3601273\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "7\n",
            "Test RMSE: 0.3872896730899811\n",
            "train RMSE: 1.4840728\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "8\n",
            "Test RMSE: 0.345923513174057\n",
            "train RMSE: 1.3834424\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "9\n",
            "Test RMSE: 0.3570448160171509\n",
            "train RMSE: 1.3511823\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "10\n",
            "Test RMSE: 0.3894788324832916\n",
            "train RMSE: 1.3847226\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "11\n",
            "Test RMSE: 0.352055162191391\n",
            "train RMSE: 1.3549068\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "12\n",
            "Test RMSE: 0.3785400390625\n",
            "train RMSE: 1.3744857\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "13\n",
            "Test RMSE: 0.3585914969444275\n",
            "train RMSE: 1.3742698\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "14\n",
            "Test RMSE: 0.36951306462287903\n",
            "train RMSE: 1.384723\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "15\n",
            "Test RMSE: 0.35912129282951355\n",
            "train RMSE: 1.3752686\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "16\n",
            "Test RMSE: 0.36742109060287476\n",
            "train RMSE: 1.4049726\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "17\n",
            "Test RMSE: 0.33034875988960266\n",
            "train RMSE: 1.3595632\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "18\n",
            "Test RMSE: 0.3878186047077179\n",
            "train RMSE: 1.3793368\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "19\n",
            "Test RMSE: 0.4161304831504822\n",
            "train RMSE: 1.4033167\n",
            "hello\n",
            "<generator object Module.parameters at 0x787680528a50>\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "20\n",
            "Test RMSE: 0.36102914810180664\n",
            "train RMSE: 1.3904171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your data to tensors\n",
        "inputs_train = torch.tensor(X_train, dtype=torch.float)\n",
        "labels_train = torch.tensor(y_train, dtype=torch.float)\n",
        "inputs_test = torch.tensor(X_test, dtype=torch.float)\n",
        "labels_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "test_dataset = TensorDataset(inputs_test, labels_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  # Create ELM model\n",
        "  input_dim = inputs_train.shape[1]\n",
        "  hidden_dim = [roh]\n",
        "  output_dim = 1  # Set output_size to 1 for a single regression target\n",
        "\n",
        "  # Create an instance of the MLP model\n",
        "  model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "  # Define your loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print(\"hello\")\n",
        "  print(model.parameters())\n",
        "  # Create an instance of the AdaBelief optimizer\n",
        "  optimizer = RangerAdaBelief(model.parameters(), lr=1e-2, eps=1e-12, betas=(0.9,0.999),weight_decouple = False)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 100\n",
        "  best_loss = float('inf')  # Initialize with a very high loss\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      #print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
        "      # Check if current loss is the lowest so far\n",
        "      if avg_loss < best_loss:\n",
        "          best_loss = avg_loss\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "\n",
        "  # Load the state of the best model\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "\n",
        "  train_predictions=[]\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          train_predictions.extend(output.numpy())\n",
        "  train_predictions = np.array(train_predictions)\n",
        "  if roh==1:\n",
        "    labels_train = labels_train.numpy()\n",
        "  else:\n",
        "    labels_train = labels_train\n",
        "  # Load the state of the best model\n",
        "  train_rmse = np.sqrt(mean_squared_error(labels_train, train_predictions))\n",
        "\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          predictions.extend(output.numpy())\n",
        "\n",
        "  predictions = np.array(predictions)\n",
        "  if roh==1:\n",
        "    labels_test = labels_test.numpy()\n",
        "  else:\n",
        "    labels_test = labels_test\n",
        "  rmse = np.sqrt(mean_squared_error(labels_test, predictions))\n",
        "  print(roh)\n",
        "  print(f\"Test RMSE: {rmse}\")\n",
        "  print(\"train RMSE:\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=predictions\n",
        "\n",
        "ws1['H4']=best_hidden_size\n",
        "ws1['I4']=best_train_rmse\n",
        "ws1['J4']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws14['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws14['B{}'.format(i+2)] = float(prediction)\n",
        "\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyUc5ZGdZYCj",
        "outputId": "d61c6dc8-9a57-45b3-ec45-71a020525d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "<generator object Module.parameters at 0x78767f6dbd80>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "1\n",
            "Test RMSE: 0.4334132969379425\n",
            "train RMSE: 1.3032271\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "2\n",
            "Test RMSE: 0.43082207441329956\n",
            "train RMSE: 1.4008877\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "3\n",
            "Test RMSE: 0.3997681438922882\n",
            "train RMSE: 1.3697808\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "4\n",
            "Test RMSE: 0.3869655430316925\n",
            "train RMSE: 1.4124495\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "5\n",
            "Test RMSE: 0.37143099308013916\n",
            "train RMSE: 1.3564638\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "6\n",
            "Test RMSE: 0.3797164261341095\n",
            "train RMSE: 1.3793833\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "7\n",
            "Test RMSE: 0.3606612980365753\n",
            "train RMSE: 1.3798441\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "8\n",
            "Test RMSE: 0.36451977491378784\n",
            "train RMSE: 1.3704019\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "9\n",
            "Test RMSE: 0.3812018036842346\n",
            "train RMSE: 1.3646244\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "10\n",
            "Test RMSE: 0.36103367805480957\n",
            "train RMSE: 1.4203383\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "11\n",
            "Test RMSE: 0.39035120606422424\n",
            "train RMSE: 1.3644515\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "12\n",
            "Test RMSE: 0.3899666965007782\n",
            "train RMSE: 1.383453\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "13\n",
            "Test RMSE: 0.38713395595550537\n",
            "train RMSE: 1.3946358\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "14\n",
            "Test RMSE: 0.39877796173095703\n",
            "train RMSE: 1.3640136\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "15\n",
            "Test RMSE: 0.3972601592540741\n",
            "train RMSE: 1.3800417\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "16\n",
            "Test RMSE: 0.37504929304122925\n",
            "train RMSE: 1.4031926\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "17\n",
            "Test RMSE: 0.36822080612182617\n",
            "train RMSE: 1.3692442\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "18\n",
            "Test RMSE: 0.38346195220947266\n",
            "train RMSE: 1.3527272\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "19\n",
            "Test RMSE: 0.38414740562438965\n",
            "train RMSE: 1.3757035\n",
            "hello\n",
            "<generator object Module.parameters at 0x78767ff48890>\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "20\n",
            "Test RMSE: 0.3879479467868805\n",
            "train RMSE: 1.4070152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we pass our data to the Conv1D layer, we have to reshape it in order to make sure it works\n",
        "x = tf.constant(X_train)\n",
        "expand_dims_layer = layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) # add an extra dimension for timesteps\n",
        "print(f\"Original shape: {x.shape}\") # (WINDOW_SIZE)\n",
        "print(f\"Expanded shape: {expand_dims_layer(x).shape}\") # (WINDOW_SIZE, input_dim)\n",
        "print(f\"Original values with expanded shape:\\n {expand_dims_layer(x)}\")\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create model\n",
        "model_10 = tf.keras.Sequential([\n",
        "  # Create Lambda layer to reshape inputs, without this layer, the model will error\n",
        "  layers.Lambda(lambda x: tf.expand_dims(x, axis=1)), # resize the inputs to adjust for window size / Conv1D 3D input requirements\n",
        "  layers.Conv1D(filters=12, kernel_size=5, padding=\"causal\", activation=\"relu\"),\n",
        "  layers.Dense(HORIZON)\n",
        "], name=\"model_10_conv1D\")\n",
        "\n",
        "# Compile model\n",
        "model_10.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "# Fit model\n",
        "model_10.fit(X_train,\n",
        "            y_train,\n",
        "            batch_size=128,\n",
        "            epochs=100,\n",
        "            verbose=0,\n",
        "            validation_data=(X_test, y_test),\n",
        "            callbacks=[create_model_checkpoint(model_name=model_10.name)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgIn609fZih5",
        "outputId": "5152b51b-48b2-4318-b3a4-a2209083740b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (2833, 6)\n",
            "Expanded shape: (2833, 1, 6)\n",
            "Original values with expanded shape:\n",
            " [[[-0.4032232  -0.7458762  -0.53653353 -0.4248603  -0.62721187\n",
            "   -0.4421828 ]]\n",
            "\n",
            " [[-1.2142386  -0.9646546  -0.9517654  -1.2762262  -0.18470922\n",
            "   -1.2763008 ]]\n",
            "\n",
            " [[-1.045161   -1.1638292  -0.64796025 -1.0525275  -0.62721187\n",
            "   -1.0783588 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.8657881   1.2097985   0.6939246   1.1369331  -0.18470922\n",
            "    1.0990016 ]]\n",
            "\n",
            " [[ 0.84627926  1.1651019   0.8205888   1.0828525   0.2577933\n",
            "    1.0502068 ]]\n",
            "\n",
            " [[ 0.99027425  1.1690223   1.0320144   1.0894073   1.3640499\n",
            "    1.093478  ]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78767e3161a0>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz6J24eOZlEv",
        "outputId": "811f55e3-1859-4a90-fc0a-4d17faad9cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1378 - root_mean_squared_error: 0.3712\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13779959082603455, 0.3712136745452881]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # Let's build an LSTM model with the Functional API\n",
        "  inputs = layers.Input(shape=(6))\n",
        "  x = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(inputs) # expand input dimension to be compatible with LSTM\n",
        "  # print(x.shape)\n",
        "  # x = layers.LSTM(128, activation=\"relu\", return_sequences=True)(x) # this layer will error if the inputs are not the right shape\n",
        "  x = layers.LSTM(roh, activation=\"relu\")(x) # using the tanh loss function results in a massive error\n",
        "  # print(x.shape)\n",
        "\n",
        "\n",
        "  output = layers.Dense(HORIZON)(x)\n",
        "  model_11 = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_11_lstm\")\n",
        "\n",
        "  # Compile model\n",
        "  model_11.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  # Seems when saving the model several warnings are appearing: https://github.com/tensorflow/tensorflow/issues/47554\n",
        "  model_11.fit(X_train,\n",
        "              y_train,\n",
        "              epochs=100,\n",
        "              verbose=0,\n",
        "              batch_size=128,\n",
        "              validation_data=(X_test, y_test),\n",
        "              callbacks=[create_model_checkpoint(model_name=model_11.name)])\n",
        "  print(roh)\n",
        "  rmse=model_11.evaluate(X_test, y_test)\n",
        "  rmse=rmse[1]\n",
        "  print(\"test rmse\",rmse)\n",
        "  train_rmse=model_11.evaluate(X_train, y_train)\n",
        "  train_rmse=train_rmse[1]\n",
        "  print(\"train rmse\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=model_11.predict(X_test)\n",
        "\n",
        "ws1['K4']=best_hidden_size\n",
        "ws1['L4']=best_train_rmse\n",
        "ws1['M4']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws15['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws15['B{}'.format(i+2)] = float(prediction)\n",
        "\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUGiqmgsZlKf",
        "outputId": "befab606-5814-4d70-ba21-cff3599d39f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1781 - root_mean_squared_error: 0.4221\n",
            "test rmse 0.4220583140850067\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1367 - root_mean_squared_error: 0.3697\n",
            "train rmse 0.3697308599948883\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1595 - root_mean_squared_error: 0.3993\n",
            "test rmse 0.3993253707885742\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1252 - root_mean_squared_error: 0.3538\n",
            "train rmse 0.3538261353969574\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1412 - root_mean_squared_error: 0.3758\n",
            "test rmse 0.3758156895637512\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1121 - root_mean_squared_error: 0.3348\n",
            "train rmse 0.3348178267478943\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1638 - root_mean_squared_error: 0.4048\n",
            "test rmse 0.40475931763648987\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1236 - root_mean_squared_error: 0.3516\n",
            "train rmse 0.3515556752681732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1454 - root_mean_squared_error: 0.3814\n",
            "test rmse 0.3813718557357788\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1074 - root_mean_squared_error: 0.3277\n",
            "train rmse 0.32770073413848877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1390 - root_mean_squared_error: 0.3729\n",
            "test rmse 0.37286773324012756\n",
            "89/89 [==============================] - 0s 3ms/step - loss: 0.1050 - root_mean_squared_error: 0.3240\n",
            "train rmse 0.3239879012107849\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1410 - root_mean_squared_error: 0.3755\n",
            "test rmse 0.3755434453487396\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1067 - root_mean_squared_error: 0.3267\n",
            "train rmse 0.32665184140205383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1415 - root_mean_squared_error: 0.3762\n",
            "test rmse 0.37620219588279724\n",
            "89/89 [==============================] - 0s 3ms/step - loss: 0.1067 - root_mean_squared_error: 0.3266\n",
            "train rmse 0.32658109068870544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1366 - root_mean_squared_error: 0.3696\n",
            "test rmse 0.36960217356681824\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1027 - root_mean_squared_error: 0.3205\n",
            "train rmse 0.3204623758792877\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1370 - root_mean_squared_error: 0.3701\n",
            "test rmse 0.37010660767555237\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1025 - root_mean_squared_error: 0.3202\n",
            "train rmse 0.320186585187912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1378 - root_mean_squared_error: 0.3712\n",
            "test rmse 0.3712388873100281\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1045 - root_mean_squared_error: 0.3233\n",
            "train rmse 0.3233163356781006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1382 - root_mean_squared_error: 0.3717\n",
            "test rmse 0.371743381023407\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1036 - root_mean_squared_error: 0.3218\n",
            "train rmse 0.3218461871147156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1384 - root_mean_squared_error: 0.3720\n",
            "test rmse 0.37202852964401245\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1036 - root_mean_squared_error: 0.3219\n",
            "train rmse 0.32188278436660767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1360 - root_mean_squared_error: 0.3688\n",
            "test rmse 0.36876392364501953\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1027 - root_mean_squared_error: 0.3204\n",
            "train rmse 0.32039496302604675\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1362 - root_mean_squared_error: 0.3691\n",
            "test rmse 0.36905190348625183\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1021 - root_mean_squared_error: 0.3196\n",
            "train rmse 0.3195609152317047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1357 - root_mean_squared_error: 0.3684\n",
            "test rmse 0.3684409260749817\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1029 - root_mean_squared_error: 0.3207\n",
            "train rmse 0.3207460045814514\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1353 - root_mean_squared_error: 0.3679\n",
            "test rmse 0.36787149310112\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1038 - root_mean_squared_error: 0.3222\n",
            "train rmse 0.322160542011261\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1380 - root_mean_squared_error: 0.3715\n",
            "test rmse 0.3714733123779297\n",
            "89/89 [==============================] - 0s 3ms/step - loss: 0.1040 - root_mean_squared_error: 0.3225\n",
            "train rmse 0.3225158154964447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1353 - root_mean_squared_error: 0.3678\n",
            "test rmse 0.36777088046073914\n",
            "89/89 [==============================] - 0s 3ms/step - loss: 0.1026 - root_mean_squared_error: 0.3203\n",
            "train rmse 0.3203267455101013\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1344 - root_mean_squared_error: 0.3666\n",
            "test rmse 0.36662721633911133\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.1010 - root_mean_squared_error: 0.3178\n",
            "train rmse 0.3178369700908661\n",
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "train_labels_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
        "\n",
        "test_features_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "test_labels_dataset = tf.data.Dataset.from_tensor_slices(y_test)\n",
        "\n",
        "# 2. Combine features & labels\n",
        "train_dataset = tf.data.Dataset.zip((train_features_dataset, train_labels_dataset))\n",
        "test_dataset = tf.data.Dataset.zip((test_features_dataset, test_labels_dataset))\n",
        "\n",
        "# 3. Batch and prefetch for optimal performance\n",
        "BATCH_SIZE = 1024 # taken from Appendix D in N-BEATS paper\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uleV9cscZuqv",
        "outputId": "32afa499-1fc1-4001-b034-48333198fef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 6), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
              " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 6), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_rmse=1\n",
        "for roh in range(1,21):\n",
        "  # Values from N-BEATS paper Figure 1 and Table 18/Appendix D\n",
        "  N_EPOCHS = 100 # called \"Iterations\" in Table 18\n",
        "  N_NEURONS = roh # called \"Width\" in Table 18\n",
        "  N_LAYERS = 2\n",
        "  N_STACKS = 1\n",
        "  INPUT_SIZE = WINDOW_SIZE * HORIZON # called \"Lookback\" in Table 18\n",
        "  THETA_SIZE = INPUT_SIZE + HORIZON\n",
        "\n",
        "  INPUT_SIZE, THETA_SIZE\n",
        "\n",
        "\n",
        "  # %%time\n",
        "\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # 1. Setup N-BEATS Block layer\n",
        "  nbeats_block_layer = NBeatsBlock(input_size=INPUT_SIZE,\n",
        "                                  theta_size=THETA_SIZE,\n",
        "                                  horizon=HORIZON,\n",
        "                                  n_neurons=N_NEURONS,\n",
        "                                  n_layers=N_LAYERS,\n",
        "                                  name=\"InitialBlock\")\n",
        "\n",
        "  # 2. Create input to stacks\n",
        "  stack_input = layers.Input(shape=(6), name=\"stack_input\")\n",
        "\n",
        "  # 3. Create initial backcast and forecast input (backwards predictions are referred to as residuals in the paper)\n",
        "  backcast, forecast = nbeats_block_layer(stack_input)\n",
        "  # Add in subtraction residual link, thank you to: https://github.com/mrdbourke/tensorflow-deep-learning/discussions/174\n",
        "  residuals = layers.subtract([stack_input, backcast], name=f\"subtract_00\")\n",
        "\n",
        "  # 4. Create stacks of blocks\n",
        "  for i, _ in enumerate(range(N_STACKS-1)): # first stack is already creted in (3)\n",
        "\n",
        "    # 5. Use the NBeatsBlock to calculate the backcast as well as block forecast\n",
        "    backcast, block_forecast = NBeatsBlock(\n",
        "        input_size=INPUT_SIZE,\n",
        "        theta_size=THETA_SIZE,\n",
        "        horizon=HORIZON,\n",
        "        n_neurons=N_NEURONS,\n",
        "        n_layers=N_LAYERS,\n",
        "        name=f\"NBeatsBlock_{i}\"\n",
        "    )(residuals) # pass it in residuals (the backcast)\n",
        "\n",
        "    # 6. Create the double residual stacking\n",
        "    residuals = layers.subtract([residuals, backcast], name=f\"subtract_{i}\")\n",
        "    forecast = layers.add([forecast, block_forecast], name=f\"add_{i}\")\n",
        "\n",
        "  # 7. Put the stack model together\n",
        "  model_12 = tf.keras.Model(inputs=stack_input,\n",
        "                          outputs=forecast,\n",
        "                          name=\"model_12_N-BEATS\")\n",
        "\n",
        "  # 8. Compile with MAE loss and Adam optimizer\n",
        "  model_12.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  # 9. Fit the model with EarlyStopping and ReduceLROnPlateau callbacks\n",
        "  model_12.fit(train_dataset,\n",
        "              epochs=N_EPOCHS,\n",
        "              validation_data=test_dataset,\n",
        "              verbose=0, # prevent large amounts of training outputs\n",
        "              # callbacks=[create_model_checkpoint(model_name=stack_model.name)] # saving model every epoch consumes far too much time\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100, verbose=1)])\n",
        "  print(roh)\n",
        "  # Evaluate N-BEATS model on the test dataset\n",
        "  rmse=model_12.evaluate(test_dataset)\n",
        "  rmse=rmse[1]\n",
        "  print(\"test RMSE:\",rmse)\n",
        "  train_rmse=model_12.evaluate(train_dataset)\n",
        "  train_rmse=train_rmse[1]\n",
        "  print(\"train RMSE:\",train_rmse)\n",
        "  if rmse < best_test_rmse:\n",
        "    best_test_rmse=rmse\n",
        "    best_hidden_size=roh\n",
        "    best_train_rmse=train_rmse\n",
        "    best_test_predictions=model_12.predict(X_test)\n",
        "\n",
        "ws1['N4']=best_hidden_size\n",
        "ws1['O4']=best_train_rmse\n",
        "ws1['P4']=best_test_rmse\n",
        "\n",
        "for i, prediction in enumerate(y_test):\n",
        "    ws16['A{}'.format(i+2)] = float(prediction)\n",
        "for i, prediction in enumerate(best_test_predictions):\n",
        "    ws16['B{}'.format(i+2)] = float(prediction)\n",
        "\n",
        "\n",
        "wb.save(filename = 'Results.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu8FZmSYZutl",
        "outputId": "f10b8f4f-0285-4720-d61f-b32a499a5e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5789 - root_mean_squared_error: 0.7609\n",
            "test RMSE: 0.7608597278594971\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5161 - root_mean_squared_error: 0.7184\n",
            "train RMSE: 0.718392014503479\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "2\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4499 - root_mean_squared_error: 0.6708\n",
            "test RMSE: 0.6707602739334106\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3732 - root_mean_squared_error: 0.6109\n",
            "train RMSE: 0.6109338998794556\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "3\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3660 - root_mean_squared_error: 0.6050\n",
            "test RMSE: 0.6050038933753967\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.3138 - root_mean_squared_error: 0.5602\n",
            "train RMSE: 0.5601626634597778\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "4\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1526 - root_mean_squared_error: 0.3906\n",
            "test RMSE: 0.39057689905166626\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1173 - root_mean_squared_error: 0.3425\n",
            "train RMSE: 0.3424743711948395\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2945 - root_mean_squared_error: 0.5427\n",
            "test RMSE: 0.5426995754241943\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2389 - root_mean_squared_error: 0.4887\n",
            "train RMSE: 0.4887318015098572\n",
            "6\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1696 - root_mean_squared_error: 0.4119\n",
            "test RMSE: 0.4118652641773224\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1396 - root_mean_squared_error: 0.3737\n",
            "train RMSE: 0.3736627995967865\n",
            "7\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2572 - root_mean_squared_error: 0.5071\n",
            "test RMSE: 0.5071248412132263\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4034 - root_mean_squared_error: 0.6352\n",
            "train RMSE: 0.6351559162139893\n",
            "8\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1615 - root_mean_squared_error: 0.4019\n",
            "test RMSE: 0.40190866589546204\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1180 - root_mean_squared_error: 0.3435\n",
            "train RMSE: 0.34351423382759094\n",
            "9\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1424 - root_mean_squared_error: 0.3774\n",
            "test RMSE: 0.3773704767227173\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1097 - root_mean_squared_error: 0.3312\n",
            "train RMSE: 0.3311614990234375\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "10\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1496 - root_mean_squared_error: 0.3867\n",
            "test RMSE: 0.3867482841014862\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1177 - root_mean_squared_error: 0.3431\n",
            "train RMSE: 0.3431271016597748\n",
            "11\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1638 - root_mean_squared_error: 0.4048\n",
            "test RMSE: 0.4047693908214569\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1197 - root_mean_squared_error: 0.3460\n",
            "train RMSE: 0.34595075249671936\n",
            "12\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1507 - root_mean_squared_error: 0.3882\n",
            "test RMSE: 0.3882298171520233\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1132 - root_mean_squared_error: 0.3365\n",
            "train RMSE: 0.3364613354206085\n",
            "13\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1535 - root_mean_squared_error: 0.3918\n",
            "test RMSE: 0.39180460572242737\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1082 - root_mean_squared_error: 0.3289\n",
            "train RMSE: 0.32887181639671326\n",
            "14\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1464 - root_mean_squared_error: 0.3827\n",
            "test RMSE: 0.38267916440963745\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1113 - root_mean_squared_error: 0.3335\n",
            "train RMSE: 0.3335473835468292\n",
            "15\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1430 - root_mean_squared_error: 0.3782\n",
            "test RMSE: 0.3781960606575012\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1113 - root_mean_squared_error: 0.3337\n",
            "train RMSE: 0.3336756229400635\n",
            "16\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1432 - root_mean_squared_error: 0.3784\n",
            "test RMSE: 0.37842246890068054\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1018 - root_mean_squared_error: 0.3190\n",
            "train RMSE: 0.3189888298511505\n",
            "17\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1444 - root_mean_squared_error: 0.3800\n",
            "test RMSE: 0.3799510896205902\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1119 - root_mean_squared_error: 0.3345\n",
            "train RMSE: 0.33453822135925293\n",
            "18\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1496 - root_mean_squared_error: 0.3867\n",
            "test RMSE: 0.3867238759994507\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1046 - root_mean_squared_error: 0.3234\n",
            "train RMSE: 0.32336246967315674\n",
            "19\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1417 - root_mean_squared_error: 0.3764\n",
            "test RMSE: 0.37637656927108765\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1074 - root_mean_squared_error: 0.3277\n",
            "train RMSE: 0.32769596576690674\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1455 - root_mean_squared_error: 0.3815\n",
            "test RMSE: 0.38148754835128784\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1088 - root_mean_squared_error: 0.3299\n",
            "train RMSE: 0.32985687255859375\n"
          ]
        }
      ]
    }
  ]
}